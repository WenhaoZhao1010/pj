{"cells":[{"cell_type":"code","source":[],"metadata":{"id":"bM2XTh3cggOx"},"id":"bM2XTh3cggOx","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"id":"radical-fifty","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"radical-fifty","executionInfo":{"status":"ok","timestamp":1764720424368,"user_tz":480,"elapsed":4382,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"b5237173-1944-44ee-c517-0b1c0d81bc61","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["=> Building model...\n","ResNet_Cifar_Internal_8x8(\n","  (conv1): QuantConv2d(\n","    3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","    (weight_quant): weight_quantize_fn()\n","  )\n","  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): QuantConv2d(\n","        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (conv2): QuantConv2d(\n","        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): QuantConv2d(\n","        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (conv2): QuantConv2d(\n","        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): QuantConv2d(\n","        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (conv2): QuantConv2d(\n","        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): QuantConv2d(\n","        16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (conv2): QuantConv2d(\n","        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): QuantConv2d(\n","          16, 8, kernel_size=(1, 1), stride=(2, 2), bias=False\n","          (weight_quant): weight_quantize_fn()\n","        )\n","        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): QuantBasicBlockNoBN(\n","      (conv1): QuantConv2d(\n","        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (relu): ReLU(inplace=True)\n","      (conv2): QuantConv2d(\n","        8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): QuantConv2d(\n","        8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (conv2): QuantConv2d(\n","        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): QuantConv2d(\n","          8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (weight_quant): weight_quantize_fn()\n","        )\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): QuantConv2d(\n","        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (conv2): QuantConv2d(\n","        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): QuantConv2d(\n","          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n","          (weight_quant): weight_quantize_fn()\n","        )\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): QuantConv2d(\n","        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (conv2): QuantConv2d(\n","        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): QuantConv2d(\n","        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (conv2): QuantConv2d(\n","        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (weight_quant): weight_quantize_fn()\n","      )\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n","  (fc): Linear(in_features=64, out_features=10, bias=True)\n",")\n"]}],"source":["import argparse\n","import os\n","import time\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from models import *\n","\n","\n","global best_prec\n","use_gpu = torch.cuda.is_available()\n","print('=> Building model...')\n","\n","\n","\n","batch_size = 128\n","model_name = \"ResNet20_project\"\n","model = resnet20_internal_8x8()\n","\n","print(model)\n","\n","normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n","\n","\n","train_dataset = torchvision.datasets.CIFAR10(\n","    root='./data',\n","    train=True,\n","    download=True,\n","    transform=transforms.Compose([\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]))\n","trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","\n","test_dataset = torchvision.datasets.CIFAR10(\n","    root='./data',\n","    train=False,\n","    download=True,\n","    transform=transforms.Compose([\n","        transforms.ToTensor(),\n","        normalize,\n","    ]))\n","\n","testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","\n","print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n","# CIFAR10 has 50,000 training data, and 10,000 validation data.\n","\n","def train(trainloader, model, criterion, optimizer, epoch):\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(trainloader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        input, target = input.cuda(), target.cuda()\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss\n","        prec = accuracy(output, target)[0]\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(prec.item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","\n","        if i % print_freq == 0:\n","            print('Epoch: [{0}][{1}/{2}]\\t'\n","                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n","                   epoch, i, len(trainloader), batch_time=batch_time,\n","                   data_time=data_time, loss=losses, top1=top1))\n","\n","\n","\n","def validate(val_loader, model, criterion ):\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    end = time.time()\n","    with torch.no_grad():\n","        for i, (input, target) in enumerate(val_loader):\n","\n","            input, target = input.cuda(), target.cuda()\n","\n","            # compute output\n","            output = model(input)\n","            loss = criterion(output, target)\n","\n","            # measure accuracy and record loss\n","            prec = accuracy(output, target)[0]\n","            losses.update(loss.item(), input.size(0))\n","            top1.update(prec.item(), input.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n","                print('Test: [{0}/{1}]\\t'\n","                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n","                   i, len(val_loader), batch_time=batch_time, loss=losses,\n","                   top1=top1))\n","\n","    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n","    return top1.avg\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def save_checkpoint(state, is_best, fdir):\n","    filepath = os.path.join(fdir, 'checkpoint.pth')\n","    torch.save(state, filepath)\n","    if is_best:\n","        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n","\n","#model = nn.DataParallel(model).cuda()\n","#all_params = checkpoint['state_dict']\n","#model.load_state_dict(all_params, strict=False)\n","#criterion = nn.CrossEntropyLoss().cuda()\n","#validate(testloader, model, criterion)"]},{"cell_type":"code","execution_count":2,"id":"2107ceeb","metadata":{"id":"2107ceeb","executionInfo":{"status":"ok","timestamp":1764720473671,"user_tz":480,"elapsed":64,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}}},"outputs":[],"source":["def adjust_learning_rate(optimizer, epoch):\n","    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n","    adjust_list = [60, 80]\n","    if epoch in adjust_list:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = param_group['lr'] * 0.1"]},{"cell_type":"code","execution_count":3,"id":"junior-reminder","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"junior-reminder","executionInfo":{"status":"ok","timestamp":1764721895725,"user_tz":480,"elapsed":1418923,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"44856831-950b-4851-8d7a-35d2e8b5830c","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [0][0/391]\tTime 1.909 (1.909)\tData 0.143 (0.143)\tLoss 2.3821 (2.3821)\tPrec 6.250% (6.250%)\n","Epoch: [0][100/391]\tTime 0.032 (0.052)\tData 0.001 (0.003)\tLoss 1.8416 (1.9802)\tPrec 36.719% (24.435%)\n","Epoch: [0][200/391]\tTime 0.034 (0.042)\tData 0.002 (0.002)\tLoss 1.6746 (1.8451)\tPrec 35.938% (29.878%)\n","Epoch: [0][300/391]\tTime 0.033 (0.039)\tData 0.001 (0.002)\tLoss 1.6057 (1.7557)\tPrec 38.281% (33.591%)\n","Validation starts\n","Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.4880 (1.4880)\tPrec 46.875% (46.875%)\n"," * Prec 45.050% \n","best acc: 45.050000\n","Epoch: [1][0/391]\tTime 0.146 (0.146)\tData 0.104 (0.104)\tLoss 1.4578 (1.4578)\tPrec 50.781% (50.781%)\n","Epoch: [1][100/391]\tTime 0.033 (0.036)\tData 0.002 (0.003)\tLoss 1.3928 (1.3908)\tPrec 52.344% (49.002%)\n","Epoch: [1][200/391]\tTime 0.034 (0.035)\tData 0.002 (0.002)\tLoss 1.4572 (1.3708)\tPrec 47.656% (49.580%)\n","Epoch: [1][300/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 1.1810 (1.3377)\tPrec 57.812% (51.041%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 1.2348 (1.2348)\tPrec 51.562% (51.562%)\n"," * Prec 51.610% \n","best acc: 51.610000\n","Epoch: [2][0/391]\tTime 0.146 (0.146)\tData 0.105 (0.105)\tLoss 1.1616 (1.1616)\tPrec 56.250% (56.250%)\n","Epoch: [2][100/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 1.0822 (1.1583)\tPrec 57.812% (57.774%)\n","Epoch: [2][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 1.1787 (1.1453)\tPrec 57.812% (58.559%)\n","Epoch: [2][300/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.8935 (1.1188)\tPrec 72.656% (59.637%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 1.1266 (1.1266)\tPrec 60.156% (60.156%)\n"," * Prec 61.210% \n","best acc: 61.210000\n","Epoch: [3][0/391]\tTime 0.146 (0.146)\tData 0.104 (0.104)\tLoss 0.8446 (0.8446)\tPrec 70.312% (70.312%)\n","Epoch: [3][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 1.0347 (0.9891)\tPrec 59.375% (64.821%)\n","Epoch: [3][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.8484 (0.9909)\tPrec 67.969% (64.665%)\n","Epoch: [3][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.7922 (0.9781)\tPrec 77.344% (65.145%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.9575 (0.9575)\tPrec 63.281% (63.281%)\n"," * Prec 63.850% \n","best acc: 63.850000\n","Epoch: [4][0/391]\tTime 0.159 (0.159)\tData 0.105 (0.105)\tLoss 0.9389 (0.9389)\tPrec 66.406% (66.406%)\n","Epoch: [4][100/391]\tTime 0.032 (0.038)\tData 0.001 (0.003)\tLoss 0.8916 (0.8947)\tPrec 66.406% (68.023%)\n","Epoch: [4][200/391]\tTime 0.031 (0.035)\tData 0.001 (0.002)\tLoss 0.7775 (0.8745)\tPrec 69.531% (68.925%)\n","Epoch: [4][300/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.9503 (0.8712)\tPrec 64.844% (69.228%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.8109 (0.8109)\tPrec 72.656% (72.656%)\n"," * Prec 68.150% \n","best acc: 68.150000\n","Epoch: [5][0/391]\tTime 0.145 (0.145)\tData 0.105 (0.105)\tLoss 0.8200 (0.8200)\tPrec 73.438% (73.438%)\n","Epoch: [5][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.7079 (0.8078)\tPrec 75.781% (71.248%)\n","Epoch: [5][200/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.7188 (0.7937)\tPrec 73.438% (71.720%)\n","Epoch: [5][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.7478 (0.8011)\tPrec 73.438% (71.608%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 1.0197 (1.0197)\tPrec 68.750% (68.750%)\n"," * Prec 66.840% \n","best acc: 68.150000\n","Epoch: [6][0/391]\tTime 0.158 (0.158)\tData 0.107 (0.107)\tLoss 0.5902 (0.5902)\tPrec 82.031% (82.031%)\n","Epoch: [6][100/391]\tTime 0.044 (0.035)\tData 0.002 (0.003)\tLoss 0.7451 (0.7438)\tPrec 74.219% (73.778%)\n","Epoch: [6][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.002)\tLoss 0.8448 (0.7441)\tPrec 75.781% (73.869%)\n","Epoch: [6][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.5930 (0.7423)\tPrec 79.688% (74.094%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.7126 (0.7126)\tPrec 75.781% (75.781%)\n"," * Prec 73.020% \n","best acc: 73.020000\n","Epoch: [7][0/391]\tTime 0.146 (0.146)\tData 0.104 (0.104)\tLoss 0.5467 (0.5467)\tPrec 80.469% (80.469%)\n","Epoch: [7][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.7507 (0.6993)\tPrec 71.875% (75.170%)\n","Epoch: [7][200/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 1.0120 (0.7021)\tPrec 64.844% (75.303%)\n","Epoch: [7][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.7170 (0.6998)\tPrec 74.219% (75.387%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.6833 (0.6833)\tPrec 76.562% (76.562%)\n"," * Prec 70.610% \n","best acc: 73.020000\n","Epoch: [8][0/391]\tTime 0.145 (0.145)\tData 0.103 (0.103)\tLoss 0.6877 (0.6877)\tPrec 78.906% (78.906%)\n","Epoch: [8][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.6888 (0.6541)\tPrec 78.906% (76.787%)\n","Epoch: [8][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.6994 (0.6675)\tPrec 78.125% (76.481%)\n","Epoch: [8][300/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.6814 (0.6601)\tPrec 75.781% (76.736%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.8881 (0.8881)\tPrec 71.094% (71.094%)\n"," * Prec 74.200% \n","best acc: 74.200000\n","Epoch: [9][0/391]\tTime 0.143 (0.143)\tData 0.102 (0.102)\tLoss 0.5806 (0.5806)\tPrec 75.781% (75.781%)\n","Epoch: [9][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.5558 (0.6400)\tPrec 79.688% (77.614%)\n","Epoch: [9][200/391]\tTime 0.032 (0.032)\tData 0.002 (0.002)\tLoss 0.5638 (0.6382)\tPrec 79.688% (77.421%)\n","Epoch: [9][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.6782 (0.6324)\tPrec 75.000% (77.850%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.6339 (0.6339)\tPrec 78.906% (78.906%)\n"," * Prec 75.790% \n","best acc: 75.790000\n","Epoch: [10][0/391]\tTime 0.142 (0.142)\tData 0.101 (0.101)\tLoss 0.6053 (0.6053)\tPrec 78.906% (78.906%)\n","Epoch: [10][100/391]\tTime 0.038 (0.033)\tData 0.002 (0.002)\tLoss 0.6190 (0.6061)\tPrec 78.906% (78.937%)\n","Epoch: [10][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.6679 (0.6020)\tPrec 78.125% (79.237%)\n","Epoch: [10][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.5186 (0.6059)\tPrec 82.812% (79.057%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.6785 (0.6785)\tPrec 80.469% (80.469%)\n"," * Prec 76.020% \n","best acc: 76.020000\n","Epoch: [11][0/391]\tTime 0.142 (0.142)\tData 0.101 (0.101)\tLoss 0.5714 (0.5714)\tPrec 82.812% (82.812%)\n","Epoch: [11][100/391]\tTime 0.034 (0.033)\tData 0.001 (0.002)\tLoss 0.6120 (0.6013)\tPrec 76.562% (78.914%)\n","Epoch: [11][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.5960 (0.5874)\tPrec 78.906% (79.388%)\n","Epoch: [11][300/391]\tTime 0.033 (0.032)\tData 0.001 (0.002)\tLoss 0.6174 (0.5823)\tPrec 80.469% (79.698%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.6518 (0.6518)\tPrec 82.031% (82.031%)\n"," * Prec 76.890% \n","best acc: 76.890000\n","Epoch: [12][0/391]\tTime 0.144 (0.144)\tData 0.104 (0.104)\tLoss 0.5161 (0.5161)\tPrec 84.375% (84.375%)\n","Epoch: [12][100/391]\tTime 0.031 (0.033)\tData 0.002 (0.002)\tLoss 0.4602 (0.5516)\tPrec 84.375% (81.088%)\n","Epoch: [12][200/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.6482 (0.5600)\tPrec 78.906% (80.566%)\n","Epoch: [12][300/391]\tTime 0.032 (0.032)\tData 0.002 (0.002)\tLoss 0.4940 (0.5650)\tPrec 83.594% (80.217%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.6169 (0.6169)\tPrec 75.781% (75.781%)\n"," * Prec 77.910% \n","best acc: 77.910000\n","Epoch: [13][0/391]\tTime 0.145 (0.145)\tData 0.105 (0.105)\tLoss 0.5475 (0.5475)\tPrec 78.906% (78.906%)\n","Epoch: [13][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.4875 (0.5354)\tPrec 85.156% (81.737%)\n","Epoch: [13][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.6108 (0.5461)\tPrec 81.250% (81.021%)\n","Epoch: [13][300/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.4301 (0.5400)\tPrec 85.156% (81.193%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.6721 (0.6721)\tPrec 79.688% (79.688%)\n"," * Prec 77.510% \n","best acc: 77.910000\n","Epoch: [14][0/391]\tTime 0.141 (0.141)\tData 0.101 (0.101)\tLoss 0.4685 (0.4685)\tPrec 87.500% (87.500%)\n","Epoch: [14][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.4094 (0.5368)\tPrec 84.375% (81.521%)\n","Epoch: [14][200/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.4804 (0.5336)\tPrec 82.812% (81.685%)\n","Epoch: [14][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.5371 (0.5316)\tPrec 82.031% (81.629%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.7802 (0.7802)\tPrec 73.438% (73.438%)\n"," * Prec 70.760% \n","best acc: 77.910000\n","Epoch: [15][0/391]\tTime 0.155 (0.155)\tData 0.102 (0.102)\tLoss 0.5769 (0.5769)\tPrec 78.125% (78.125%)\n","Epoch: [15][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.5191 (0.5170)\tPrec 84.375% (81.884%)\n","Epoch: [15][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.6779 (0.5140)\tPrec 75.781% (82.090%)\n","Epoch: [15][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.4748 (0.5130)\tPrec 85.156% (82.068%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.6869 (0.6869)\tPrec 78.125% (78.125%)\n"," * Prec 75.710% \n","best acc: 77.910000\n","Epoch: [16][0/391]\tTime 0.142 (0.142)\tData 0.102 (0.102)\tLoss 0.4078 (0.4078)\tPrec 83.594% (83.594%)\n","Epoch: [16][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.4278 (0.4828)\tPrec 86.719% (83.184%)\n","Epoch: [16][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.4243 (0.4916)\tPrec 85.156% (82.762%)\n","Epoch: [16][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.6009 (0.4984)\tPrec 83.594% (82.574%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.6388 (0.6388)\tPrec 80.469% (80.469%)\n"," * Prec 79.350% \n","best acc: 79.350000\n","Epoch: [17][0/391]\tTime 0.152 (0.152)\tData 0.112 (0.112)\tLoss 0.4377 (0.4377)\tPrec 88.281% (88.281%)\n","Epoch: [17][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.4754 (0.4954)\tPrec 87.500% (82.689%)\n","Epoch: [17][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.5381 (0.4857)\tPrec 79.688% (83.077%)\n","Epoch: [17][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.6121 (0.4840)\tPrec 80.469% (83.147%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.5995 (0.5995)\tPrec 76.562% (76.562%)\n"," * Prec 73.570% \n","best acc: 79.350000\n","Epoch: [18][0/391]\tTime 0.143 (0.143)\tData 0.102 (0.102)\tLoss 0.4543 (0.4543)\tPrec 82.031% (82.031%)\n","Epoch: [18][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.4686 (0.4695)\tPrec 80.469% (83.679%)\n","Epoch: [18][200/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 0.4871 (0.4718)\tPrec 80.469% (83.582%)\n","Epoch: [18][300/391]\tTime 0.043 (0.033)\tData 0.001 (0.002)\tLoss 0.4631 (0.4739)\tPrec 82.031% (83.604%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.7847 (0.7847)\tPrec 72.656% (72.656%)\n"," * Prec 75.930% \n","best acc: 79.350000\n","Epoch: [19][0/391]\tTime 0.141 (0.141)\tData 0.099 (0.099)\tLoss 0.5303 (0.5303)\tPrec 82.812% (82.812%)\n","Epoch: [19][100/391]\tTime 0.042 (0.034)\tData 0.002 (0.002)\tLoss 0.4351 (0.4711)\tPrec 82.031% (83.470%)\n","Epoch: [19][200/391]\tTime 0.034 (0.035)\tData 0.001 (0.002)\tLoss 0.6024 (0.4694)\tPrec 78.906% (83.520%)\n","Epoch: [19][300/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.4859 (0.4612)\tPrec 83.594% (83.822%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.5482 (0.5482)\tPrec 82.031% (82.031%)\n"," * Prec 80.700% \n","best acc: 80.700000\n","Epoch: [20][0/391]\tTime 0.141 (0.141)\tData 0.101 (0.101)\tLoss 0.4940 (0.4940)\tPrec 82.812% (82.812%)\n","Epoch: [20][100/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 0.4545 (0.4579)\tPrec 85.156% (83.965%)\n","Epoch: [20][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3561 (0.4540)\tPrec 85.938% (84.289%)\n","Epoch: [20][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.4438 (0.4493)\tPrec 85.156% (84.375%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.5811 (0.5811)\tPrec 82.031% (82.031%)\n"," * Prec 81.050% \n","best acc: 81.050000\n","Epoch: [21][0/391]\tTime 0.141 (0.141)\tData 0.100 (0.100)\tLoss 0.5157 (0.5157)\tPrec 85.156% (85.156%)\n","Epoch: [21][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.002)\tLoss 0.4315 (0.4409)\tPrec 82.812% (84.708%)\n","Epoch: [21][200/391]\tTime 0.042 (0.033)\tData 0.001 (0.002)\tLoss 0.3831 (0.4489)\tPrec 89.062% (84.383%)\n","Epoch: [21][300/391]\tTime 0.032 (0.035)\tData 0.001 (0.002)\tLoss 0.5037 (0.4497)\tPrec 79.688% (84.339%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.5156 (0.5156)\tPrec 80.469% (80.469%)\n"," * Prec 80.180% \n","best acc: 81.050000\n","Epoch: [22][0/391]\tTime 0.156 (0.156)\tData 0.103 (0.103)\tLoss 0.5613 (0.5613)\tPrec 80.469% (80.469%)\n","Epoch: [22][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3701 (0.4285)\tPrec 89.062% (84.886%)\n","Epoch: [22][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3902 (0.4322)\tPrec 85.156% (84.698%)\n","Epoch: [22][300/391]\tTime 0.034 (0.032)\tData 0.002 (0.002)\tLoss 0.3049 (0.4351)\tPrec 86.719% (84.811%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4326 (0.4326)\tPrec 84.375% (84.375%)\n"," * Prec 81.010% \n","best acc: 81.050000\n","Epoch: [23][0/391]\tTime 0.146 (0.146)\tData 0.105 (0.105)\tLoss 0.3985 (0.3985)\tPrec 87.500% (87.500%)\n","Epoch: [23][100/391]\tTime 0.032 (0.036)\tData 0.002 (0.003)\tLoss 0.4289 (0.4249)\tPrec 85.156% (85.241%)\n","Epoch: [23][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.002)\tLoss 0.3525 (0.4272)\tPrec 88.281% (85.051%)\n","Epoch: [23][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.5556 (0.4290)\tPrec 78.906% (85.021%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.5696 (0.5696)\tPrec 82.031% (82.031%)\n"," * Prec 81.520% \n","best acc: 81.520000\n","Epoch: [24][0/391]\tTime 0.141 (0.141)\tData 0.100 (0.100)\tLoss 0.3181 (0.3181)\tPrec 89.062% (89.062%)\n","Epoch: [24][100/391]\tTime 0.043 (0.037)\tData 0.001 (0.002)\tLoss 0.5194 (0.4178)\tPrec 79.688% (85.690%)\n","Epoch: [24][200/391]\tTime 0.033 (0.035)\tData 0.001 (0.002)\tLoss 0.3874 (0.4116)\tPrec 86.719% (85.813%)\n","Epoch: [24][300/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.4280 (0.4161)\tPrec 86.719% (85.520%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.6688 (0.6688)\tPrec 76.562% (76.562%)\n"," * Prec 77.850% \n","best acc: 81.520000\n","Epoch: [25][0/391]\tTime 0.145 (0.145)\tData 0.104 (0.104)\tLoss 0.3778 (0.3778)\tPrec 85.156% (85.156%)\n","Epoch: [25][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.4465 (0.3931)\tPrec 85.938% (85.961%)\n","Epoch: [25][200/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 0.3985 (0.4091)\tPrec 88.281% (85.525%)\n","Epoch: [25][300/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.3826 (0.4094)\tPrec 88.281% (85.455%)\n","Validation starts\n","Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.5352 (0.5352)\tPrec 81.250% (81.250%)\n"," * Prec 81.090% \n","best acc: 81.520000\n","Epoch: [26][0/391]\tTime 0.144 (0.144)\tData 0.104 (0.104)\tLoss 0.4988 (0.4988)\tPrec 79.688% (79.688%)\n","Epoch: [26][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3926 (0.3899)\tPrec 88.281% (86.061%)\n","Epoch: [26][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.5505 (0.3975)\tPrec 80.469% (85.895%)\n","Epoch: [26][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.6510 (0.4020)\tPrec 81.250% (85.787%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.6360 (0.6360)\tPrec 78.125% (78.125%)\n"," * Prec 80.470% \n","best acc: 81.520000\n","Epoch: [27][0/391]\tTime 0.142 (0.142)\tData 0.102 (0.102)\tLoss 0.3583 (0.3583)\tPrec 85.938% (85.938%)\n","Epoch: [27][100/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.4509 (0.3887)\tPrec 84.375% (86.572%)\n","Epoch: [27][200/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.5375 (0.3847)\tPrec 80.469% (86.800%)\n","Epoch: [27][300/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.3177 (0.3868)\tPrec 90.625% (86.677%)\n","Validation starts\n","Test: [0/79]\tTime 0.089 (0.089)\tLoss 0.3151 (0.3151)\tPrec 89.062% (89.062%)\n"," * Prec 83.380% \n","best acc: 83.380000\n","Epoch: [28][0/391]\tTime 0.141 (0.141)\tData 0.102 (0.102)\tLoss 0.3414 (0.3414)\tPrec 89.062% (89.062%)\n","Epoch: [28][100/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3759 (0.3638)\tPrec 85.156% (87.067%)\n","Epoch: [28][200/391]\tTime 0.044 (0.032)\tData 0.001 (0.002)\tLoss 0.4298 (0.3805)\tPrec 82.812% (86.653%)\n","Epoch: [28][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.002)\tLoss 0.4357 (0.3823)\tPrec 80.469% (86.527%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.5666 (0.5666)\tPrec 82.031% (82.031%)\n"," * Prec 80.010% \n","best acc: 83.380000\n","Epoch: [29][0/391]\tTime 0.141 (0.141)\tData 0.100 (0.100)\tLoss 0.4106 (0.4106)\tPrec 86.719% (86.719%)\n","Epoch: [29][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3831 (0.3719)\tPrec 87.500% (87.129%)\n","Epoch: [29][200/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.3535 (0.3797)\tPrec 85.156% (86.839%)\n","Epoch: [29][300/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.3466 (0.3792)\tPrec 87.500% (86.823%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4391 (0.4391)\tPrec 85.938% (85.938%)\n"," * Prec 83.750% \n","best acc: 83.750000\n","Epoch: [30][0/391]\tTime 0.145 (0.145)\tData 0.101 (0.101)\tLoss 0.3466 (0.3466)\tPrec 89.062% (89.062%)\n","Epoch: [30][100/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.4292 (0.3807)\tPrec 85.156% (86.719%)\n","Epoch: [30][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.4203 (0.3757)\tPrec 84.375% (86.913%)\n","Epoch: [30][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3116 (0.3734)\tPrec 91.406% (87.090%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4133 (0.4133)\tPrec 85.938% (85.938%)\n"," * Prec 82.760% \n","best acc: 83.750000\n","Epoch: [31][0/391]\tTime 0.140 (0.140)\tData 0.099 (0.099)\tLoss 0.3789 (0.3789)\tPrec 85.156% (85.156%)\n","Epoch: [31][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3741 (0.3747)\tPrec 85.156% (86.796%)\n","Epoch: [31][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.5293 (0.3777)\tPrec 82.812% (86.863%)\n","Epoch: [31][300/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.4399 (0.3787)\tPrec 83.594% (86.771%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4845 (0.4845)\tPrec 85.156% (85.156%)\n"," * Prec 81.590% \n","best acc: 83.750000\n","Epoch: [32][0/391]\tTime 0.140 (0.140)\tData 0.100 (0.100)\tLoss 0.2490 (0.2490)\tPrec 95.312% (95.312%)\n","Epoch: [32][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.5144 (0.3560)\tPrec 82.812% (87.794%)\n","Epoch: [32][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3042 (0.3615)\tPrec 89.844% (87.523%)\n","Epoch: [32][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.4691 (0.3645)\tPrec 85.156% (87.349%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.4774 (0.4774)\tPrec 84.375% (84.375%)\n"," * Prec 81.630% \n","best acc: 83.750000\n","Epoch: [33][0/391]\tTime 0.141 (0.141)\tData 0.101 (0.101)\tLoss 0.3645 (0.3645)\tPrec 88.281% (88.281%)\n","Epoch: [33][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.4398 (0.3710)\tPrec 83.594% (87.067%)\n","Epoch: [33][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.4501 (0.3617)\tPrec 85.156% (87.298%)\n","Epoch: [33][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3431 (0.3633)\tPrec 85.938% (87.300%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.4618 (0.4618)\tPrec 82.812% (82.812%)\n"," * Prec 82.350% \n","best acc: 83.750000\n","Epoch: [34][0/391]\tTime 0.145 (0.145)\tData 0.104 (0.104)\tLoss 0.3201 (0.3201)\tPrec 88.281% (88.281%)\n","Epoch: [34][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.002)\tLoss 0.3269 (0.3470)\tPrec 86.719% (87.840%)\n","Epoch: [34][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.3520 (0.3595)\tPrec 87.500% (87.488%)\n","Epoch: [34][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.2713 (0.3539)\tPrec 90.625% (87.679%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.5209 (0.5209)\tPrec 83.594% (83.594%)\n"," * Prec 83.280% \n","best acc: 83.750000\n","Epoch: [35][0/391]\tTime 0.143 (0.143)\tData 0.102 (0.102)\tLoss 0.3492 (0.3492)\tPrec 86.719% (86.719%)\n","Epoch: [35][100/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.3155 (0.3471)\tPrec 88.281% (87.933%)\n","Epoch: [35][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.2254 (0.3490)\tPrec 90.625% (87.842%)\n","Epoch: [35][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3823 (0.3517)\tPrec 86.719% (87.736%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.4755 (0.4755)\tPrec 82.812% (82.812%)\n"," * Prec 81.860% \n","best acc: 83.750000\n","Epoch: [36][0/391]\tTime 0.140 (0.140)\tData 0.099 (0.099)\tLoss 0.2483 (0.2483)\tPrec 91.406% (91.406%)\n","Epoch: [36][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3066 (0.3350)\tPrec 87.500% (88.467%)\n","Epoch: [36][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3157 (0.3358)\tPrec 87.500% (88.219%)\n","Epoch: [36][300/391]\tTime 0.034 (0.033)\tData 0.002 (0.002)\tLoss 0.2702 (0.3406)\tPrec 89.844% (88.004%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.4659 (0.4659)\tPrec 82.031% (82.031%)\n"," * Prec 83.830% \n","best acc: 83.830000\n","Epoch: [37][0/391]\tTime 0.143 (0.143)\tData 0.103 (0.103)\tLoss 0.2354 (0.2354)\tPrec 92.969% (92.969%)\n","Epoch: [37][100/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3524 (0.3267)\tPrec 89.062% (88.134%)\n","Epoch: [37][200/391]\tTime 0.035 (0.032)\tData 0.002 (0.002)\tLoss 0.3093 (0.3334)\tPrec 89.844% (88.036%)\n","Epoch: [37][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.2508 (0.3398)\tPrec 90.625% (88.001%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.5067 (0.5067)\tPrec 83.594% (83.594%)\n"," * Prec 82.340% \n","best acc: 83.830000\n","Epoch: [38][0/391]\tTime 0.140 (0.140)\tData 0.100 (0.100)\tLoss 0.3570 (0.3570)\tPrec 88.281% (88.281%)\n","Epoch: [38][100/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.3684 (0.3283)\tPrec 87.500% (88.444%)\n","Epoch: [38][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.3617 (0.3313)\tPrec 84.375% (88.444%)\n","Epoch: [38][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.3237 (0.3371)\tPrec 88.281% (88.224%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4170 (0.4170)\tPrec 87.500% (87.500%)\n"," * Prec 85.260% \n","best acc: 85.260000\n","Epoch: [39][0/391]\tTime 0.142 (0.142)\tData 0.101 (0.101)\tLoss 0.2334 (0.2334)\tPrec 91.406% (91.406%)\n","Epoch: [39][100/391]\tTime 0.032 (0.035)\tData 0.001 (0.002)\tLoss 0.2787 (0.3174)\tPrec 91.406% (89.047%)\n","Epoch: [39][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.3116 (0.3253)\tPrec 90.625% (88.837%)\n","Epoch: [39][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.3218 (0.3327)\tPrec 86.719% (88.486%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4730 (0.4730)\tPrec 83.594% (83.594%)\n"," * Prec 79.840% \n","best acc: 85.260000\n","Epoch: [40][0/391]\tTime 0.147 (0.147)\tData 0.105 (0.105)\tLoss 0.2666 (0.2666)\tPrec 90.625% (90.625%)\n","Epoch: [40][100/391]\tTime 0.033 (0.034)\tData 0.001 (0.002)\tLoss 0.2765 (0.3216)\tPrec 91.406% (88.985%)\n","Epoch: [40][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.4092 (0.3184)\tPrec 86.719% (88.915%)\n","Epoch: [40][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3095 (0.3271)\tPrec 89.062% (88.543%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.4146 (0.4146)\tPrec 87.500% (87.500%)\n"," * Prec 84.970% \n","best acc: 85.260000\n","Epoch: [41][0/391]\tTime 0.143 (0.143)\tData 0.102 (0.102)\tLoss 0.3160 (0.3160)\tPrec 86.719% (86.719%)\n","Epoch: [41][100/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.2867 (0.3192)\tPrec 90.625% (88.653%)\n","Epoch: [41][200/391]\tTime 0.032 (0.035)\tData 0.001 (0.002)\tLoss 0.3870 (0.3233)\tPrec 87.500% (88.573%)\n","Epoch: [41][300/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.3311 (0.3255)\tPrec 89.844% (88.489%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.3897 (0.3897)\tPrec 84.375% (84.375%)\n"," * Prec 83.370% \n","best acc: 85.260000\n","Epoch: [42][0/391]\tTime 0.156 (0.156)\tData 0.104 (0.104)\tLoss 0.3740 (0.3740)\tPrec 83.594% (83.594%)\n","Epoch: [42][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.3321 (0.3013)\tPrec 89.844% (89.248%)\n","Epoch: [42][200/391]\tTime 0.032 (0.032)\tData 0.002 (0.002)\tLoss 0.2790 (0.3055)\tPrec 90.625% (89.269%)\n","Epoch: [42][300/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.3342 (0.3140)\tPrec 88.281% (88.995%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.5998 (0.5998)\tPrec 82.812% (82.812%)\n"," * Prec 81.320% \n","best acc: 85.260000\n","Epoch: [43][0/391]\tTime 0.142 (0.142)\tData 0.101 (0.101)\tLoss 0.3563 (0.3563)\tPrec 88.281% (88.281%)\n","Epoch: [43][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3034 (0.3100)\tPrec 90.625% (89.209%)\n","Epoch: [43][200/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.2392 (0.3073)\tPrec 92.969% (89.195%)\n","Epoch: [43][300/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.3261 (0.3146)\tPrec 88.281% (88.998%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.6579 (0.6579)\tPrec 80.469% (80.469%)\n"," * Prec 78.750% \n","best acc: 85.260000\n","Epoch: [44][0/391]\tTime 0.158 (0.158)\tData 0.105 (0.105)\tLoss 0.2701 (0.2701)\tPrec 90.625% (90.625%)\n","Epoch: [44][100/391]\tTime 0.031 (0.035)\tData 0.001 (0.003)\tLoss 0.2823 (0.3132)\tPrec 89.844% (89.093%)\n","Epoch: [44][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.002)\tLoss 0.3237 (0.3141)\tPrec 91.406% (89.090%)\n","Epoch: [44][300/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 0.5150 (0.3168)\tPrec 85.938% (89.011%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.4388 (0.4388)\tPrec 83.594% (83.594%)\n"," * Prec 83.280% \n","best acc: 85.260000\n","Epoch: [45][0/391]\tTime 0.141 (0.141)\tData 0.101 (0.101)\tLoss 0.2921 (0.2921)\tPrec 92.188% (92.188%)\n","Epoch: [45][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.2761 (0.2950)\tPrec 88.281% (89.689%)\n","Epoch: [45][200/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.3349 (0.3015)\tPrec 88.281% (89.463%)\n","Epoch: [45][300/391]\tTime 0.033 (0.032)\tData 0.002 (0.002)\tLoss 0.2720 (0.3073)\tPrec 90.625% (89.200%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.3755 (0.3755)\tPrec 85.938% (85.938%)\n"," * Prec 82.210% \n","best acc: 85.260000\n","Epoch: [46][0/391]\tTime 0.146 (0.146)\tData 0.105 (0.105)\tLoss 0.2456 (0.2456)\tPrec 92.188% (92.188%)\n","Epoch: [46][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3178 (0.2987)\tPrec 86.719% (89.418%)\n","Epoch: [46][200/391]\tTime 0.033 (0.032)\tData 0.001 (0.002)\tLoss 0.2087 (0.2978)\tPrec 92.969% (89.436%)\n","Epoch: [46][300/391]\tTime 0.042 (0.032)\tData 0.001 (0.002)\tLoss 0.3081 (0.3029)\tPrec 87.500% (89.397%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.3834 (0.3834)\tPrec 87.500% (87.500%)\n"," * Prec 84.010% \n","best acc: 85.260000\n","Epoch: [47][0/391]\tTime 0.141 (0.141)\tData 0.101 (0.101)\tLoss 0.3313 (0.3313)\tPrec 84.375% (84.375%)\n","Epoch: [47][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.3446 (0.2976)\tPrec 89.062% (89.527%)\n","Epoch: [47][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.2204 (0.2969)\tPrec 91.406% (89.673%)\n","Epoch: [47][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3555 (0.2950)\tPrec 85.938% (89.724%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4828 (0.4828)\tPrec 80.469% (80.469%)\n"," * Prec 83.750% \n","best acc: 85.260000\n","Epoch: [48][0/391]\tTime 0.143 (0.143)\tData 0.102 (0.102)\tLoss 0.2726 (0.2726)\tPrec 89.844% (89.844%)\n","Epoch: [48][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.2979 (0.2920)\tPrec 90.625% (89.712%)\n","Epoch: [48][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.2910 (0.2948)\tPrec 90.625% (89.669%)\n","Epoch: [48][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3202 (0.3014)\tPrec 85.938% (89.423%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.5225 (0.5225)\tPrec 82.812% (82.812%)\n"," * Prec 84.750% \n","best acc: 85.260000\n","Epoch: [49][0/391]\tTime 0.146 (0.146)\tData 0.105 (0.105)\tLoss 0.3355 (0.3355)\tPrec 90.625% (90.625%)\n","Epoch: [49][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.3218 (0.2976)\tPrec 88.281% (89.643%)\n","Epoch: [49][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.2420 (0.2950)\tPrec 91.406% (89.782%)\n","Epoch: [49][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.2855 (0.2992)\tPrec 88.281% (89.688%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.4863 (0.4863)\tPrec 85.938% (85.938%)\n"," * Prec 82.540% \n","best acc: 85.260000\n","Epoch: [50][0/391]\tTime 0.153 (0.153)\tData 0.101 (0.101)\tLoss 0.3306 (0.3306)\tPrec 89.062% (89.062%)\n","Epoch: [50][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.3710 (0.2878)\tPrec 88.281% (89.797%)\n","Epoch: [50][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.3104 (0.2962)\tPrec 88.281% (89.517%)\n","Epoch: [50][300/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.4631 (0.2996)\tPrec 82.812% (89.436%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3948 (0.3948)\tPrec 88.281% (88.281%)\n"," * Prec 85.250% \n","best acc: 85.260000\n","Epoch: [51][0/391]\tTime 0.142 (0.142)\tData 0.102 (0.102)\tLoss 0.3179 (0.3179)\tPrec 89.062% (89.062%)\n","Epoch: [51][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.2989 (0.2959)\tPrec 88.281% (89.356%)\n","Epoch: [51][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.2242 (0.2919)\tPrec 92.188% (89.486%)\n","Epoch: [51][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3990 (0.2936)\tPrec 86.719% (89.522%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4925 (0.4925)\tPrec 82.812% (82.812%)\n"," * Prec 84.120% \n","best acc: 85.260000\n","Epoch: [52][0/391]\tTime 0.141 (0.141)\tData 0.100 (0.100)\tLoss 0.2583 (0.2583)\tPrec 90.625% (90.625%)\n","Epoch: [52][100/391]\tTime 0.042 (0.034)\tData 0.002 (0.002)\tLoss 0.2558 (0.2960)\tPrec 89.844% (89.658%)\n","Epoch: [52][200/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.2991 (0.2952)\tPrec 90.625% (89.836%)\n","Epoch: [52][300/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.3574 (0.2921)\tPrec 82.812% (89.820%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.3452 (0.3452)\tPrec 85.938% (85.938%)\n"," * Prec 84.180% \n","best acc: 85.260000\n","Epoch: [53][0/391]\tTime 0.144 (0.144)\tData 0.102 (0.102)\tLoss 0.1815 (0.1815)\tPrec 93.750% (93.750%)\n","Epoch: [53][100/391]\tTime 0.042 (0.039)\tData 0.001 (0.003)\tLoss 0.2562 (0.2851)\tPrec 91.406% (89.952%)\n","Epoch: [53][200/391]\tTime 0.032 (0.037)\tData 0.001 (0.002)\tLoss 0.2591 (0.2924)\tPrec 88.281% (89.677%)\n","Epoch: [53][300/391]\tTime 0.031 (0.035)\tData 0.001 (0.002)\tLoss 0.2317 (0.2892)\tPrec 89.844% (89.875%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4896 (0.4896)\tPrec 83.594% (83.594%)\n"," * Prec 84.510% \n","best acc: 85.260000\n","Epoch: [54][0/391]\tTime 0.154 (0.154)\tData 0.100 (0.100)\tLoss 0.1935 (0.1935)\tPrec 92.188% (92.188%)\n","Epoch: [54][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.2951 (0.2750)\tPrec 89.844% (90.331%)\n","Epoch: [54][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.3964 (0.2773)\tPrec 85.938% (90.345%)\n","Epoch: [54][300/391]\tTime 0.034 (0.032)\tData 0.002 (0.002)\tLoss 0.2742 (0.2802)\tPrec 92.188% (90.153%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.4759 (0.4759)\tPrec 83.594% (83.594%)\n"," * Prec 84.200% \n","best acc: 85.260000\n","Epoch: [55][0/391]\tTime 0.141 (0.141)\tData 0.101 (0.101)\tLoss 0.3134 (0.3134)\tPrec 89.062% (89.062%)\n","Epoch: [55][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.003)\tLoss 0.4119 (0.2728)\tPrec 83.594% (90.447%)\n","Epoch: [55][200/391]\tTime 0.038 (0.033)\tData 0.001 (0.002)\tLoss 0.2037 (0.2729)\tPrec 92.188% (90.489%)\n","Epoch: [55][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.3353 (0.2797)\tPrec 85.156% (90.186%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.3360 (0.3360)\tPrec 88.281% (88.281%)\n"," * Prec 84.950% \n","best acc: 85.260000\n","Epoch: [56][0/391]\tTime 0.142 (0.142)\tData 0.101 (0.101)\tLoss 0.3417 (0.3417)\tPrec 86.719% (86.719%)\n","Epoch: [56][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.003)\tLoss 0.1415 (0.2856)\tPrec 96.094% (90.223%)\n","Epoch: [56][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.2325 (0.2800)\tPrec 90.625% (90.310%)\n","Epoch: [56][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.4948 (0.2780)\tPrec 86.719% (90.321%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4170 (0.4170)\tPrec 87.500% (87.500%)\n"," * Prec 84.170% \n","best acc: 85.260000\n","Epoch: [57][0/391]\tTime 0.144 (0.144)\tData 0.102 (0.102)\tLoss 0.1337 (0.1337)\tPrec 95.312% (95.312%)\n","Epoch: [57][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.2356 (0.2622)\tPrec 90.625% (90.571%)\n","Epoch: [57][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.2311 (0.2661)\tPrec 91.406% (90.563%)\n","Epoch: [57][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.2312 (0.2677)\tPrec 90.625% (90.526%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.5023 (0.5023)\tPrec 86.719% (86.719%)\n"," * Prec 84.090% \n","best acc: 85.260000\n","Epoch: [58][0/391]\tTime 0.145 (0.145)\tData 0.104 (0.104)\tLoss 0.2458 (0.2458)\tPrec 92.188% (92.188%)\n","Epoch: [58][100/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 0.3575 (0.2696)\tPrec 86.719% (90.184%)\n","Epoch: [58][200/391]\tTime 0.031 (0.032)\tData 0.002 (0.002)\tLoss 0.4037 (0.2661)\tPrec 83.594% (90.466%)\n","Epoch: [58][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.2614 (0.2708)\tPrec 91.406% (90.360%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.3146 (0.3146)\tPrec 86.719% (86.719%)\n"," * Prec 85.200% \n","best acc: 85.260000\n","Epoch: [59][0/391]\tTime 0.141 (0.141)\tData 0.100 (0.100)\tLoss 0.2297 (0.2297)\tPrec 90.625% (90.625%)\n","Epoch: [59][100/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 0.2694 (0.2588)\tPrec 93.750% (90.958%)\n","Epoch: [59][200/391]\tTime 0.031 (0.032)\tData 0.002 (0.002)\tLoss 0.2664 (0.2638)\tPrec 89.062% (90.625%)\n","Epoch: [59][300/391]\tTime 0.034 (0.032)\tData 0.002 (0.002)\tLoss 0.2272 (0.2672)\tPrec 92.188% (90.635%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.5230 (0.5230)\tPrec 85.938% (85.938%)\n"," * Prec 82.310% \n","best acc: 85.260000\n","Epoch: [60][0/391]\tTime 0.140 (0.140)\tData 0.100 (0.100)\tLoss 0.2788 (0.2788)\tPrec 88.281% (88.281%)\n","Epoch: [60][100/391]\tTime 0.042 (0.034)\tData 0.002 (0.003)\tLoss 0.2501 (0.2265)\tPrec 89.844% (92.172%)\n","Epoch: [60][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.002)\tLoss 0.1653 (0.2148)\tPrec 92.188% (92.642%)\n","Epoch: [60][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1696 (0.2103)\tPrec 96.875% (92.790%)\n","Validation starts\n","Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.2875 (0.2875)\tPrec 91.406% (91.406%)\n"," * Prec 88.420% \n","best acc: 88.420000\n","Epoch: [61][0/391]\tTime 0.141 (0.141)\tData 0.101 (0.101)\tLoss 0.1565 (0.1565)\tPrec 96.875% (96.875%)\n","Epoch: [61][100/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.1872 (0.1803)\tPrec 95.312% (93.889%)\n","Epoch: [61][200/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.1343 (0.1838)\tPrec 96.094% (93.797%)\n","Epoch: [61][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.2595 (0.1826)\tPrec 93.750% (93.760%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2856 (0.2856)\tPrec 90.625% (90.625%)\n"," * Prec 88.800% \n","best acc: 88.800000\n","Epoch: [62][0/391]\tTime 0.156 (0.156)\tData 0.103 (0.103)\tLoss 0.0869 (0.0869)\tPrec 99.219% (99.219%)\n","Epoch: [62][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.1426 (0.1695)\tPrec 96.094% (94.230%)\n","Epoch: [62][200/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 0.1392 (0.1723)\tPrec 96.875% (93.964%)\n","Epoch: [62][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.2534 (0.1729)\tPrec 89.062% (93.976%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2673 (0.2673)\tPrec 92.188% (92.188%)\n"," * Prec 88.910% \n","best acc: 88.910000\n","Epoch: [63][0/391]\tTime 0.147 (0.147)\tData 0.106 (0.106)\tLoss 0.1235 (0.1235)\tPrec 94.531% (94.531%)\n","Epoch: [63][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 0.1760 (0.1702)\tPrec 92.188% (94.199%)\n","Epoch: [63][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.002)\tLoss 0.1595 (0.1685)\tPrec 92.969% (94.248%)\n","Epoch: [63][300/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 0.1646 (0.1683)\tPrec 96.875% (94.243%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2306 (0.2306)\tPrec 91.406% (91.406%)\n"," * Prec 88.810% \n","best acc: 88.910000\n","Epoch: [64][0/391]\tTime 0.145 (0.145)\tData 0.105 (0.105)\tLoss 0.2614 (0.2614)\tPrec 87.500% (87.500%)\n","Epoch: [64][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1758 (0.1669)\tPrec 92.188% (94.168%)\n","Epoch: [64][200/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.2491 (0.1661)\tPrec 90.625% (94.216%)\n","Epoch: [64][300/391]\tTime 0.042 (0.033)\tData 0.001 (0.002)\tLoss 0.1213 (0.1648)\tPrec 96.875% (94.290%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2497 (0.2497)\tPrec 90.625% (90.625%)\n"," * Prec 88.870% \n","best acc: 88.910000\n","Epoch: [65][0/391]\tTime 0.146 (0.146)\tData 0.105 (0.105)\tLoss 0.1500 (0.1500)\tPrec 94.531% (94.531%)\n","Epoch: [65][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1342 (0.1595)\tPrec 96.094% (94.578%)\n","Epoch: [65][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1801 (0.1616)\tPrec 92.969% (94.465%)\n","Epoch: [65][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1016 (0.1625)\tPrec 96.094% (94.427%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2279 (0.2279)\tPrec 91.406% (91.406%)\n"," * Prec 89.050% \n","best acc: 89.050000\n","Epoch: [66][0/391]\tTime 0.147 (0.147)\tData 0.104 (0.104)\tLoss 0.1514 (0.1514)\tPrec 93.750% (93.750%)\n","Epoch: [66][100/391]\tTime 0.032 (0.039)\tData 0.002 (0.003)\tLoss 0.1001 (0.1593)\tPrec 96.875% (94.307%)\n","Epoch: [66][200/391]\tTime 0.033 (0.036)\tData 0.002 (0.002)\tLoss 0.2177 (0.1597)\tPrec 92.188% (94.368%)\n","Epoch: [66][300/391]\tTime 0.031 (0.038)\tData 0.001 (0.002)\tLoss 0.1288 (0.1600)\tPrec 96.094% (94.451%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2571 (0.2571)\tPrec 90.625% (90.625%)\n"," * Prec 88.880% \n","best acc: 89.050000\n","Epoch: [67][0/391]\tTime 0.141 (0.141)\tData 0.101 (0.101)\tLoss 0.1492 (0.1492)\tPrec 93.750% (93.750%)\n","Epoch: [67][100/391]\tTime 0.032 (0.035)\tData 0.001 (0.002)\tLoss 0.1147 (0.1620)\tPrec 96.094% (94.508%)\n","Epoch: [67][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.1705 (0.1575)\tPrec 93.750% (94.574%)\n","Epoch: [67][300/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 0.1510 (0.1582)\tPrec 96.094% (94.508%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.3067 (0.3067)\tPrec 89.062% (89.062%)\n"," * Prec 88.540% \n","best acc: 89.050000\n","Epoch: [68][0/391]\tTime 0.142 (0.142)\tData 0.101 (0.101)\tLoss 0.2047 (0.2047)\tPrec 90.625% (90.625%)\n","Epoch: [68][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.2081 (0.1529)\tPrec 92.188% (94.732%)\n","Epoch: [68][200/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.1627 (0.1522)\tPrec 95.312% (94.702%)\n","Epoch: [68][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1205 (0.1534)\tPrec 94.531% (94.614%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.3199 (0.3199)\tPrec 90.625% (90.625%)\n"," * Prec 89.230% \n","best acc: 89.230000\n","Epoch: [69][0/391]\tTime 0.143 (0.143)\tData 0.103 (0.103)\tLoss 0.1466 (0.1466)\tPrec 95.312% (95.312%)\n","Epoch: [69][100/391]\tTime 0.038 (0.033)\tData 0.002 (0.002)\tLoss 0.0903 (0.1533)\tPrec 96.875% (94.725%)\n","Epoch: [69][200/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.1073 (0.1510)\tPrec 96.094% (94.831%)\n","Epoch: [69][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1375 (0.1532)\tPrec 94.531% (94.757%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2623 (0.2623)\tPrec 92.969% (92.969%)\n"," * Prec 88.960% \n","best acc: 89.230000\n","Epoch: [70][0/391]\tTime 0.146 (0.146)\tData 0.104 (0.104)\tLoss 0.1377 (0.1377)\tPrec 94.531% (94.531%)\n","Epoch: [70][100/391]\tTime 0.032 (0.034)\tData 0.001 (0.003)\tLoss 0.1821 (0.1484)\tPrec 92.969% (94.918%)\n","Epoch: [70][200/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 0.1615 (0.1536)\tPrec 93.750% (94.694%)\n","Epoch: [70][300/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 0.1676 (0.1528)\tPrec 92.969% (94.721%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2982 (0.2982)\tPrec 92.969% (92.969%)\n"," * Prec 88.780% \n","best acc: 89.230000\n","Epoch: [71][0/391]\tTime 0.148 (0.148)\tData 0.106 (0.106)\tLoss 0.1246 (0.1246)\tPrec 96.875% (96.875%)\n","Epoch: [71][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.003)\tLoss 0.2150 (0.1490)\tPrec 89.062% (94.848%)\n","Epoch: [71][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1509 (0.1472)\tPrec 94.531% (94.885%)\n","Epoch: [71][300/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.1458 (0.1500)\tPrec 95.312% (94.786%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.3071 (0.3071)\tPrec 92.969% (92.969%)\n"," * Prec 88.720% \n","best acc: 89.230000\n","Epoch: [72][0/391]\tTime 0.157 (0.157)\tData 0.103 (0.103)\tLoss 0.1020 (0.1020)\tPrec 94.531% (94.531%)\n","Epoch: [72][100/391]\tTime 0.044 (0.040)\tData 0.001 (0.003)\tLoss 0.1164 (0.1373)\tPrec 96.094% (95.243%)\n","Epoch: [72][200/391]\tTime 0.033 (0.037)\tData 0.002 (0.002)\tLoss 0.1689 (0.1413)\tPrec 92.188% (95.114%)\n","Epoch: [72][300/391]\tTime 0.043 (0.037)\tData 0.001 (0.002)\tLoss 0.2277 (0.1437)\tPrec 90.625% (95.017%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2461 (0.2461)\tPrec 92.188% (92.188%)\n"," * Prec 88.860% \n","best acc: 89.230000\n","Epoch: [73][0/391]\tTime 0.147 (0.147)\tData 0.105 (0.105)\tLoss 0.1727 (0.1727)\tPrec 95.312% (95.312%)\n","Epoch: [73][100/391]\tTime 0.034 (0.034)\tData 0.002 (0.002)\tLoss 0.1314 (0.1485)\tPrec 95.312% (94.485%)\n","Epoch: [73][200/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.1074 (0.1488)\tPrec 96.094% (94.539%)\n","Epoch: [73][300/391]\tTime 0.037 (0.033)\tData 0.001 (0.002)\tLoss 0.1598 (0.1465)\tPrec 93.750% (94.721%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2906 (0.2906)\tPrec 92.969% (92.969%)\n"," * Prec 88.950% \n","best acc: 89.230000\n","Epoch: [74][0/391]\tTime 0.167 (0.167)\tData 0.108 (0.108)\tLoss 0.1786 (0.1786)\tPrec 95.312% (95.312%)\n","Epoch: [74][100/391]\tTime 0.033 (0.038)\tData 0.002 (0.003)\tLoss 0.1725 (0.1466)\tPrec 92.969% (94.980%)\n","Epoch: [74][200/391]\tTime 0.034 (0.035)\tData 0.001 (0.002)\tLoss 0.1664 (0.1477)\tPrec 95.312% (94.928%)\n","Epoch: [74][300/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.1906 (0.1473)\tPrec 92.969% (94.910%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2801 (0.2801)\tPrec 90.625% (90.625%)\n"," * Prec 88.970% \n","best acc: 89.230000\n","Epoch: [75][0/391]\tTime 0.157 (0.157)\tData 0.105 (0.105)\tLoss 0.0992 (0.0992)\tPrec 97.656% (97.656%)\n","Epoch: [75][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.003)\tLoss 0.0900 (0.1293)\tPrec 98.438% (95.823%)\n","Epoch: [75][200/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 0.0764 (0.1404)\tPrec 98.438% (95.235%)\n","Epoch: [75][300/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 0.1390 (0.1434)\tPrec 93.750% (95.045%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2915 (0.2915)\tPrec 90.625% (90.625%)\n"," * Prec 88.840% \n","best acc: 89.230000\n","Epoch: [76][0/391]\tTime 0.148 (0.148)\tData 0.106 (0.106)\tLoss 0.0970 (0.0970)\tPrec 97.656% (97.656%)\n","Epoch: [76][100/391]\tTime 0.033 (0.033)\tData 0.002 (0.003)\tLoss 0.1699 (0.1435)\tPrec 94.531% (94.988%)\n","Epoch: [76][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.002)\tLoss 0.2067 (0.1423)\tPrec 89.844% (94.990%)\n","Epoch: [76][300/391]\tTime 0.032 (0.035)\tData 0.002 (0.002)\tLoss 0.1716 (0.1426)\tPrec 93.750% (95.030%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.3239 (0.3239)\tPrec 89.062% (89.062%)\n"," * Prec 88.970% \n","best acc: 89.230000\n","Epoch: [77][0/391]\tTime 0.147 (0.147)\tData 0.105 (0.105)\tLoss 0.1995 (0.1995)\tPrec 93.750% (93.750%)\n","Epoch: [77][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.2102 (0.1411)\tPrec 92.969% (95.142%)\n","Epoch: [77][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.1599 (0.1432)\tPrec 92.188% (95.165%)\n","Epoch: [77][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.0757 (0.1396)\tPrec 99.219% (95.201%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3147 (0.3147)\tPrec 89.844% (89.844%)\n"," * Prec 89.150% \n","best acc: 89.230000\n","Epoch: [78][0/391]\tTime 0.146 (0.146)\tData 0.105 (0.105)\tLoss 0.1127 (0.1127)\tPrec 96.094% (96.094%)\n","Epoch: [78][100/391]\tTime 0.032 (0.035)\tData 0.001 (0.003)\tLoss 0.2313 (0.1397)\tPrec 91.406% (95.065%)\n","Epoch: [78][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.1379 (0.1401)\tPrec 96.094% (95.044%)\n","Epoch: [78][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1395 (0.1418)\tPrec 92.969% (95.022%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.2885 (0.2885)\tPrec 92.188% (92.188%)\n"," * Prec 88.730% \n","best acc: 89.230000\n","Epoch: [79][0/391]\tTime 0.145 (0.145)\tData 0.104 (0.104)\tLoss 0.2023 (0.2023)\tPrec 92.969% (92.969%)\n","Epoch: [79][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1735 (0.1353)\tPrec 93.750% (95.251%)\n","Epoch: [79][200/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.1573 (0.1350)\tPrec 94.531% (95.258%)\n","Epoch: [79][300/391]\tTime 0.041 (0.033)\tData 0.002 (0.002)\tLoss 0.0643 (0.1345)\tPrec 97.656% (95.312%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.2889 (0.2889)\tPrec 91.406% (91.406%)\n"," * Prec 88.910% \n","best acc: 89.230000\n","Epoch: [80][0/391]\tTime 0.142 (0.142)\tData 0.101 (0.101)\tLoss 0.0923 (0.0923)\tPrec 97.656% (97.656%)\n","Epoch: [80][100/391]\tTime 0.033 (0.035)\tData 0.001 (0.002)\tLoss 0.0513 (0.1310)\tPrec 98.438% (95.475%)\n","Epoch: [80][200/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.0898 (0.1310)\tPrec 98.438% (95.425%)\n","Epoch: [80][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1091 (0.1289)\tPrec 95.312% (95.497%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.2521 (0.2521)\tPrec 92.188% (92.188%)\n"," * Prec 89.430% \n","best acc: 89.430000\n","Epoch: [81][0/391]\tTime 0.156 (0.156)\tData 0.102 (0.102)\tLoss 0.1295 (0.1295)\tPrec 96.094% (96.094%)\n","Epoch: [81][100/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.1306 (0.1305)\tPrec 92.969% (95.421%)\n","Epoch: [81][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.2453 (0.1290)\tPrec 92.969% (95.553%)\n","Epoch: [81][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.1363 (0.1277)\tPrec 96.875% (95.621%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.2503 (0.2503)\tPrec 91.406% (91.406%)\n"," * Prec 89.350% \n","best acc: 89.430000\n","Epoch: [82][0/391]\tTime 0.146 (0.146)\tData 0.104 (0.104)\tLoss 0.1690 (0.1690)\tPrec 93.750% (93.750%)\n","Epoch: [82][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.1450 (0.1261)\tPrec 94.531% (95.668%)\n","Epoch: [82][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.0825 (0.1273)\tPrec 96.094% (95.690%)\n","Epoch: [82][300/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 0.1422 (0.1251)\tPrec 95.312% (95.751%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2918 (0.2918)\tPrec 91.406% (91.406%)\n"," * Prec 89.350% \n","best acc: 89.430000\n","Epoch: [83][0/391]\tTime 0.144 (0.144)\tData 0.103 (0.103)\tLoss 0.1569 (0.1569)\tPrec 95.312% (95.312%)\n","Epoch: [83][100/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.1397 (0.1233)\tPrec 95.312% (95.668%)\n","Epoch: [83][200/391]\tTime 0.035 (0.032)\tData 0.002 (0.002)\tLoss 0.1065 (0.1243)\tPrec 95.312% (95.725%)\n","Epoch: [83][300/391]\tTime 0.033 (0.032)\tData 0.001 (0.002)\tLoss 0.1033 (0.1243)\tPrec 96.875% (95.728%)\n","Validation starts\n","Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.2743 (0.2743)\tPrec 91.406% (91.406%)\n"," * Prec 89.580% \n","best acc: 89.580000\n","Epoch: [84][0/391]\tTime 0.148 (0.148)\tData 0.106 (0.106)\tLoss 0.2988 (0.2988)\tPrec 91.406% (91.406%)\n","Epoch: [84][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.1303 (0.1321)\tPrec 96.094% (95.367%)\n","Epoch: [84][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.1394 (0.1293)\tPrec 96.875% (95.515%)\n","Epoch: [84][300/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.1006 (0.1274)\tPrec 97.656% (95.562%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.2907 (0.2907)\tPrec 91.406% (91.406%)\n"," * Prec 89.170% \n","best acc: 89.580000\n","Epoch: [85][0/391]\tTime 0.143 (0.143)\tData 0.102 (0.102)\tLoss 0.1518 (0.1518)\tPrec 95.312% (95.312%)\n","Epoch: [85][100/391]\tTime 0.033 (0.033)\tData 0.002 (0.003)\tLoss 0.2005 (0.1261)\tPrec 92.188% (95.545%)\n","Epoch: [85][200/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.0937 (0.1275)\tPrec 97.656% (95.561%)\n","Epoch: [85][300/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 0.1029 (0.1267)\tPrec 96.094% (95.603%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2707 (0.2707)\tPrec 92.188% (92.188%)\n"," * Prec 89.420% \n","best acc: 89.580000\n","Epoch: [86][0/391]\tTime 0.144 (0.144)\tData 0.103 (0.103)\tLoss 0.1380 (0.1380)\tPrec 96.094% (96.094%)\n","Epoch: [86][100/391]\tTime 0.031 (0.035)\tData 0.001 (0.003)\tLoss 0.1834 (0.1212)\tPrec 89.844% (95.931%)\n","Epoch: [86][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1267 (0.1264)\tPrec 94.531% (95.794%)\n","Epoch: [86][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.1582 (0.1265)\tPrec 93.750% (95.749%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2677 (0.2677)\tPrec 92.969% (92.969%)\n"," * Prec 89.230% \n","best acc: 89.580000\n","Epoch: [87][0/391]\tTime 0.162 (0.162)\tData 0.109 (0.109)\tLoss 0.1891 (0.1891)\tPrec 94.531% (94.531%)\n","Epoch: [87][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1697 (0.1260)\tPrec 94.531% (95.808%)\n","Epoch: [87][200/391]\tTime 0.032 (0.032)\tData 0.001 (0.002)\tLoss 0.1041 (0.1237)\tPrec 96.094% (95.787%)\n","Epoch: [87][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.0788 (0.1223)\tPrec 98.438% (95.850%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2913 (0.2913)\tPrec 91.406% (91.406%)\n"," * Prec 89.430% \n","best acc: 89.580000\n","Epoch: [88][0/391]\tTime 0.144 (0.144)\tData 0.103 (0.103)\tLoss 0.2027 (0.2027)\tPrec 94.531% (94.531%)\n","Epoch: [88][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.003)\tLoss 0.1513 (0.1208)\tPrec 96.094% (96.063%)\n","Epoch: [88][200/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 0.1741 (0.1222)\tPrec 94.531% (95.938%)\n","Epoch: [88][300/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.0552 (0.1235)\tPrec 97.656% (95.852%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2931 (0.2931)\tPrec 91.406% (91.406%)\n"," * Prec 89.050% \n","best acc: 89.580000\n","Epoch: [89][0/391]\tTime 0.146 (0.146)\tData 0.104 (0.104)\tLoss 0.1198 (0.1198)\tPrec 96.094% (96.094%)\n","Epoch: [89][100/391]\tTime 0.043 (0.034)\tData 0.001 (0.002)\tLoss 0.1833 (0.1197)\tPrec 92.188% (95.931%)\n","Epoch: [89][200/391]\tTime 0.031 (0.037)\tData 0.001 (0.002)\tLoss 0.1081 (0.1203)\tPrec 96.094% (95.857%)\n","Epoch: [89][300/391]\tTime 0.031 (0.035)\tData 0.001 (0.002)\tLoss 0.1553 (0.1201)\tPrec 96.094% (95.907%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.2830 (0.2830)\tPrec 90.625% (90.625%)\n"," * Prec 89.440% \n","best acc: 89.580000\n","Epoch: [90][0/391]\tTime 0.142 (0.142)\tData 0.102 (0.102)\tLoss 0.1732 (0.1732)\tPrec 92.969% (92.969%)\n","Epoch: [90][100/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.1521 (0.1191)\tPrec 96.094% (96.071%)\n","Epoch: [90][200/391]\tTime 0.032 (0.035)\tData 0.001 (0.002)\tLoss 0.1569 (0.1227)\tPrec 96.094% (95.763%)\n","Epoch: [90][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.002)\tLoss 0.0737 (0.1232)\tPrec 98.438% (95.746%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.3339 (0.3339)\tPrec 89.062% (89.062%)\n"," * Prec 89.340% \n","best acc: 89.580000\n","Epoch: [91][0/391]\tTime 0.146 (0.146)\tData 0.106 (0.106)\tLoss 0.2112 (0.2112)\tPrec 90.625% (90.625%)\n","Epoch: [91][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.002)\tLoss 0.0881 (0.1212)\tPrec 97.656% (95.908%)\n","Epoch: [91][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.1132 (0.1196)\tPrec 95.312% (95.965%)\n","Epoch: [91][300/391]\tTime 0.033 (0.032)\tData 0.002 (0.002)\tLoss 0.0686 (0.1223)\tPrec 98.438% (95.790%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.3281 (0.3281)\tPrec 90.625% (90.625%)\n"," * Prec 89.440% \n","best acc: 89.580000\n","Epoch: [92][0/391]\tTime 0.158 (0.158)\tData 0.105 (0.105)\tLoss 0.1380 (0.1380)\tPrec 97.656% (97.656%)\n","Epoch: [92][100/391]\tTime 0.032 (0.035)\tData 0.001 (0.003)\tLoss 0.1220 (0.1263)\tPrec 93.750% (95.622%)\n","Epoch: [92][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1504 (0.1234)\tPrec 93.750% (95.732%)\n","Epoch: [92][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1145 (0.1240)\tPrec 96.875% (95.746%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2902 (0.2902)\tPrec 91.406% (91.406%)\n"," * Prec 89.310% \n","best acc: 89.580000\n","Epoch: [93][0/391]\tTime 0.145 (0.145)\tData 0.103 (0.103)\tLoss 0.0720 (0.0720)\tPrec 96.875% (96.875%)\n","Epoch: [93][100/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.1295 (0.1271)\tPrec 94.531% (95.730%)\n","Epoch: [93][200/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.0960 (0.1249)\tPrec 97.656% (95.678%)\n","Epoch: [93][300/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.1535 (0.1247)\tPrec 94.531% (95.637%)\n","Validation starts\n","Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.3282 (0.3282)\tPrec 91.406% (91.406%)\n"," * Prec 89.450% \n","best acc: 89.580000\n","Epoch: [94][0/391]\tTime 0.148 (0.148)\tData 0.106 (0.106)\tLoss 0.1305 (0.1305)\tPrec 94.531% (94.531%)\n","Epoch: [94][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.002)\tLoss 0.0863 (0.1170)\tPrec 98.438% (96.117%)\n","Epoch: [94][200/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.1798 (0.1164)\tPrec 92.969% (96.113%)\n","Epoch: [94][300/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.1679 (0.1203)\tPrec 93.750% (95.956%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2760 (0.2760)\tPrec 92.188% (92.188%)\n"," * Prec 89.250% \n","best acc: 89.580000\n","Epoch: [95][0/391]\tTime 0.156 (0.156)\tData 0.102 (0.102)\tLoss 0.1527 (0.1527)\tPrec 93.750% (93.750%)\n","Epoch: [95][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.1042 (0.1186)\tPrec 95.312% (95.955%)\n","Epoch: [95][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.0991 (0.1214)\tPrec 97.656% (95.853%)\n","Epoch: [95][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1594 (0.1221)\tPrec 93.750% (95.837%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.3152 (0.3152)\tPrec 91.406% (91.406%)\n"," * Prec 89.140% \n","best acc: 89.580000\n","Epoch: [96][0/391]\tTime 0.145 (0.145)\tData 0.104 (0.104)\tLoss 0.0747 (0.0747)\tPrec 98.438% (98.438%)\n","Epoch: [96][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.0731 (0.1228)\tPrec 97.656% (95.815%)\n","Epoch: [96][200/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.1611 (0.1247)\tPrec 97.656% (95.728%)\n","Epoch: [96][300/391]\tTime 0.034 (0.032)\tData 0.002 (0.002)\tLoss 0.1159 (0.1234)\tPrec 95.312% (95.725%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.3069 (0.3069)\tPrec 90.625% (90.625%)\n"," * Prec 89.290% \n","best acc: 89.580000\n","Epoch: [97][0/391]\tTime 0.156 (0.156)\tData 0.103 (0.103)\tLoss 0.1252 (0.1252)\tPrec 95.312% (95.312%)\n","Epoch: [97][100/391]\tTime 0.032 (0.034)\tData 0.001 (0.002)\tLoss 0.1612 (0.1159)\tPrec 92.969% (95.916%)\n","Epoch: [97][200/391]\tTime 0.033 (0.033)\tData 0.001 (0.002)\tLoss 0.0996 (0.1166)\tPrec 96.094% (95.911%)\n","Epoch: [97][300/391]\tTime 0.032 (0.033)\tData 0.001 (0.002)\tLoss 0.1134 (0.1164)\tPrec 97.656% (95.985%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.2933 (0.2933)\tPrec 91.406% (91.406%)\n"," * Prec 89.320% \n","best acc: 89.580000\n","Epoch: [98][0/391]\tTime 0.145 (0.145)\tData 0.104 (0.104)\tLoss 0.1389 (0.1389)\tPrec 94.531% (94.531%)\n","Epoch: [98][100/391]\tTime 0.032 (0.033)\tData 0.001 (0.003)\tLoss 0.0864 (0.1180)\tPrec 96.875% (95.900%)\n","Epoch: [98][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.0747 (0.1191)\tPrec 99.219% (95.880%)\n","Epoch: [98][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.1046 (0.1192)\tPrec 96.875% (95.917%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2751 (0.2751)\tPrec 91.406% (91.406%)\n"," * Prec 89.420% \n","best acc: 89.580000\n","Epoch: [99][0/391]\tTime 0.142 (0.142)\tData 0.102 (0.102)\tLoss 0.0936 (0.0936)\tPrec 97.656% (97.656%)\n","Epoch: [99][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.002)\tLoss 0.0789 (0.1208)\tPrec 96.875% (95.893%)\n","Epoch: [99][200/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 0.0852 (0.1211)\tPrec 98.438% (95.896%)\n","Epoch: [99][300/391]\tTime 0.031 (0.032)\tData 0.001 (0.002)\tLoss 0.2105 (0.1213)\tPrec 91.406% (95.850%)\n","Validation starts\n","Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.3229 (0.3229)\tPrec 91.406% (91.406%)\n"," * Prec 89.200% \n","best acc: 89.580000\n"]}],"source":["# This cell won't be given, but students will complete the training\n","\n","lr = 4e-2\n","weight_decay = 1e-4\n","epochs = 100\n","best_prec = 0\n","\n","#model = nn.DataParallel(model).cuda()\n","model.cuda()\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n","#cudnn.benchmark = True\n","\n","if not os.path.exists('result'):\n","    os.makedirs('result')\n","fdir = 'result/'+str(model_name)\n","if not os.path.exists(fdir):\n","    os.makedirs(fdir)\n","\n","\n","for epoch in range(0, epochs):\n","    adjust_learning_rate(optimizer, epoch)\n","\n","    train(trainloader, model, criterion, optimizer, epoch)\n","\n","    # evaluate on test set\n","    print(\"Validation starts\")\n","    prec = validate(testloader, model, criterion)\n","\n","    # remember best precision and save checkpoint\n","    is_best = prec > best_prec\n","    best_prec = max(prec,best_prec)\n","    print('best acc: {:1f}'.format(best_prec))\n","    save_checkpoint({\n","        'epoch': epoch + 1,\n","        'state_dict': model.state_dict(),\n","        'best_prec': best_prec,\n","        'optimizer': optimizer.state_dict(),\n","    }, is_best, fdir)"]},{"cell_type":"code","execution_count":4,"id":"entertaining-queensland","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"entertaining-queensland","executionInfo":{"status":"ok","timestamp":1764722011402,"user_tz":480,"elapsed":1361,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"86c3c612-5906-4494-f680-87d3c89e48fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Accuracy: 8958/10000 (90%)\n","\n"]}],"source":["PATH = \"/content/result/ResNet20_project/model_best.pth.tar\"\n","model_name = \"ResNet20_project\"\n","model = resnet20_internal_8x8()\n","checkpoint = torch.load(PATH)\n","model.load_state_dict(checkpoint['state_dict'])\n","device = torch.device(\"cuda\")\n","\n","model.cuda()\n","model.eval()\n","\n","test_loss = 0\n","correct = 0\n","\n","with torch.no_grad():\n","    for data, target in testloader:\n","        data, target = data.to(device), target.to(device) # loading to GPU\n","        output = model(data)\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","test_loss /= len(testloader.dataset)\n","\n","print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        correct, len(testloader.dataset),\n","        100. * correct / len(testloader.dataset)))"]},{"cell_type":"code","execution_count":10,"id":"ceramic-nigeria","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ceramic-nigeria","executionInfo":{"status":"ok","timestamp":1764722609277,"user_tz":480,"elapsed":111,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"2a9d593d-c3d9-424a-b31a-ac45867e2901","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Registering hooks...\n","Captured 22 layer inputs.\n","\n","--- Data Shapes ---\n","Input:  torch.Size([128, 8, 16, 16])\n","Weight: torch.Size([8, 8, 3, 3])\n","Ref:    torch.Size([128, 8, 16, 16])\n","\n","--- Integer Check ---\n","x_int sample: [9.0, 4.0, 4.0, 3.000000238418579, 3.000000238418579]\n","w_int sample: [4.999999523162842, 2.0, 0.0]\n","\n","--- Verification Result ---\n","Mean Difference: 1.0696428489609389e-06\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class SaveOutput:\n","    def __init__(self):\n","        self.outputs = []\n","\n","    def __call__(self, module, module_in):\n","        self.outputs.append(module_in[0])\n","\n","    def clear(self):\n","        self.outputs = []\n","\n","save_output = SaveOutput()\n","hook_handles = []\n","\n","print(\"Registering hooks...\")\n","for i, m in enumerate(model.modules()):\n","    if isinstance(m, QuantConv2d):\n","        handle = m.register_forward_pre_hook(save_output)\n","        hook_handles.append(handle)\n","\n","\n","model.eval()\n","model.cuda()\n","\n","\n","dataiter = iter(testloader)\n","images, labels = next(dataiter)\n","images = images.cuda()\n","\n","save_output.clear()\n","\n","with torch.no_grad():\n","    _ = model(images)\n","\n","print(f\"Captured {len(save_output.outputs)} layer inputs.\")\n","\n","\n","input_idx = 10\n","ref_idx = 11\n","\n","x_raw = save_output.outputs[input_idx].detach()\n","\n","\n","target_layer = model.layer2[1].conv1\n","weight_q = target_layer.weight_q.detach()\n","\n","\n","output_ref = save_output.outputs[ref_idx].detach()\n","\n","print(f\"\\n--- Data Shapes ---\")\n","print(f\"Input:  {x_raw.shape}\")\n","print(f\"Weight: {weight_q.shape}\")\n","print(f\"Ref:    {output_ref.shape}\")\n","\n","\n","x_bit = 4\n","w_bit = 4\n","\n","x_alpha = target_layer.act_alpha.detach()\n","x_delta = x_alpha / (2**x_bit - 1)\n","\n","act_quant_fn = act_quantization(x_bit)\n","x_quantized_float = act_quant_fn(x_raw, x_alpha)\n","x_int = x_quantized_float / x_delta\n","\n","\n","w_alpha = target_layer.weight_quant.wgt_alpha.detach()\n","w_delta = w_alpha / (2**(w_bit - 1) - 1)\n","w_int = weight_q / w_delta\n","\n","print(f\"\\n--- Integer Check ---\")\n","print(f\"x_int sample: {x_int[0,0,0,:5].tolist()}\")\n","print(f\"w_int sample: {w_int[0,0,0,:5].tolist()}\")\n","\n","\n","sim_conv = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, padding=1, bias=False).cuda()\n","sim_conv.weight = nn.Parameter(w_int)\n","\n","output_int = sim_conv(x_int)\n","\n","output_recovered = output_int * x_delta * w_delta\n","output_simulated = F.relu(output_recovered)\n","\n","difference = (output_simulated - output_ref).abs()\n","mean_error = difference.mean().item()\n","\n","print(f\"\\n--- Verification Result ---\")\n","print(f\"Mean Difference: {mean_error}\")\n","\n","\n","\n","for h in hook_handles:\n","    h.remove()\n","save_output.clear()"]},{"cell_type":"code","execution_count":null,"id":"significant-whole","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"significant-whole","executionInfo":{"status":"ok","timestamp":1764043241170,"user_tz":480,"elapsed":21,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"66275cc5-3687-44fe-974e-f2a0585233c5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 36])"]},"metadata":{},"execution_count":46}],"source":["x_pad = torch.zeros(128, 8, 6, 6).to(x_int.device)\n","x_pad[:, :, 1:5, 1:5] = x_int\n","X = x_pad[0]\n","X = X.reshape(X.size(0), -1)\n","X.size()"]},{"cell_type":"code","execution_count":null,"id":"corresponding-significance","metadata":{"id":"corresponding-significance"},"outputs":[],"source":["tile_id = 0\n","nij = 200 # just a random number\n","#X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n","\n","bit_precision = 4\n","file = open('activation.txt', 'w') #write to file\n","file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n","file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n","file.write('#................#\\n')\n","\n","for i in range(X.size(1)):  # time step\n","    for j in range(X.size(0)): # row #\n","        X_bin = '{0:04b}'.format(int(X[7-j,i].item()+0.001))\n","        for k in range(bit_precision):\n","            file.write(X_bin[k])\n","        #file.write(' ')  # for visibility with blank between words, you can use\n","    file.write('\\n')\n","file.close() #close file"]},{"cell_type":"code","source":["print(weight_int.size())\n","W = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))\n","print(W.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-anPbG6Kl6z","executionInfo":{"status":"ok","timestamp":1764043245530,"user_tz":480,"elapsed":14,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"bb5094ac-5b0e-45be-d037-165686b5a9db"},"id":"P-anPbG6Kl6z","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 8, 3, 3])\n","torch.Size([8, 8, 9])\n"]}]},{"cell_type":"code","source":["\n","bit_precision = 4\n","file = open('weight.txt', 'w') #write to file\n","file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n","file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n","file.write('#................#\\n')\n","for kij in range(9):\n","    for i in range(W.size(0)):\n","        for j in range(W.size(1)):\n","            if (W[i, 7-j, kij].item()<0):\n","                W_bin = '{0:04b}'.format(int(W[i,7-j,kij].item()+2**bit_precision+0.001))\n","            else:\n","                W_bin = '{0:04b}'.format(int(W[i,7-j,kij].item()+0.001))\n","            for k in range(bit_precision):\n","                file.write(W_bin[k])\n","            #file.write(' ')  # for visibility with blank between words, you can use\n","        file.write('\\n')\n","file.close() #close file"],"metadata":{"id":"W0o2upN-KvJm"},"id":"W0o2upN-KvJm","execution_count":null,"outputs":[]},{"cell_type":"code","source":["W[0,:,0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxR9Na_VLDAp","executionInfo":{"status":"ok","timestamp":1764043249145,"user_tz":480,"elapsed":14,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"960885ad-b067-4201-9136-c53803f1bb5b"},"id":"pxR9Na_VLDAp","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-5.0000, -0.0000,  2.0000,  7.0000,  7.0000,  3.0000, -3.0000,  2.0000],\n","       device='cuda:0', grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["p_nijg = range(X.size(1)) ## psum nij group\n","psum = torch.zeros(8, len(p_nijg), 9).cuda()\n","for kij in range(9):\n","    for nij in p_nijg:       # time domain, sequentially given input\n","        m = nn.Linear(8, 8, bias=False)\n","        m.weight = torch.nn.Parameter(W[:,:,kij])\n","        psum[:, nij, kij] = m(X[:,nij]).cuda()\n","bit_precision = 16\n","file = open('psum.txt', 'w') #write to file\n","file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n","file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n","file.write('#................#\\n')\n","for kij in range(9):\n","    for i in range(psum.size(1)):\n","        for j in range(psum.size(0)):\n","            if (psum[7-j,i,kij].item()<0):\n","                P_bin = '{0:016b}'.format(int(psum[7-j,i,kij].item()+2**bit_precision+0.001))\n","            else:\n","                P_bin = '{0:016b}'.format(int(psum[7-j,i,kij].item()+0.001))\n","            for k in range(bit_precision):\n","                file.write(P_bin[k])\n","            #file.write(' ')  # for visibility with blank between words, you can use\n","        file.write('\\n')\n","file.close()"],"metadata":{"id":"4jMH_fdkLJtd"},"id":"4jMH_fdkLJtd","execution_count":null,"outputs":[]},{"cell_type":"code","source":["out = relu(output_int[0])\n","out = torch.reshape(out, (out.size(0), -1))\n","bit_precision = 16\n","file = open('output.txt', 'w') #write to file\n","file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n","file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n","file.write('#................#\\n')\n","\n","for i in range(out.size(1)):\n","    for j in range(out.size(0)):\n","        if (out[7-j,i].item()<0):\n","            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+2**bit_precision+0.001))\n","        else:\n","            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+0.001))\n","        for k in range(bit_precision):\n","            file.write(O_bin[k])\n","        #file.write(' ')  # for visibility with blank between words, you can use\n","    file.write('\\n')\n","file.close()"],"metadata":{"id":"_1SmPoKDMmpE"},"id":"_1SmPoKDMmpE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import math\n","\n","# ======================\n","# 1.  activation.txt  x_pad[0]\n","# ======================\n","\n","def read_activation_txt(path, C_in=8):\n","    lines = []\n","    with open(path, 'r') as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line or line.startswith('#'):\n","                continue\n","            lines.append(line)\n","\n","    T = len(lines)                 # time steps = \n","    X = torch.zeros(C_in, T, dtype=torch.int32)\n","\n","    for t, line in enumerate(lines):\n","        # : ch7(4bit) ch6(4bit) ... ch0(4bit)   8*4 = 32 bit\n","        assert len(line) >= C_in * 4, f\"activation line too short: {len(line)} bits\"\n","\n","        for c in range(C_in):\n","            group_idx = 7 - c      #  X[7-j,i] group=7-c\n","            start = group_idx * 4\n","            bits = line[start:start+4]\n","            val = int(bits, 2)     #  4bitReLU \n","            X[c, t] = val\n","\n","    # : T = H_pad * W_pad\n","    H_pad = int(math.sqrt(T))\n","    W_pad = H_pad\n","    assert H_pad * W_pad == T, f\"activation T={T}  sqrt \"\n","\n","    x_pad_0 = X.view(C_in, H_pad, W_pad)  # [C_in, H_pad, W_pad]\n","    return x_pad_0\n","\n","\n","# ======================\n","# 2.  weight.txt  weight_int\n","# ======================\n","\n","def read_weight_txt(path, C_in=8, K=3):\n","    lines = []\n","    with open(path, 'r') as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line or line.startswith('#'):\n","                continue\n","            lines.append(line)\n","\n","    total_lines = len(lines)\n","    K2 = K * K                      # 3x3  9\n","    assert total_lines % K2 == 0, \"weight.txt  9 \"\n","\n","    C_out = total_lines // K2       #  kij  C_out \n","    W = torch.zeros(C_out, C_in, K2, dtype=torch.int32)  # [oc, ic, kij]\n","\n","    for kij in range(K2):\n","        for oc in range(C_out):\n","            line_idx = kij * C_out + oc\n","            line = lines[line_idx]\n","            assert len(line) >= C_in * 4, f\"weight line too short: {len(line)} bits\"\n","\n","            for ic in range(C_in):\n","                group_idx = 7 - ic       #  W[i,7-j,kij]group = j  ic = 7-j\n","                start = group_idx * 4\n","                bits = line[start:start+4]\n","                v_u = int(bits, 2)       # 0..15\n","\n","                # 4-bit   \n","                if v_u >= 8:\n","                    v = v_u - 16\n","                else:\n","                    v = v_u\n","\n","                W[oc, ic, kij] = v\n","\n","    #  [C_out, C_in, K, K]\n","    weight_int = W.view(C_out, C_in, K, K)\n","    return weight_int\n","\n","\n","# ======================\n","# 3.  output.txt  output_int[0]\n","# ======================\n","\n","def read_output_txt(path, C_out=8):\n","    lines = []\n","    with open(path, 'r') as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line or line.startswith('#'):\n","                continue\n","            lines.append(line)\n","\n","    T = len(lines)                  #  (4x4=16)\n","    out_flat = torch.zeros(C_out, T, dtype=torch.int32)\n","\n","    for t, line in enumerate(lines):\n","        assert len(line) >= C_out * 16, f\"output line too short: {len(line)} bits\"\n","        for oc in range(C_out):\n","            group_idx = 7 - oc      #  out[7-j,i] group=7-oc\n","            start = group_idx * 16\n","            bits = line[start:start+16]\n","            v_u = int(bits, 2)      #  16-bit\n","\n","            # 16-bit \n","            if v_u >= 2**15:\n","                v = v_u - 2**16\n","            else:\n","                v = v_u\n","\n","            out_flat[oc, t] = v\n","\n","    #  H_out x W_out 4x4 sqrt\n","    H_out = int(math.sqrt(T))\n","    W_out = H_out\n","    assert H_out * W_out == T, f\"output T={T}  sqrt \"\n","\n","    out_0 = out_flat.view(C_out, H_out, W_out)  # [C_out, H_out, W_out]\n","    return out_0\n","\n","\n","# ======================\n","# 4.  x_pad_0  weight_int  3x3 conv\n","# ======================\n","\n","def manual_conv_3x3_stride1_pad1_from_xpad(x_pad_0, weight_int):\n","    \"\"\"\n","    x_pad_0: [C_in, H_pad, W_pad] ( 8x6x6)\n","    weight_int: [C_out, C_in, 3, 3]\n","    return: [C_out, H_out, W_out] = [C_out, H_pad-2, W_pad-2]\n","    \"\"\"\n","    C_in = x_pad_0.size(0)\n","    C_out = weight_int.size(0)\n","    Kh = Kw = 3\n","    H_pad, W_pad = x_pad_0.size(1), x_pad_0.size(2)\n","    H_out, W_out = H_pad - Kh + 1, W_pad - Kw + 1\n","\n","    out = torch.zeros(C_out, H_out, W_out, dtype=torch.int32)\n","\n","    for oc in range(C_out):\n","        for h in range(H_out):\n","            for w in range(W_out):\n","                acc = 0\n","                for ic in range(C_in):\n","                    for kh in range(Kh):\n","                        for kw in range(Kw):\n","                            acc += int(x_pad_0[ic, h+kh, w+kw].item()) * \\\n","                                   int(weight_int[oc, ic, kh, kw].item())\n","                out[oc, h, w] = acc\n","\n","    return out\n","\n","\n","# ======================\n","# 5.  txt     output.txt\n","# ======================\n","\n","act_path = \"activation.txt\"\n","wgt_path = \"weight.txt\"\n","out_path = \"output.txt\"\n","\n","x_pad_0 = read_activation_txt(act_path, C_in=8)\n","weight_int = read_weight_txt(wgt_path, C_in=8, K=3)\n","out_from_txt = read_output_txt(out_path, C_out=8)\n","\n","print(\"x_pad_0 shape:\", x_pad_0.shape)       #  [8,6,6]\n","print(\"weight_int shape:\", weight_int.shape) #  [8,8,3,3]\n","print(\"out_from_txt shape:\", out_from_txt.shape)  #  [8,4,4]\n","\n","out_manual = manual_conv_3x3_stride1_pad1_from_xpad(x_pad_0, weight_int)\n","\n","diff = (out_manual.to(torch.int32) - out_from_txt.to(torch.int32)).abs()\n","print(\"max abs diff:\", diff.max().item())\n","print(\"all equal?:\", bool(torch.all(diff == 0)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zl3e0iLvNkd1","executionInfo":{"status":"ok","timestamp":1764044495084,"user_tz":480,"elapsed":139,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"197ceafe-50c1-4448-b921-6711ac51f7d9"},"id":"zl3e0iLvNkd1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_pad_0 shape: torch.Size([8, 6, 6])\n","weight_int shape: torch.Size([8, 8, 3, 3])\n","out_from_txt shape: torch.Size([8, 4, 4])\n","max abs diff: 411\n","all equal?: False\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"vscode":{"interpreter":{"hash":"907cbb87cc825d52daa26d94a4f3471be4a7efbfbc56d778ed32b1cc3c9bdcfc"}},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}