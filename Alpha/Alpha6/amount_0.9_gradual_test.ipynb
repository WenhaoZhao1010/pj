{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee6b148-b045-4127-8ae6-78045666c652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [01:59<00:00, 1431493.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "============================================================\n",
      "1. 原始模型（无剪枝）测试\n",
      "============================================================\n",
      "Test: [0/79]\tTime 0.693 (0.693)\tLoss 0.3867 (0.3867)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.670% \n",
      "全模型 - Total params: 14710464, Zero params: 0, Sparsity: 0.00%\n",
      "QuantConv2d层 - Total params: 14710464, Zero params: 0, Sparsity: 0.00%\n",
      "\n",
      "============================================================\n",
      "2. 分3次渐进式剪枝模型测试 (目标稀疏度: 90%)\n",
      "============================================================\n",
      "Test: [0/79]\tTime 0.376 (0.376)\tLoss 1.0111 (1.0111)\tPrec 67.969% (67.969%)\n",
      " * Prec 61.430% \n",
      "全模型 - Total params: 14710464, Zero params: 13239416, Sparsity: 90.00%\n",
      "QuantConv2d层 - Total params: 14710464, Zero params: 13239416, Sparsity: 90.00%\n",
      "精度下降: 27.24%\n",
      "\n",
      "============================================================\n",
      "3. 分6次渐进式剪枝模型测试 (目标稀疏度: 90%)\n",
      "============================================================\n",
      "Test: [0/79]\tTime 0.267 (0.267)\tLoss 0.7874 (0.7874)\tPrec 73.438% (73.438%)\n",
      " * Prec 70.330% \n",
      "全模型 - Total params: 14710464, Zero params: 13239416, Sparsity: 90.00%\n",
      "QuantConv2d层 - Total params: 14710464, Zero params: 13239416, Sparsity: 90.00%\n",
      "精度下降: 18.34%\n"
     ]
    }
   ],
   "source": [
    "# %load 渐进式剪枝测试_0.9.py\n",
    "# 渐进式剪枝测试 - 目标稀疏度 90%\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from vgg_quant import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "model_1 = VGG16_quant()\n",
    "model_2 = VGG16_quant()\n",
    "model_3 = VGG16_quant()\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print_freq = 100\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                       i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                       top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "\n",
    "def count_zeros_quant_only(model):\n",
    "    \"\"\"只统计 QuantConv2d 层的稀疏度\"\"\"\n",
    "    total = 0\n",
    "    zeros = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantConv2d):\n",
    "            weight = module.weight.data.cpu().numpy()\n",
    "            total += weight.size\n",
    "            zeros += (weight == 0).sum()\n",
    "    return total, zeros, zeros / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def count_zeros_quant_only(model):\n",
    "    \"\"\"只统计 QuantConv2d 层的稀疏度\"\"\"\n",
    "    total = 0\n",
    "    zeros = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantConv2d):\n",
    "            weight = module.weight.data.cpu().numpy()\n",
    "            total += weight.size\n",
    "            zeros += (weight == 0).sum()\n",
    "    return total, zeros, zeros / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def load_pruned_state_dict(model, state_dict):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for key, value in state_dict.items():\n",
    "        if key.endswith('_orig'):\n",
    "            base_key = key[:-5]\n",
    "            mask_key = base_key + '_mask'\n",
    "            if mask_key in state_dict:\n",
    "                new_state_dict[base_key] = value * state_dict[mask_key]\n",
    "            else:\n",
    "                new_state_dict[base_key] = value\n",
    "        elif key.endswith('_mask'):\n",
    "            continue\n",
    "        else:\n",
    "            new_state_dict[key] = value\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    return model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1.无剪枝\n",
    "print(\"=\" * 60)\n",
    "print(\"1. 原始模型（无剪枝）测试\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_valid_parameters = '4bit_VGG_best_valid_acc.pth'\n",
    "checkpoint = torch.load(best_valid_parameters)\n",
    "model_1.load_state_dict(checkpoint['state_dict'])\n",
    "model_1.eval()\n",
    "model_1.cuda()\n",
    "\n",
    "prec_origin = validate(testloader, model_1, criterion)\n",
    "total, zeros, sparsity = count_zeros_quant_only(model_1)\n",
    "print(f\"全模型 - Total params: {total}, Zero params: {zeros}, Sparsity: {sparsity*100:.2f}%\")\n",
    "total_q, zeros_q, sparsity_q = count_zeros_quant_only(model_1)\n",
    "print(f\"QuantConv2d层 - Total params: {total_q}, Zero params: {zeros_q}, Sparsity: {sparsity_q*100:.2f}%\")\n",
    "\n",
    "# 2 3次渐进剪枝\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. 分3次渐进式剪枝模型测试 (目标稀疏度: 90%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "PATH_3step = \"gradual_3step_0.9_ep10_vgg_pruned.pth\"\n",
    "try:\n",
    "    checkpoint_3step = torch.load(PATH_3step)\n",
    "    model_2 = load_pruned_state_dict(model_2, checkpoint_3step['model_state_dict'])\n",
    "    model_2.eval()\n",
    "    model_2.cuda()\n",
    "    \n",
    "    prec_3step = validate(testloader, model_2, criterion)\n",
    "    total, zeros, sparsity = count_zeros_quant_only(model_2)\n",
    "    print(f\"全模型 - Total params: {total}, Zero params: {zeros}, Sparsity: {sparsity*100:.2f}%\")\n",
    "    total_q, zeros_q, sparsity_q = count_zeros_quant_only(model_2)\n",
    "    print(f\"QuantConv2d层 - Total params: {total_q}, Zero params: {zeros_q}, Sparsity: {sparsity_q*100:.2f}%\")\n",
    "    print(f\"精度下降: {prec_origin - prec_3step:.2f}%\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"文件 {PATH_3step} 不存在，跳过测试\")\n",
    "    prec_3step = None\n",
    "\n",
    "\n",
    "#3 6次渐进剪枝\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. 分6次渐进式剪枝模型测试 (目标稀疏度: 90%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "PATH_6step = \"gradual_6step_0.9_ep10_vgg_pruned.pth\"\n",
    "try:\n",
    "    checkpoint_6step = torch.load(PATH_6step)\n",
    "    model_3 = load_pruned_state_dict(model_3, checkpoint_6step['model_state_dict'])\n",
    "    model_3.eval()\n",
    "    model_3.cuda()\n",
    "    \n",
    "    prec_6step = validate(testloader, model_3, criterion)\n",
    "    total, zeros, sparsity = count_zeros_quant_only(model_3)\n",
    "    print(f\"全模型 - Total params: {total}, Zero params: {zeros}, Sparsity: {sparsity*100:.2f}%\")\n",
    "    total_q, zeros_q, sparsity_q = count_zeros_quant_only(model_3)\n",
    "    print(f\"QuantConv2d层 - Total params: {total_q}, Zero params: {zeros_q}, Sparsity: {sparsity_q*100:.2f}%\")\n",
    "    print(f\"精度下降: {prec_origin - prec_6step:.2f}%\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"文件 {PATH_6step} 不存在，跳过测试\")\n",
    "    prec_6step = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce062a-115e-4d8e-82c0-708a41e95240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
