{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92eeb215-2855-42db-9a57-0d175e4ec7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "============================================================\n",
      "1. 原始模型（无剪枝）测试\n",
      "============================================================\n",
      "Test: [0/79]\tTime 0.654 (0.654)\tLoss 0.3867 (0.3867)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.670% \n",
      "Total params: 14710464\n",
      "Zero params: 0\n",
      "Sparsity: 0.00%\n",
      "\n",
      "============================================================\n",
      "2. 分2次渐进式剪枝模型测试 (目标稀疏度: 80%)\n",
      "============================================================\n",
      "Test: [0/79]\tTime 0.344 (0.344)\tLoss 0.4182 (0.4182)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.420% \n",
      "Total params: 14710464\n",
      "Zero params: 11768371\n",
      "Sparsity: 80.00%\n",
      "精度下降: 6.25%\n",
      "\n",
      "============================================================\n",
      "3. 分4次渐进式剪枝模型测试 (目标稀疏度: 80%)\n",
      "============================================================\n",
      "Test: [0/79]\tTime 0.241 (0.241)\tLoss 0.4884 (0.4884)\tPrec 84.375% (84.375%)\n",
      " * Prec 82.750% \n",
      "Total params: 14710464\n",
      "Zero params: 11768371\n",
      "Sparsity: 80.00%\n",
      "精度下降: 5.92%\n"
     ]
    }
   ],
   "source": [
    "# %load My_unstructured_pruning.py\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from vgg_quant import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "\n",
    "model_1 = VGG16_quant()\n",
    "model_2 = VGG16_quant()\n",
    "model_3 = VGG16_quant()\n",
    "\n",
    "        \n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk) # 5\n",
    "    batch_size = target.size(0) # 128\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True) # topk(k, dim=None, largest=True, sorted=True)\n",
    "                                    # will output (max value, its index)\n",
    "    pred = pred.t()               # transpose\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))   # \"-1\": calculate automatically\n",
    "\n",
    "    res = []\n",
    "    for k in topk: # 1, 5\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)  # view(-1): make a flattened 1D tensor\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))   # correct: size of [maxk, batch_size]\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n    ## n is impact factor\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)\n",
    "\n",
    "\n",
    "\n",
    "# lr = 4e-3\n",
    "# weight_decay = 1e-4\n",
    "# epochs = 100\n",
    "# best_prec = 0\n",
    "# model = model.cuda()\n",
    "# criterion = nn.CrossEntropyLoss().cuda()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "# fdir = 'result/'+str(model_name)+'/model_best_valid.pth'\n",
    "# epoch_parameters = 'epoch_parameters.pth'\n",
    "# best_valid_parameters = 'best_valid_acc.pth'\n",
    "\n",
    "\n",
    "def count_zeros_quant_only(model):\n",
    "    \"\"\"只统计 QuantConv2d 层的稀疏度\"\"\"\n",
    "    total = 0\n",
    "    zeros = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantConv2d):\n",
    "            weight = module.weight.data.cpu().numpy()\n",
    "            total += weight.size\n",
    "            zeros += (weight == 0).sum()\n",
    "    return total, zeros, zeros / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def load_pruned_state_dict(model, state_dict):\n",
    "    \"\"\"\n",
    "    加载剪枝后的模型权重\n",
    "    将 weight_orig * weight_mask 合并为 weight\n",
    "    \"\"\"\n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for key, value in state_dict.items():\n",
    "        if key.endswith('_orig'):\n",
    "            # 找到对应的 mask\n",
    "            base_key = key[:-5]  # 移除 '_orig'\n",
    "            mask_key = base_key + '_mask'\n",
    "            if mask_key in state_dict:\n",
    "                # 合并: weight = weight_orig * weight_mask\n",
    "                new_state_dict[base_key] = value * state_dict[mask_key]\n",
    "            else:\n",
    "                new_state_dict[base_key] = value\n",
    "        elif key.endswith('_mask'):\n",
    "            # mask 已在上面处理，跳过\n",
    "            continue\n",
    "        else:\n",
    "            new_state_dict[key] = value\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#1. 测试原始模型（无剪枝\n",
    "print(\"=\" * 60)\n",
    "print(\"1. 原始模型（无剪枝）测试\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_valid_parameters = '4bit_VGG_best_valid_acc.pth'\n",
    "checkpoint = torch.load(best_valid_parameters)\n",
    "model_1.load_state_dict(checkpoint['state_dict'])\n",
    "model_1.eval()\n",
    "model_1.cuda()\n",
    "\n",
    "prec_origin = validate(testloader, model_1, criterion)\n",
    "total, zeros, sparsity = count_zeros_quant_only(model_1)\n",
    "print(f\"Total params: {total}\")\n",
    "print(f\"Zero params: {zeros}\")\n",
    "print(f\"Sparsity: {sparsity*100:.2f}%\")\n",
    "\n",
    "\n",
    "# 2. 测试分2次渐进式剪枝模型\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. 分2次渐进式剪枝模型测试 (目标稀疏度: 80%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "PATH_2step = \"gradual_2step_0.8_ep10_vgg_pruned.pth\"\n",
    "try:\n",
    "    checkpoint_2step = torch.load(PATH_2step)\n",
    "    model_2 = load_pruned_state_dict(model_2, checkpoint_2step['model_state_dict'])\n",
    "    model_2.eval()\n",
    "    model_2.cuda()\n",
    "    \n",
    "    prec_2step = validate(testloader, model_2, criterion)\n",
    "    total, zeros, sparsity = count_zeros_quant_only(model_2)\n",
    "    print(f\"Total params: {total}\")\n",
    "    print(f\"Zero params: {zeros}\")\n",
    "    print(f\"Sparsity: {sparsity*100:.2f}%\")\n",
    "    print(f\"精度下降: {prec_origin - prec_2step:.2f}%\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"文件 {PATH_2step} 不存在，跳过测试\")\n",
    "    prec_2step = None\n",
    "\n",
    "\n",
    "# #3. 测试分4次渐进式剪枝模型\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. 分4次渐进式剪枝模型测试 (目标稀疏度: 80%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "PATH_4step = \"gradual_4step_0.8_ep10_vgg_pruned.pth\"\n",
    "try:\n",
    "    checkpoint_4step = torch.load(PATH_4step)\n",
    "    model_3 = load_pruned_state_dict(model_3, checkpoint_4step['model_state_dict'])\n",
    "    model_3.eval()\n",
    "    model_3.cuda()\n",
    "    \n",
    "    prec_4step = validate(testloader, model_3, criterion)\n",
    "    total, zeros, sparsity = count_zeros_quant_only(model_3)\n",
    "    print(f\"Total params: {total}\")\n",
    "    print(f\"Zero params: {zeros}\")\n",
    "    print(f\"Sparsity: {sparsity*100:.2f}%\")\n",
    "    print(f\"精度下降: {prec_origin - prec_4step:.2f}%\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"文件 {PATH_4step} 不存在，跳过测试\")\n",
    "    prec_4step = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc528a-c6dd-42ff-bcc2-adf521470aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
