{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4566,
     "status": "ok",
     "timestamp": 1763963552082,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "radical-fifty",
    "outputId": "077f9a55-6322-445b-fc0f-75a17775665a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): QuantConv2d(\n",
      "      16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (33): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (41): ReLU(inplace=True)\n",
      "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "model_name = \"VGG16_project\"\n",
    "model = VGG16_project()\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2107ceeb",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1763963574775,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "2107ceeb"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [100, 120]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "junior-reminder",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1729837,
     "status": "ok",
     "timestamp": 1763965308952,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "junior-reminder",
    "outputId": "4be3d6f1-b264-45c0-f8dd-e1bd78ed3f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.702 (0.702)\tData 0.110 (0.110)\tLoss 2.4724 (2.4724)\tPrec 9.375% (9.375%)\n",
      "Epoch: [0][100/391]\tTime 0.035 (0.034)\tData 0.007 (0.004)\tLoss 2.2994 (3.0935)\tPrec 12.500% (10.791%)\n",
      "Epoch: [0][200/391]\tTime 0.029 (0.030)\tData 0.009 (0.005)\tLoss 2.3398 (2.7141)\tPrec 12.500% (11.194%)\n",
      "Epoch: [0][300/391]\tTime 0.028 (0.028)\tData 0.008 (0.005)\tLoss 2.2924 (2.5766)\tPrec 17.188% (11.698%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 2.2312 (2.2312)\tPrec 14.062% (14.062%)\n",
      " * Prec 13.530% \n",
      "best acc: 13.530000\n",
      "Epoch: [1][0/391]\tTime 0.140 (0.140)\tData 0.111 (0.111)\tLoss 2.3381 (2.3381)\tPrec 11.719% (11.719%)\n",
      "Epoch: [1][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 2.2930 (2.2765)\tPrec 14.062% (14.364%)\n",
      "Epoch: [1][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 2.0824 (2.2631)\tPrec 18.750% (14.782%)\n",
      "Epoch: [1][300/391]\tTime 0.022 (0.025)\tData 0.000 (0.005)\tLoss 2.1651 (2.2296)\tPrec 11.719% (15.677%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 2.0925 (2.0925)\tPrec 21.094% (21.094%)\n",
      " * Prec 23.450% \n",
      "best acc: 23.450000\n",
      "Epoch: [2][0/391]\tTime 0.143 (0.143)\tData 0.111 (0.111)\tLoss 2.1230 (2.1230)\tPrec 24.219% (24.219%)\n",
      "Epoch: [2][100/391]\tTime 0.031 (0.027)\tData 0.011 (0.006)\tLoss 1.9520 (2.0228)\tPrec 22.656% (23.043%)\n",
      "Epoch: [2][200/391]\tTime 0.030 (0.026)\tData 0.011 (0.006)\tLoss 2.0285 (1.9978)\tPrec 28.906% (23.554%)\n",
      "Epoch: [2][300/391]\tTime 0.030 (0.026)\tData 0.010 (0.005)\tLoss 1.8853 (1.9909)\tPrec 27.344% (23.796%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 1.9235 (1.9235)\tPrec 25.781% (25.781%)\n",
      " * Prec 27.110% \n",
      "best acc: 27.110000\n",
      "Epoch: [3][0/391]\tTime 0.140 (0.140)\tData 0.111 (0.111)\tLoss 1.9770 (1.9770)\tPrec 29.688% (29.688%)\n",
      "Epoch: [3][100/391]\tTime 0.020 (0.027)\tData 0.000 (0.005)\tLoss 1.8631 (1.9135)\tPrec 26.562% (27.529%)\n",
      "Epoch: [3][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 2.0195 (1.8926)\tPrec 20.312% (28.409%)\n",
      "Epoch: [3][300/391]\tTime 0.021 (0.025)\tData 0.000 (0.005)\tLoss 2.0154 (1.8712)\tPrec 30.469% (29.573%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 1.8882 (1.8882)\tPrec 34.375% (34.375%)\n",
      " * Prec 29.970% \n",
      "best acc: 29.970000\n",
      "Epoch: [4][0/391]\tTime 0.141 (0.141)\tData 0.112 (0.112)\tLoss 1.8320 (1.8320)\tPrec 32.812% (32.812%)\n",
      "Epoch: [4][100/391]\tTime 0.029 (0.026)\tData 0.010 (0.005)\tLoss 1.8816 (1.7736)\tPrec 28.906% (33.942%)\n",
      "Epoch: [4][200/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 1.7602 (1.7665)\tPrec 35.938% (34.383%)\n",
      "Epoch: [4][300/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 1.7947 (1.7562)\tPrec 38.281% (34.920%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 1.6417 (1.6417)\tPrec 37.500% (37.500%)\n",
      " * Prec 37.210% \n",
      "best acc: 37.210000\n",
      "Epoch: [5][0/391]\tTime 0.151 (0.151)\tData 0.114 (0.114)\tLoss 1.6624 (1.6624)\tPrec 33.594% (33.594%)\n",
      "Epoch: [5][100/391]\tTime 0.025 (0.027)\tData 0.005 (0.005)\tLoss 1.6865 (1.6885)\tPrec 35.156% (38.049%)\n",
      "Epoch: [5][200/391]\tTime 0.036 (0.026)\tData 0.016 (0.005)\tLoss 1.5827 (1.6804)\tPrec 41.406% (38.145%)\n",
      "Epoch: [5][300/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 1.6537 (1.6677)\tPrec 42.188% (38.684%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 1.6600 (1.6600)\tPrec 39.844% (39.844%)\n",
      " * Prec 40.100% \n",
      "best acc: 40.100000\n",
      "Epoch: [6][0/391]\tTime 0.144 (0.144)\tData 0.112 (0.112)\tLoss 1.6662 (1.6662)\tPrec 32.812% (32.812%)\n",
      "Epoch: [6][100/391]\tTime 0.034 (0.026)\tData 0.014 (0.006)\tLoss 1.7409 (1.6004)\tPrec 38.281% (41.306%)\n",
      "Epoch: [6][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 1.6606 (1.5894)\tPrec 41.406% (41.663%)\n",
      "Epoch: [6][300/391]\tTime 0.026 (0.025)\tData 0.007 (0.005)\tLoss 1.5137 (1.5827)\tPrec 46.094% (42.297%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 1.5506 (1.5506)\tPrec 42.188% (42.188%)\n",
      " * Prec 44.620% \n",
      "best acc: 44.620000\n",
      "Epoch: [7][0/391]\tTime 0.148 (0.148)\tData 0.113 (0.113)\tLoss 1.4973 (1.4973)\tPrec 46.875% (46.875%)\n",
      "Epoch: [7][100/391]\tTime 0.021 (0.027)\tData 0.002 (0.005)\tLoss 1.6188 (1.5365)\tPrec 38.281% (44.756%)\n",
      "Epoch: [7][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 1.6609 (1.5251)\tPrec 44.531% (44.908%)\n",
      "Epoch: [7][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 1.5752 (1.5223)\tPrec 45.312% (45.206%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 1.6402 (1.6402)\tPrec 45.312% (45.312%)\n",
      " * Prec 46.310% \n",
      "best acc: 46.310000\n",
      "Epoch: [8][0/391]\tTime 0.145 (0.145)\tData 0.115 (0.115)\tLoss 1.5249 (1.5249)\tPrec 39.844% (39.844%)\n",
      "Epoch: [8][100/391]\tTime 0.027 (0.026)\tData 0.008 (0.005)\tLoss 1.4071 (1.4720)\tPrec 46.094% (46.658%)\n",
      "Epoch: [8][200/391]\tTime 0.029 (0.025)\tData 0.008 (0.005)\tLoss 1.5135 (1.4661)\tPrec 45.312% (47.143%)\n",
      "Epoch: [8][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 1.5313 (1.4650)\tPrec 44.531% (47.288%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 1.6290 (1.6290)\tPrec 38.281% (38.281%)\n",
      " * Prec 46.870% \n",
      "best acc: 46.870000\n",
      "Epoch: [9][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 1.3721 (1.3721)\tPrec 48.438% (48.438%)\n",
      "Epoch: [9][100/391]\tTime 0.020 (0.029)\tData 0.000 (0.004)\tLoss 1.3387 (1.4137)\tPrec 56.250% (48.925%)\n",
      "Epoch: [9][200/391]\tTime 0.020 (0.027)\tData 0.000 (0.005)\tLoss 1.2521 (1.4129)\tPrec 53.125% (49.265%)\n",
      "Epoch: [9][300/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 1.4549 (1.4089)\tPrec 50.000% (49.286%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 1.5128 (1.5128)\tPrec 45.312% (45.312%)\n",
      " * Prec 49.350% \n",
      "best acc: 49.350000\n",
      "Epoch: [10][0/391]\tTime 0.152 (0.152)\tData 0.115 (0.115)\tLoss 1.4474 (1.4474)\tPrec 48.438% (48.438%)\n",
      "Epoch: [10][100/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 1.2981 (1.3656)\tPrec 50.781% (50.982%)\n",
      "Epoch: [10][200/391]\tTime 0.028 (0.026)\tData 0.007 (0.005)\tLoss 1.3239 (1.3524)\tPrec 51.562% (51.562%)\n",
      "Epoch: [10][300/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 1.4188 (1.3447)\tPrec 47.656% (51.848%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 1.2461 (1.2461)\tPrec 57.031% (57.031%)\n",
      " * Prec 54.300% \n",
      "best acc: 54.300000\n",
      "Epoch: [11][0/391]\tTime 0.141 (0.141)\tData 0.112 (0.112)\tLoss 1.2518 (1.2518)\tPrec 57.031% (57.031%)\n",
      "Epoch: [11][100/391]\tTime 0.027 (0.026)\tData 0.008 (0.005)\tLoss 1.0775 (1.2913)\tPrec 66.406% (53.775%)\n",
      "Epoch: [11][200/391]\tTime 0.025 (0.025)\tData 0.005 (0.005)\tLoss 1.4054 (1.2888)\tPrec 50.781% (53.961%)\n",
      "Epoch: [11][300/391]\tTime 0.028 (0.025)\tData 0.009 (0.005)\tLoss 1.2783 (1.2879)\tPrec 53.906% (53.808%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 1.2185 (1.2185)\tPrec 58.594% (58.594%)\n",
      " * Prec 54.800% \n",
      "best acc: 54.800000\n",
      "Epoch: [12][0/391]\tTime 0.140 (0.140)\tData 0.111 (0.111)\tLoss 1.3487 (1.3487)\tPrec 52.344% (52.344%)\n",
      "Epoch: [12][100/391]\tTime 0.030 (0.026)\tData 0.008 (0.005)\tLoss 1.4587 (1.2495)\tPrec 53.125% (55.801%)\n",
      "Epoch: [12][200/391]\tTime 0.025 (0.025)\tData 0.006 (0.005)\tLoss 1.0718 (1.2429)\tPrec 57.812% (55.706%)\n",
      "Epoch: [12][300/391]\tTime 0.031 (0.025)\tData 0.011 (0.005)\tLoss 1.0626 (1.2404)\tPrec 60.156% (55.804%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 1.4611 (1.4611)\tPrec 50.000% (50.000%)\n",
      " * Prec 52.470% \n",
      "best acc: 54.800000\n",
      "Epoch: [13][0/391]\tTime 0.155 (0.155)\tData 0.114 (0.114)\tLoss 1.3037 (1.3037)\tPrec 50.781% (50.781%)\n",
      "Epoch: [13][100/391]\tTime 0.021 (0.026)\tData 0.002 (0.005)\tLoss 1.1455 (1.1992)\tPrec 57.031% (57.232%)\n",
      "Epoch: [13][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 1.0958 (1.2094)\tPrec 62.500% (57.101%)\n",
      "Epoch: [13][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 1.0936 (1.2029)\tPrec 63.281% (57.387%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 1.2133 (1.2133)\tPrec 53.906% (53.906%)\n",
      " * Prec 55.740% \n",
      "best acc: 55.740000\n",
      "Epoch: [14][0/391]\tTime 0.148 (0.148)\tData 0.112 (0.112)\tLoss 1.1109 (1.1109)\tPrec 57.812% (57.812%)\n",
      "Epoch: [14][100/391]\tTime 0.022 (0.028)\tData 0.000 (0.005)\tLoss 1.1190 (1.1602)\tPrec 58.594% (58.385%)\n",
      "Epoch: [14][200/391]\tTime 0.019 (0.026)\tData 0.000 (0.005)\tLoss 1.1348 (1.1577)\tPrec 61.719% (58.804%)\n",
      "Epoch: [14][300/391]\tTime 0.022 (0.025)\tData 0.002 (0.004)\tLoss 1.0875 (1.1563)\tPrec 63.281% (58.955%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 1.1780 (1.1780)\tPrec 57.812% (57.812%)\n",
      " * Prec 59.210% \n",
      "best acc: 59.210000\n",
      "Epoch: [15][0/391]\tTime 0.141 (0.141)\tData 0.112 (0.112)\tLoss 1.1792 (1.1792)\tPrec 55.469% (55.469%)\n",
      "Epoch: [15][100/391]\tTime 0.032 (0.026)\tData 0.012 (0.005)\tLoss 1.3064 (1.1224)\tPrec 53.125% (60.094%)\n",
      "Epoch: [15][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 1.0921 (1.1276)\tPrec 62.500% (59.865%)\n",
      "Epoch: [15][300/391]\tTime 0.033 (0.025)\tData 0.013 (0.005)\tLoss 1.2831 (1.1230)\tPrec 53.125% (60.177%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.088 (0.088)\tLoss 1.3567 (1.3567)\tPrec 52.344% (52.344%)\n",
      " * Prec 55.140% \n",
      "best acc: 59.210000\n",
      "Epoch: [16][0/391]\tTime 0.143 (0.143)\tData 0.112 (0.112)\tLoss 1.1853 (1.1853)\tPrec 53.906% (53.906%)\n",
      "Epoch: [16][100/391]\tTime 0.025 (0.026)\tData 0.003 (0.005)\tLoss 1.0813 (1.0850)\tPrec 62.500% (61.680%)\n",
      "Epoch: [16][200/391]\tTime 0.029 (0.025)\tData 0.008 (0.005)\tLoss 1.1111 (1.0827)\tPrec 53.906% (61.676%)\n",
      "Epoch: [16][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 1.0129 (1.0885)\tPrec 59.375% (61.579%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 1.0742 (1.0742)\tPrec 61.719% (61.719%)\n",
      " * Prec 61.590% \n",
      "best acc: 61.590000\n",
      "Epoch: [17][0/391]\tTime 0.141 (0.141)\tData 0.112 (0.112)\tLoss 1.2420 (1.2420)\tPrec 55.469% (55.469%)\n",
      "Epoch: [17][100/391]\tTime 0.032 (0.027)\tData 0.008 (0.006)\tLoss 1.0859 (1.0611)\tPrec 61.719% (62.570%)\n",
      "Epoch: [17][200/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.8645 (1.0562)\tPrec 71.875% (62.893%)\n",
      "Epoch: [17][300/391]\tTime 0.024 (0.025)\tData 0.003 (0.005)\tLoss 0.9423 (1.0583)\tPrec 67.188% (62.949%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 1.1714 (1.1714)\tPrec 62.500% (62.500%)\n",
      " * Prec 58.830% \n",
      "best acc: 61.590000\n",
      "Epoch: [18][0/391]\tTime 0.140 (0.140)\tData 0.112 (0.112)\tLoss 1.0669 (1.0669)\tPrec 64.844% (64.844%)\n",
      "Epoch: [18][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.9990 (1.0491)\tPrec 64.062% (63.281%)\n",
      "Epoch: [18][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 1.0158 (1.0282)\tPrec 64.844% (63.985%)\n",
      "Epoch: [18][300/391]\tTime 0.030 (0.025)\tData 0.010 (0.005)\tLoss 0.9740 (1.0252)\tPrec 67.969% (64.156%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 1.0698 (1.0698)\tPrec 60.156% (60.156%)\n",
      " * Prec 60.440% \n",
      "best acc: 61.590000\n",
      "Epoch: [19][0/391]\tTime 0.141 (0.141)\tData 0.112 (0.112)\tLoss 1.1736 (1.1736)\tPrec 58.594% (58.594%)\n",
      "Epoch: [19][100/391]\tTime 0.028 (0.026)\tData 0.001 (0.006)\tLoss 1.0168 (0.9943)\tPrec 64.844% (65.169%)\n",
      "Epoch: [19][200/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 1.0246 (0.9872)\tPrec 64.844% (65.520%)\n",
      "Epoch: [19][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.9650 (0.9928)\tPrec 62.500% (65.189%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 1.1102 (1.1102)\tPrec 62.500% (62.500%)\n",
      " * Prec 61.120% \n",
      "best acc: 61.590000\n",
      "Epoch: [20][0/391]\tTime 0.141 (0.141)\tData 0.113 (0.113)\tLoss 0.8686 (0.8686)\tPrec 67.188% (67.188%)\n",
      "Epoch: [20][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 1.0572 (0.9681)\tPrec 60.156% (66.499%)\n",
      "Epoch: [20][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.9465 (0.9675)\tPrec 62.500% (66.422%)\n",
      "Epoch: [20][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.8766 (0.9664)\tPrec 67.969% (66.393%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.9385 (0.9385)\tPrec 67.188% (67.188%)\n",
      " * Prec 64.260% \n",
      "best acc: 64.260000\n",
      "Epoch: [21][0/391]\tTime 0.142 (0.142)\tData 0.112 (0.112)\tLoss 0.9962 (0.9962)\tPrec 66.406% (66.406%)\n",
      "Epoch: [21][100/391]\tTime 0.023 (0.025)\tData 0.002 (0.005)\tLoss 1.0257 (0.9471)\tPrec 58.594% (67.218%)\n",
      "Epoch: [21][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 1.1451 (0.9401)\tPrec 64.844% (67.483%)\n",
      "Epoch: [21][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 1.1486 (0.9389)\tPrec 55.469% (67.429%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 1.1076 (1.1076)\tPrec 59.375% (59.375%)\n",
      " * Prec 62.970% \n",
      "best acc: 64.260000\n",
      "Epoch: [22][0/391]\tTime 0.151 (0.151)\tData 0.113 (0.113)\tLoss 0.8546 (0.8546)\tPrec 75.781% (75.781%)\n",
      "Epoch: [22][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.7790 (0.9351)\tPrec 78.125% (67.628%)\n",
      "Epoch: [22][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 1.0725 (0.9280)\tPrec 60.156% (67.969%)\n",
      "Epoch: [22][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 1.0474 (0.9192)\tPrec 65.625% (68.158%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.9369 (0.9369)\tPrec 67.969% (67.969%)\n",
      " * Prec 66.360% \n",
      "best acc: 66.360000\n",
      "Epoch: [23][0/391]\tTime 0.152 (0.152)\tData 0.114 (0.114)\tLoss 1.0411 (1.0411)\tPrec 64.844% (64.844%)\n",
      "Epoch: [23][100/391]\tTime 0.021 (0.027)\tData 0.002 (0.006)\tLoss 0.9819 (0.8893)\tPrec 66.406% (69.160%)\n",
      "Epoch: [23][200/391]\tTime 0.027 (0.027)\tData 0.007 (0.005)\tLoss 1.2754 (0.8861)\tPrec 53.125% (69.368%)\n",
      "Epoch: [23][300/391]\tTime 0.030 (0.026)\tData 0.010 (0.005)\tLoss 0.9216 (0.8848)\tPrec 71.094% (69.347%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.9011 (0.9011)\tPrec 68.750% (68.750%)\n",
      " * Prec 66.150% \n",
      "best acc: 66.360000\n",
      "Epoch: [24][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 0.8772 (0.8772)\tPrec 71.094% (71.094%)\n",
      "Epoch: [24][100/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.8999 (0.8806)\tPrec 67.969% (69.717%)\n",
      "Epoch: [24][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.9149 (0.8699)\tPrec 69.531% (69.951%)\n",
      "Epoch: [24][300/391]\tTime 0.030 (0.025)\tData 0.010 (0.005)\tLoss 0.7325 (0.8707)\tPrec 71.094% (69.871%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.8483 (0.8483)\tPrec 70.312% (70.312%)\n",
      " * Prec 69.300% \n",
      "best acc: 69.300000\n",
      "Epoch: [25][0/391]\tTime 0.152 (0.152)\tData 0.114 (0.114)\tLoss 0.6924 (0.6924)\tPrec 77.344% (77.344%)\n",
      "Epoch: [25][100/391]\tTime 0.028 (0.027)\tData 0.008 (0.006)\tLoss 0.7362 (0.8477)\tPrec 76.562% (70.591%)\n",
      "Epoch: [25][200/391]\tTime 0.021 (0.026)\tData 0.002 (0.005)\tLoss 0.9198 (0.8487)\tPrec 67.969% (70.546%)\n",
      "Epoch: [25][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.8417 (0.8485)\tPrec 70.312% (70.756%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 1.0298 (1.0298)\tPrec 66.406% (66.406%)\n",
      " * Prec 65.410% \n",
      "best acc: 69.300000\n",
      "Epoch: [26][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.6603 (0.6603)\tPrec 75.000% (75.000%)\n",
      "Epoch: [26][100/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.8912 (0.8003)\tPrec 71.875% (72.215%)\n",
      "Epoch: [26][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.8492 (0.8188)\tPrec 68.750% (71.743%)\n",
      "Epoch: [26][300/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.6579 (0.8208)\tPrec 78.906% (71.538%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.8293 (0.8293)\tPrec 71.875% (71.875%)\n",
      " * Prec 70.480% \n",
      "best acc: 70.480000\n",
      "Epoch: [27][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 0.7541 (0.7541)\tPrec 72.656% (72.656%)\n",
      "Epoch: [27][100/391]\tTime 0.027 (0.025)\tData 0.008 (0.006)\tLoss 0.6078 (0.8094)\tPrec 78.906% (72.123%)\n",
      "Epoch: [27][200/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.6240 (0.8129)\tPrec 79.688% (71.891%)\n",
      "Epoch: [27][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.6743 (0.8101)\tPrec 77.344% (72.015%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.9803 (0.9803)\tPrec 70.312% (70.312%)\n",
      " * Prec 68.660% \n",
      "best acc: 70.480000\n",
      "Epoch: [28][0/391]\tTime 0.145 (0.145)\tData 0.116 (0.116)\tLoss 0.7432 (0.7432)\tPrec 78.906% (78.906%)\n",
      "Epoch: [28][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.7325 (0.7938)\tPrec 70.312% (72.478%)\n",
      "Epoch: [28][200/391]\tTime 0.040 (0.026)\tData 0.019 (0.005)\tLoss 0.7286 (0.7930)\tPrec 75.781% (72.707%)\n",
      "Epoch: [28][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.8630 (0.7941)\tPrec 71.875% (72.661%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.9624 (0.9624)\tPrec 67.188% (67.188%)\n",
      " * Prec 68.450% \n",
      "best acc: 70.480000\n",
      "Epoch: [29][0/391]\tTime 0.141 (0.141)\tData 0.112 (0.112)\tLoss 0.9352 (0.9352)\tPrec 64.844% (64.844%)\n",
      "Epoch: [29][100/391]\tTime 0.025 (0.026)\tData 0.000 (0.006)\tLoss 0.8849 (0.7665)\tPrec 71.875% (73.685%)\n",
      "Epoch: [29][200/391]\tTime 0.025 (0.025)\tData 0.002 (0.005)\tLoss 0.8035 (0.7738)\tPrec 76.562% (73.383%)\n",
      "Epoch: [29][300/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.9303 (0.7727)\tPrec 67.969% (73.352%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.7671 (0.7671)\tPrec 75.781% (75.781%)\n",
      " * Prec 71.180% \n",
      "best acc: 71.180000\n",
      "Epoch: [30][0/391]\tTime 0.145 (0.145)\tData 0.116 (0.116)\tLoss 0.8215 (0.8215)\tPrec 71.094% (71.094%)\n",
      "Epoch: [30][100/391]\tTime 0.023 (0.026)\tData 0.000 (0.006)\tLoss 0.7572 (0.7563)\tPrec 71.094% (73.824%)\n",
      "Epoch: [30][200/391]\tTime 0.021 (0.026)\tData 0.002 (0.005)\tLoss 0.5944 (0.7537)\tPrec 79.688% (73.939%)\n",
      "Epoch: [30][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.7085 (0.7566)\tPrec 75.781% (73.798%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.9485 (0.9485)\tPrec 66.406% (66.406%)\n",
      " * Prec 69.540% \n",
      "best acc: 71.180000\n",
      "Epoch: [31][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 0.7525 (0.7525)\tPrec 77.344% (77.344%)\n",
      "Epoch: [31][100/391]\tTime 0.022 (0.026)\tData 0.002 (0.006)\tLoss 0.8608 (0.7366)\tPrec 71.094% (74.791%)\n",
      "Epoch: [31][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.7109 (0.7408)\tPrec 75.000% (74.658%)\n",
      "Epoch: [31][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.6910 (0.7411)\tPrec 75.781% (74.486%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.6988 (0.6988)\tPrec 78.906% (78.906%)\n",
      " * Prec 72.040% \n",
      "best acc: 72.040000\n",
      "Epoch: [32][0/391]\tTime 0.149 (0.149)\tData 0.112 (0.112)\tLoss 0.8298 (0.8298)\tPrec 71.875% (71.875%)\n",
      "Epoch: [32][100/391]\tTime 0.020 (0.028)\tData 0.000 (0.005)\tLoss 0.8621 (0.7181)\tPrec 66.406% (75.387%)\n",
      "Epoch: [32][200/391]\tTime 0.023 (0.027)\tData 0.001 (0.005)\tLoss 0.7397 (0.7233)\tPrec 72.656% (75.334%)\n",
      "Epoch: [32][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.7480 (0.7227)\tPrec 69.531% (75.265%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.8295 (0.8295)\tPrec 70.312% (70.312%)\n",
      " * Prec 71.650% \n",
      "best acc: 72.040000\n",
      "Epoch: [33][0/391]\tTime 0.152 (0.152)\tData 0.114 (0.114)\tLoss 0.7971 (0.7971)\tPrec 73.438% (73.438%)\n",
      "Epoch: [33][100/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.6996 (0.7049)\tPrec 78.125% (75.704%)\n",
      "Epoch: [33][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.6846 (0.7168)\tPrec 77.344% (75.323%)\n",
      "Epoch: [33][300/391]\tTime 0.027 (0.025)\tData 0.007 (0.004)\tLoss 0.7557 (0.7135)\tPrec 73.438% (75.436%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.7548 (0.7548)\tPrec 73.438% (73.438%)\n",
      " * Prec 72.870% \n",
      "best acc: 72.870000\n",
      "Epoch: [34][0/391]\tTime 0.142 (0.142)\tData 0.114 (0.114)\tLoss 0.6601 (0.6601)\tPrec 75.000% (75.000%)\n",
      "Epoch: [34][100/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.6720 (0.6948)\tPrec 79.688% (76.006%)\n",
      "Epoch: [34][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.7150 (0.6981)\tPrec 73.438% (75.925%)\n",
      "Epoch: [34][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.5604 (0.6987)\tPrec 80.469% (76.010%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.7896 (0.7896)\tPrec 73.438% (73.438%)\n",
      " * Prec 72.540% \n",
      "best acc: 72.870000\n",
      "Epoch: [35][0/391]\tTime 0.158 (0.158)\tData 0.116 (0.116)\tLoss 0.5800 (0.5800)\tPrec 77.344% (77.344%)\n",
      "Epoch: [35][100/391]\tTime 0.031 (0.027)\tData 0.012 (0.006)\tLoss 0.5911 (0.6841)\tPrec 77.344% (76.176%)\n",
      "Epoch: [35][200/391]\tTime 0.031 (0.026)\tData 0.012 (0.006)\tLoss 0.7227 (0.6879)\tPrec 73.438% (76.325%)\n",
      "Epoch: [35][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.6517 (0.6882)\tPrec 79.688% (76.412%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.7801 (0.7801)\tPrec 74.219% (74.219%)\n",
      " * Prec 73.380% \n",
      "best acc: 73.380000\n",
      "Epoch: [36][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 0.7206 (0.7206)\tPrec 71.875% (71.875%)\n",
      "Epoch: [36][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 0.6944 (0.6813)\tPrec 75.781% (76.686%)\n",
      "Epoch: [36][200/391]\tTime 0.023 (0.025)\tData 0.001 (0.005)\tLoss 0.5961 (0.6810)\tPrec 83.594% (76.543%)\n",
      "Epoch: [36][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.5067 (0.6756)\tPrec 83.594% (76.742%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.8930 (0.8930)\tPrec 71.875% (71.875%)\n",
      " * Prec 72.890% \n",
      "best acc: 73.380000\n",
      "Epoch: [37][0/391]\tTime 0.153 (0.153)\tData 0.115 (0.115)\tLoss 0.6339 (0.6339)\tPrec 78.125% (78.125%)\n",
      "Epoch: [37][100/391]\tTime 0.021 (0.030)\tData 0.000 (0.005)\tLoss 0.5720 (0.6422)\tPrec 82.812% (78.156%)\n",
      "Epoch: [37][200/391]\tTime 0.021 (0.027)\tData 0.000 (0.005)\tLoss 0.7490 (0.6513)\tPrec 75.781% (77.655%)\n",
      "Epoch: [37][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.7357 (0.6537)\tPrec 75.000% (77.429%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.6609 (0.6609)\tPrec 78.125% (78.125%)\n",
      " * Prec 74.500% \n",
      "best acc: 74.500000\n",
      "Epoch: [38][0/391]\tTime 0.151 (0.151)\tData 0.113 (0.113)\tLoss 0.5956 (0.5956)\tPrec 81.250% (81.250%)\n",
      "Epoch: [38][100/391]\tTime 0.022 (0.026)\tData 0.003 (0.006)\tLoss 0.5639 (0.6423)\tPrec 79.688% (77.924%)\n",
      "Epoch: [38][200/391]\tTime 0.033 (0.026)\tData 0.010 (0.006)\tLoss 0.7488 (0.6545)\tPrec 74.219% (77.526%)\n",
      "Epoch: [38][300/391]\tTime 0.031 (0.025)\tData 0.011 (0.005)\tLoss 0.5919 (0.6522)\tPrec 80.469% (77.660%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.7521 (0.7521)\tPrec 73.438% (73.438%)\n",
      " * Prec 74.700% \n",
      "best acc: 74.700000\n",
      "Epoch: [39][0/391]\tTime 0.142 (0.142)\tData 0.111 (0.111)\tLoss 0.5422 (0.5422)\tPrec 79.688% (79.688%)\n",
      "Epoch: [39][100/391]\tTime 0.023 (0.025)\tData 0.003 (0.005)\tLoss 0.6404 (0.6249)\tPrec 78.125% (78.651%)\n",
      "Epoch: [39][200/391]\tTime 0.030 (0.025)\tData 0.011 (0.005)\tLoss 0.6990 (0.6370)\tPrec 79.688% (78.191%)\n",
      "Epoch: [39][300/391]\tTime 0.026 (0.025)\tData 0.007 (0.005)\tLoss 0.7943 (0.6319)\tPrec 76.562% (78.330%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.7506 (0.7506)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.310% \n",
      "best acc: 76.310000\n",
      "Epoch: [40][0/391]\tTime 0.144 (0.144)\tData 0.114 (0.114)\tLoss 0.5719 (0.5719)\tPrec 77.344% (77.344%)\n",
      "Epoch: [40][100/391]\tTime 0.031 (0.026)\tData 0.010 (0.007)\tLoss 0.7160 (0.6207)\tPrec 75.000% (78.179%)\n",
      "Epoch: [40][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.7994 (0.6197)\tPrec 74.219% (78.685%)\n",
      "Epoch: [40][300/391]\tTime 0.027 (0.026)\tData 0.008 (0.006)\tLoss 0.7015 (0.6226)\tPrec 75.781% (78.667%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.7534 (0.7534)\tPrec 75.000% (75.000%)\n",
      " * Prec 75.150% \n",
      "best acc: 76.310000\n",
      "Epoch: [41][0/391]\tTime 0.143 (0.143)\tData 0.114 (0.114)\tLoss 0.5005 (0.5005)\tPrec 88.281% (88.281%)\n",
      "Epoch: [41][100/391]\tTime 0.027 (0.025)\tData 0.008 (0.006)\tLoss 0.7610 (0.6107)\tPrec 75.000% (79.154%)\n",
      "Epoch: [41][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.6099 (0.6103)\tPrec 75.781% (79.128%)\n",
      "Epoch: [41][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.7287 (0.6181)\tPrec 73.438% (78.725%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.6768 (0.6768)\tPrec 77.344% (77.344%)\n",
      " * Prec 75.310% \n",
      "best acc: 76.310000\n",
      "Epoch: [42][0/391]\tTime 0.147 (0.147)\tData 0.118 (0.118)\tLoss 0.5077 (0.5077)\tPrec 80.469% (80.469%)\n",
      "Epoch: [42][100/391]\tTime 0.032 (0.026)\tData 0.011 (0.006)\tLoss 0.6793 (0.6105)\tPrec 77.344% (79.100%)\n",
      "Epoch: [42][200/391]\tTime 0.031 (0.026)\tData 0.011 (0.006)\tLoss 0.5456 (0.6110)\tPrec 81.250% (79.089%)\n",
      "Epoch: [42][300/391]\tTime 0.030 (0.026)\tData 0.011 (0.006)\tLoss 0.4736 (0.6119)\tPrec 82.812% (79.091%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.7592 (0.7592)\tPrec 75.000% (75.000%)\n",
      " * Prec 77.060% \n",
      "best acc: 77.060000\n",
      "Epoch: [43][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.8023 (0.8023)\tPrec 70.312% (70.312%)\n",
      "Epoch: [43][100/391]\tTime 0.033 (0.026)\tData 0.013 (0.007)\tLoss 0.3910 (0.5696)\tPrec 84.375% (80.314%)\n",
      "Epoch: [43][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.6746 (0.5799)\tPrec 75.781% (79.859%)\n",
      "Epoch: [43][300/391]\tTime 0.035 (0.026)\tData 0.015 (0.006)\tLoss 0.4523 (0.5909)\tPrec 82.031% (79.685%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.7116 (0.7116)\tPrec 76.562% (76.562%)\n",
      " * Prec 77.280% \n",
      "best acc: 77.280000\n",
      "Epoch: [44][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 0.6965 (0.6965)\tPrec 79.688% (79.688%)\n",
      "Epoch: [44][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 0.5574 (0.5713)\tPrec 79.688% (80.569%)\n",
      "Epoch: [44][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 0.5435 (0.5756)\tPrec 79.688% (80.239%)\n",
      "Epoch: [44][300/391]\tTime 0.030 (0.026)\tData 0.011 (0.005)\tLoss 0.4042 (0.5748)\tPrec 88.281% (80.246%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.6483 (0.6483)\tPrec 73.438% (73.438%)\n",
      " * Prec 77.300% \n",
      "best acc: 77.300000\n",
      "Epoch: [45][0/391]\tTime 0.143 (0.143)\tData 0.114 (0.114)\tLoss 0.7263 (0.7263)\tPrec 78.906% (78.906%)\n",
      "Epoch: [45][100/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.5905 (0.5825)\tPrec 82.812% (80.221%)\n",
      "Epoch: [45][200/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.4480 (0.5806)\tPrec 85.938% (80.068%)\n",
      "Epoch: [45][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.6451 (0.5848)\tPrec 80.469% (80.009%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.7306 (0.7306)\tPrec 72.656% (72.656%)\n",
      " * Prec 78.070% \n",
      "best acc: 78.070000\n",
      "Epoch: [46][0/391]\tTime 0.155 (0.155)\tData 0.119 (0.119)\tLoss 0.6209 (0.6209)\tPrec 78.906% (78.906%)\n",
      "Epoch: [46][100/391]\tTime 0.031 (0.027)\tData 0.012 (0.006)\tLoss 0.5404 (0.5600)\tPrec 76.562% (80.770%)\n",
      "Epoch: [46][200/391]\tTime 0.029 (0.026)\tData 0.009 (0.006)\tLoss 0.4604 (0.5648)\tPrec 84.375% (80.566%)\n",
      "Epoch: [46][300/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.6754 (0.5676)\tPrec 80.469% (80.586%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.088 (0.088)\tLoss 0.7729 (0.7729)\tPrec 75.000% (75.000%)\n",
      " * Prec 77.020% \n",
      "best acc: 78.070000\n",
      "Epoch: [47][0/391]\tTime 0.143 (0.143)\tData 0.114 (0.114)\tLoss 0.6343 (0.6343)\tPrec 77.344% (77.344%)\n",
      "Epoch: [47][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.4777 (0.5480)\tPrec 84.375% (81.126%)\n",
      "Epoch: [47][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.6431 (0.5489)\tPrec 77.344% (81.176%)\n",
      "Epoch: [47][300/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.5962 (0.5526)\tPrec 78.125% (80.944%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.7938 (0.7938)\tPrec 74.219% (74.219%)\n",
      " * Prec 77.090% \n",
      "best acc: 78.070000\n",
      "Epoch: [48][0/391]\tTime 0.148 (0.148)\tData 0.116 (0.116)\tLoss 0.4448 (0.4448)\tPrec 86.719% (86.719%)\n",
      "Epoch: [48][100/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.5999 (0.5444)\tPrec 79.688% (81.296%)\n",
      "Epoch: [48][200/391]\tTime 0.027 (0.025)\tData 0.003 (0.005)\tLoss 0.6421 (0.5392)\tPrec 78.125% (81.573%)\n",
      "Epoch: [48][300/391]\tTime 0.023 (0.025)\tData 0.002 (0.005)\tLoss 0.4409 (0.5466)\tPrec 83.594% (81.284%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.6896 (0.6896)\tPrec 78.125% (78.125%)\n",
      " * Prec 77.600% \n",
      "best acc: 78.070000\n",
      "Epoch: [49][0/391]\tTime 0.143 (0.143)\tData 0.114 (0.114)\tLoss 0.5047 (0.5047)\tPrec 82.812% (82.812%)\n",
      "Epoch: [49][100/391]\tTime 0.026 (0.025)\tData 0.006 (0.005)\tLoss 0.6626 (0.5386)\tPrec 74.219% (81.312%)\n",
      "Epoch: [49][200/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.4928 (0.5362)\tPrec 84.375% (81.611%)\n",
      "Epoch: [49][300/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.4106 (0.5352)\tPrec 87.500% (81.463%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.6893 (0.6893)\tPrec 78.125% (78.125%)\n",
      " * Prec 77.770% \n",
      "best acc: 78.070000\n",
      "Epoch: [50][0/391]\tTime 0.144 (0.144)\tData 0.114 (0.114)\tLoss 0.4946 (0.4946)\tPrec 82.031% (82.031%)\n",
      "Epoch: [50][100/391]\tTime 0.021 (0.026)\tData 0.002 (0.005)\tLoss 0.4801 (0.5076)\tPrec 79.688% (82.921%)\n",
      "Epoch: [50][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.5310 (0.5151)\tPrec 82.812% (82.408%)\n",
      "Epoch: [50][300/391]\tTime 0.027 (0.025)\tData 0.006 (0.005)\tLoss 0.4676 (0.5196)\tPrec 84.375% (82.249%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.6568 (0.6568)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.620% \n",
      "best acc: 78.070000\n",
      "Epoch: [51][0/391]\tTime 0.155 (0.155)\tData 0.118 (0.118)\tLoss 0.4674 (0.4674)\tPrec 84.375% (84.375%)\n",
      "Epoch: [51][100/391]\tTime 0.022 (0.027)\tData 0.002 (0.006)\tLoss 0.4061 (0.5097)\tPrec 85.156% (82.519%)\n",
      "Epoch: [51][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.5719 (0.5120)\tPrec 78.906% (82.490%)\n",
      "Epoch: [51][300/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 0.4040 (0.5134)\tPrec 86.719% (82.465%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.6755 (0.6755)\tPrec 76.562% (76.562%)\n",
      " * Prec 78.340% \n",
      "best acc: 78.340000\n",
      "Epoch: [52][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 0.3852 (0.3852)\tPrec 87.500% (87.500%)\n",
      "Epoch: [52][100/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 0.4998 (0.4990)\tPrec 80.469% (83.130%)\n",
      "Epoch: [52][200/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 0.6483 (0.5040)\tPrec 76.562% (82.797%)\n",
      "Epoch: [52][300/391]\tTime 0.028 (0.026)\tData 0.007 (0.004)\tLoss 0.5015 (0.5050)\tPrec 82.812% (82.691%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.6042 (0.6042)\tPrec 77.344% (77.344%)\n",
      " * Prec 77.510% \n",
      "best acc: 78.340000\n",
      "Epoch: [53][0/391]\tTime 0.145 (0.145)\tData 0.116 (0.116)\tLoss 0.5397 (0.5397)\tPrec 81.250% (81.250%)\n",
      "Epoch: [53][100/391]\tTime 0.021 (0.026)\tData 0.001 (0.005)\tLoss 0.5137 (0.4923)\tPrec 82.812% (82.921%)\n",
      "Epoch: [53][200/391]\tTime 0.021 (0.025)\tData 0.001 (0.005)\tLoss 0.4760 (0.4952)\tPrec 85.938% (82.976%)\n",
      "Epoch: [53][300/391]\tTime 0.027 (0.026)\tData 0.006 (0.004)\tLoss 0.5368 (0.4946)\tPrec 86.719% (82.937%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.6763 (0.6763)\tPrec 76.562% (76.562%)\n",
      " * Prec 78.650% \n",
      "best acc: 78.650000\n",
      "Epoch: [54][0/391]\tTime 0.155 (0.155)\tData 0.124 (0.124)\tLoss 0.3632 (0.3632)\tPrec 90.625% (90.625%)\n",
      "Epoch: [54][100/391]\tTime 0.027 (0.026)\tData 0.005 (0.005)\tLoss 0.6519 (0.4879)\tPrec 80.469% (83.222%)\n",
      "Epoch: [54][200/391]\tTime 0.026 (0.025)\tData 0.006 (0.004)\tLoss 0.5068 (0.4865)\tPrec 86.719% (83.590%)\n",
      "Epoch: [54][300/391]\tTime 0.022 (0.025)\tData 0.002 (0.004)\tLoss 0.5944 (0.4907)\tPrec 80.469% (83.425%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.5542 (0.5542)\tPrec 81.250% (81.250%)\n",
      " * Prec 79.660% \n",
      "best acc: 79.660000\n",
      "Epoch: [55][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.3864 (0.3864)\tPrec 85.938% (85.938%)\n",
      "Epoch: [55][100/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.4460 (0.4643)\tPrec 87.500% (84.004%)\n",
      "Epoch: [55][200/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.4648 (0.4845)\tPrec 86.719% (83.415%)\n",
      "Epoch: [55][300/391]\tTime 0.029 (0.025)\tData 0.008 (0.005)\tLoss 0.5622 (0.4849)\tPrec 81.250% (83.300%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.5654 (0.5654)\tPrec 82.031% (82.031%)\n",
      " * Prec 79.970% \n",
      "best acc: 79.970000\n",
      "Epoch: [56][0/391]\tTime 0.148 (0.148)\tData 0.118 (0.118)\tLoss 0.4278 (0.4278)\tPrec 87.500% (87.500%)\n",
      "Epoch: [56][100/391]\tTime 0.029 (0.026)\tData 0.010 (0.006)\tLoss 0.4019 (0.4526)\tPrec 87.500% (84.267%)\n",
      "Epoch: [56][200/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.4371 (0.4701)\tPrec 86.719% (83.780%)\n",
      "Epoch: [56][300/391]\tTime 0.025 (0.025)\tData 0.002 (0.005)\tLoss 0.4680 (0.4735)\tPrec 82.031% (83.812%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.4046 (0.4046)\tPrec 88.281% (88.281%)\n",
      " * Prec 78.930% \n",
      "best acc: 79.970000\n",
      "Epoch: [57][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.4388 (0.4388)\tPrec 83.594% (83.594%)\n",
      "Epoch: [57][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.006)\tLoss 0.5890 (0.4601)\tPrec 81.250% (84.460%)\n",
      "Epoch: [57][200/391]\tTime 0.028 (0.025)\tData 0.009 (0.005)\tLoss 0.6368 (0.4632)\tPrec 79.688% (84.309%)\n",
      "Epoch: [57][300/391]\tTime 0.021 (0.025)\tData 0.000 (0.005)\tLoss 0.4785 (0.4639)\tPrec 82.031% (84.188%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.5671 (0.5671)\tPrec 80.469% (80.469%)\n",
      " * Prec 80.580% \n",
      "best acc: 80.580000\n",
      "Epoch: [58][0/391]\tTime 0.140 (0.140)\tData 0.111 (0.111)\tLoss 0.5143 (0.5143)\tPrec 85.156% (85.156%)\n",
      "Epoch: [58][100/391]\tTime 0.029 (0.025)\tData 0.009 (0.006)\tLoss 0.4475 (0.4449)\tPrec 83.594% (84.940%)\n",
      "Epoch: [58][200/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.3949 (0.4590)\tPrec 86.719% (84.530%)\n",
      "Epoch: [58][300/391]\tTime 0.028 (0.025)\tData 0.004 (0.005)\tLoss 0.4711 (0.4595)\tPrec 83.594% (84.481%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.7280 (0.7280)\tPrec 78.906% (78.906%)\n",
      " * Prec 77.760% \n",
      "best acc: 80.580000\n",
      "Epoch: [59][0/391]\tTime 0.143 (0.143)\tData 0.114 (0.114)\tLoss 0.5735 (0.5735)\tPrec 80.469% (80.469%)\n",
      "Epoch: [59][100/391]\tTime 0.022 (0.026)\tData 0.002 (0.005)\tLoss 0.3067 (0.4357)\tPrec 88.281% (84.901%)\n",
      "Epoch: [59][200/391]\tTime 0.028 (0.025)\tData 0.009 (0.005)\tLoss 0.4268 (0.4395)\tPrec 85.156% (84.919%)\n",
      "Epoch: [59][300/391]\tTime 0.026 (0.025)\tData 0.007 (0.005)\tLoss 0.4388 (0.4414)\tPrec 85.938% (84.902%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.6339 (0.6339)\tPrec 76.562% (76.562%)\n",
      " * Prec 80.020% \n",
      "best acc: 80.580000\n",
      "Epoch: [60][0/391]\tTime 0.143 (0.143)\tData 0.113 (0.113)\tLoss 0.3683 (0.3683)\tPrec 87.500% (87.500%)\n",
      "Epoch: [60][100/391]\tTime 0.029 (0.026)\tData 0.008 (0.006)\tLoss 0.3217 (0.4262)\tPrec 89.844% (85.381%)\n",
      "Epoch: [60][200/391]\tTime 0.030 (0.025)\tData 0.010 (0.005)\tLoss 0.4081 (0.4308)\tPrec 82.031% (85.316%)\n",
      "Epoch: [60][300/391]\tTime 0.025 (0.025)\tData 0.003 (0.005)\tLoss 0.4466 (0.4439)\tPrec 83.594% (84.972%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.5645 (0.5645)\tPrec 82.812% (82.812%)\n",
      " * Prec 78.690% \n",
      "best acc: 80.580000\n",
      "Epoch: [61][0/391]\tTime 0.152 (0.152)\tData 0.114 (0.114)\tLoss 0.3872 (0.3872)\tPrec 86.719% (86.719%)\n",
      "Epoch: [61][100/391]\tTime 0.026 (0.026)\tData 0.006 (0.005)\tLoss 0.4693 (0.4259)\tPrec 82.031% (85.257%)\n",
      "Epoch: [61][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.3134 (0.4335)\tPrec 88.281% (85.160%)\n",
      "Epoch: [61][300/391]\tTime 0.037 (0.025)\tData 0.012 (0.005)\tLoss 0.3942 (0.4368)\tPrec 85.938% (85.021%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.5436 (0.5436)\tPrec 82.812% (82.812%)\n",
      " * Prec 80.620% \n",
      "best acc: 80.620000\n",
      "Epoch: [62][0/391]\tTime 0.151 (0.151)\tData 0.113 (0.113)\tLoss 0.4152 (0.4152)\tPrec 85.938% (85.938%)\n",
      "Epoch: [62][100/391]\tTime 0.027 (0.026)\tData 0.007 (0.005)\tLoss 0.3468 (0.4244)\tPrec 87.500% (85.504%)\n",
      "Epoch: [62][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.4213 (0.4194)\tPrec 86.719% (85.588%)\n",
      "Epoch: [62][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.3505 (0.4229)\tPrec 89.062% (85.475%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.4989 (0.4989)\tPrec 83.594% (83.594%)\n",
      " * Prec 81.390% \n",
      "best acc: 81.390000\n",
      "Epoch: [63][0/391]\tTime 0.152 (0.152)\tData 0.115 (0.115)\tLoss 0.5083 (0.5083)\tPrec 82.031% (82.031%)\n",
      "Epoch: [63][100/391]\tTime 0.030 (0.027)\tData 0.010 (0.006)\tLoss 0.4512 (0.4255)\tPrec 84.375% (85.412%)\n",
      "Epoch: [63][200/391]\tTime 0.027 (0.026)\tData 0.006 (0.005)\tLoss 0.6996 (0.4188)\tPrec 76.562% (85.627%)\n",
      "Epoch: [63][300/391]\tTime 0.028 (0.025)\tData 0.004 (0.005)\tLoss 0.4395 (0.4137)\tPrec 85.938% (85.699%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.4458 (0.4458)\tPrec 83.594% (83.594%)\n",
      " * Prec 81.730% \n",
      "best acc: 81.730000\n",
      "Epoch: [64][0/391]\tTime 0.152 (0.152)\tData 0.122 (0.122)\tLoss 0.2968 (0.2968)\tPrec 87.500% (87.500%)\n",
      "Epoch: [64][100/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.4203 (0.3930)\tPrec 85.938% (86.479%)\n",
      "Epoch: [64][200/391]\tTime 0.032 (0.026)\tData 0.012 (0.006)\tLoss 0.4902 (0.3977)\tPrec 85.938% (86.194%)\n",
      "Epoch: [64][300/391]\tTime 0.035 (0.026)\tData 0.011 (0.006)\tLoss 0.2812 (0.4084)\tPrec 90.625% (85.956%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.4899 (0.4899)\tPrec 82.812% (82.812%)\n",
      " * Prec 81.470% \n",
      "best acc: 81.730000\n",
      "Epoch: [65][0/391]\tTime 0.144 (0.144)\tData 0.114 (0.114)\tLoss 0.3826 (0.3826)\tPrec 84.375% (84.375%)\n",
      "Epoch: [65][100/391]\tTime 0.027 (0.026)\tData 0.007 (0.005)\tLoss 0.4009 (0.3915)\tPrec 84.375% (86.541%)\n",
      "Epoch: [65][200/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.4568 (0.3973)\tPrec 82.812% (86.427%)\n",
      "Epoch: [65][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.3071 (0.3991)\tPrec 90.625% (86.433%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4494 (0.4494)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.200% \n",
      "best acc: 82.200000\n",
      "Epoch: [66][0/391]\tTime 0.149 (0.149)\tData 0.120 (0.120)\tLoss 0.4149 (0.4149)\tPrec 85.156% (85.156%)\n",
      "Epoch: [66][100/391]\tTime 0.030 (0.026)\tData 0.008 (0.005)\tLoss 0.3276 (0.3991)\tPrec 90.625% (86.494%)\n",
      "Epoch: [66][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.2975 (0.3959)\tPrec 90.625% (86.629%)\n",
      "Epoch: [66][300/391]\tTime 0.029 (0.025)\tData 0.010 (0.005)\tLoss 0.3739 (0.3973)\tPrec 86.719% (86.573%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.6366 (0.6366)\tPrec 78.125% (78.125%)\n",
      " * Prec 80.140% \n",
      "best acc: 82.200000\n",
      "Epoch: [67][0/391]\tTime 0.148 (0.148)\tData 0.119 (0.119)\tLoss 0.3112 (0.3112)\tPrec 91.406% (91.406%)\n",
      "Epoch: [67][100/391]\tTime 0.031 (0.026)\tData 0.011 (0.006)\tLoss 0.3355 (0.3811)\tPrec 85.156% (86.897%)\n",
      "Epoch: [67][200/391]\tTime 0.030 (0.026)\tData 0.006 (0.006)\tLoss 0.4178 (0.3844)\tPrec 86.719% (86.812%)\n",
      "Epoch: [67][300/391]\tTime 0.032 (0.026)\tData 0.011 (0.006)\tLoss 0.3813 (0.3871)\tPrec 83.594% (86.729%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.4612 (0.4612)\tPrec 82.812% (82.812%)\n",
      " * Prec 81.890% \n",
      "best acc: 82.200000\n",
      "Epoch: [68][0/391]\tTime 0.153 (0.153)\tData 0.115 (0.115)\tLoss 0.2525 (0.2525)\tPrec 93.750% (93.750%)\n",
      "Epoch: [68][100/391]\tTime 0.028 (0.026)\tData 0.007 (0.005)\tLoss 0.4779 (0.3801)\tPrec 85.938% (86.997%)\n",
      "Epoch: [68][200/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.4061 (0.3759)\tPrec 89.062% (87.232%)\n",
      "Epoch: [68][300/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.4524 (0.3822)\tPrec 86.719% (87.098%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.4119 (0.4119)\tPrec 85.938% (85.938%)\n",
      " * Prec 82.210% \n",
      "best acc: 82.210000\n",
      "Epoch: [69][0/391]\tTime 0.148 (0.148)\tData 0.119 (0.119)\tLoss 0.3457 (0.3457)\tPrec 88.281% (88.281%)\n",
      "Epoch: [69][100/391]\tTime 0.028 (0.027)\tData 0.008 (0.005)\tLoss 0.3503 (0.3702)\tPrec 91.406% (87.554%)\n",
      "Epoch: [69][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.3980 (0.3771)\tPrec 85.156% (87.185%)\n",
      "Epoch: [69][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.3088 (0.3762)\tPrec 91.406% (87.277%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4071 (0.4071)\tPrec 88.281% (88.281%)\n",
      " * Prec 82.100% \n",
      "best acc: 82.210000\n",
      "Epoch: [70][0/391]\tTime 0.145 (0.145)\tData 0.116 (0.116)\tLoss 0.3637 (0.3637)\tPrec 86.719% (86.719%)\n",
      "Epoch: [70][100/391]\tTime 0.024 (0.026)\tData 0.004 (0.005)\tLoss 0.3319 (0.3585)\tPrec 88.281% (87.717%)\n",
      "Epoch: [70][200/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.3038 (0.3614)\tPrec 91.406% (87.648%)\n",
      "Epoch: [70][300/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.3845 (0.3701)\tPrec 89.062% (87.388%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.4700 (0.4700)\tPrec 82.031% (82.031%)\n",
      " * Prec 82.940% \n",
      "best acc: 82.940000\n",
      "Epoch: [71][0/391]\tTime 0.155 (0.155)\tData 0.116 (0.116)\tLoss 0.2193 (0.2193)\tPrec 92.969% (92.969%)\n",
      "Epoch: [71][100/391]\tTime 0.030 (0.027)\tData 0.011 (0.006)\tLoss 0.3900 (0.3522)\tPrec 89.844% (87.825%)\n",
      "Epoch: [71][200/391]\tTime 0.028 (0.026)\tData 0.008 (0.006)\tLoss 0.3371 (0.3573)\tPrec 89.844% (87.679%)\n",
      "Epoch: [71][300/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.2855 (0.3589)\tPrec 86.719% (87.666%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.4170 (0.4170)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.260% \n",
      "best acc: 83.260000\n",
      "Epoch: [72][0/391]\tTime 0.144 (0.144)\tData 0.114 (0.114)\tLoss 0.2639 (0.2639)\tPrec 89.062% (89.062%)\n",
      "Epoch: [72][100/391]\tTime 0.029 (0.026)\tData 0.009 (0.006)\tLoss 0.2515 (0.3465)\tPrec 93.750% (88.119%)\n",
      "Epoch: [72][200/391]\tTime 0.028 (0.025)\tData 0.007 (0.005)\tLoss 0.3648 (0.3552)\tPrec 88.281% (87.858%)\n",
      "Epoch: [72][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.2977 (0.3597)\tPrec 89.844% (87.747%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4340 (0.4340)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.750% \n",
      "best acc: 83.750000\n",
      "Epoch: [73][0/391]\tTime 0.150 (0.150)\tData 0.113 (0.113)\tLoss 0.3016 (0.3016)\tPrec 89.062% (89.062%)\n",
      "Epoch: [73][100/391]\tTime 0.022 (0.028)\tData 0.002 (0.007)\tLoss 0.3157 (0.3522)\tPrec 88.281% (87.918%)\n",
      "Epoch: [73][200/391]\tTime 0.022 (0.027)\tData 0.002 (0.006)\tLoss 0.3430 (0.3593)\tPrec 88.281% (87.702%)\n",
      "Epoch: [73][300/391]\tTime 0.021 (0.026)\tData 0.002 (0.005)\tLoss 0.2482 (0.3611)\tPrec 92.188% (87.684%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.3698 (0.3698)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.390% \n",
      "best acc: 83.750000\n",
      "Epoch: [74][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.2537 (0.2537)\tPrec 91.406% (91.406%)\n",
      "Epoch: [74][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.4458 (0.3509)\tPrec 82.812% (88.096%)\n",
      "Epoch: [74][200/391]\tTime 0.031 (0.025)\tData 0.010 (0.005)\tLoss 0.2387 (0.3539)\tPrec 92.188% (87.947%)\n",
      "Epoch: [74][300/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.3626 (0.3540)\tPrec 88.281% (87.970%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4008 (0.4008)\tPrec 85.156% (85.156%)\n",
      " * Prec 84.170% \n",
      "best acc: 84.170000\n",
      "Epoch: [75][0/391]\tTime 0.141 (0.141)\tData 0.112 (0.112)\tLoss 0.1950 (0.1950)\tPrec 92.969% (92.969%)\n",
      "Epoch: [75][100/391]\tTime 0.034 (0.026)\tData 0.013 (0.006)\tLoss 0.4370 (0.3405)\tPrec 85.938% (88.390%)\n",
      "Epoch: [75][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.2597 (0.3494)\tPrec 91.406% (88.083%)\n",
      "Epoch: [75][300/391]\tTime 0.030 (0.025)\tData 0.010 (0.005)\tLoss 0.4799 (0.3537)\tPrec 83.594% (87.827%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.4240 (0.4240)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.810% \n",
      "best acc: 84.170000\n",
      "Epoch: [76][0/391]\tTime 0.153 (0.153)\tData 0.116 (0.116)\tLoss 0.2965 (0.2965)\tPrec 87.500% (87.500%)\n",
      "Epoch: [76][100/391]\tTime 0.029 (0.026)\tData 0.010 (0.006)\tLoss 0.3011 (0.3252)\tPrec 89.062% (88.745%)\n",
      "Epoch: [76][200/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.3661 (0.3304)\tPrec 88.281% (88.787%)\n",
      "Epoch: [76][300/391]\tTime 0.029 (0.025)\tData 0.010 (0.005)\tLoss 0.3357 (0.3342)\tPrec 91.406% (88.536%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.3675 (0.3675)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.000% \n",
      "best acc: 84.170000\n",
      "Epoch: [77][0/391]\tTime 0.151 (0.151)\tData 0.114 (0.114)\tLoss 0.4329 (0.4329)\tPrec 88.281% (88.281%)\n",
      "Epoch: [77][100/391]\tTime 0.026 (0.026)\tData 0.007 (0.005)\tLoss 0.2596 (0.3255)\tPrec 90.625% (88.614%)\n",
      "Epoch: [77][200/391]\tTime 0.025 (0.025)\tData 0.002 (0.005)\tLoss 0.4407 (0.3337)\tPrec 85.156% (88.305%)\n",
      "Epoch: [77][300/391]\tTime 0.022 (0.025)\tData 0.002 (0.004)\tLoss 0.3470 (0.3385)\tPrec 88.281% (88.227%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.3894 (0.3894)\tPrec 85.156% (85.156%)\n",
      " * Prec 85.140% \n",
      "best acc: 85.140000\n",
      "Epoch: [78][0/391]\tTime 0.143 (0.143)\tData 0.113 (0.113)\tLoss 0.2514 (0.2514)\tPrec 91.406% (91.406%)\n",
      "Epoch: [78][100/391]\tTime 0.028 (0.026)\tData 0.007 (0.005)\tLoss 0.2885 (0.3104)\tPrec 91.406% (89.604%)\n",
      "Epoch: [78][200/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.2846 (0.3235)\tPrec 90.625% (88.954%)\n",
      "Epoch: [78][300/391]\tTime 0.029 (0.025)\tData 0.008 (0.005)\tLoss 0.1313 (0.3252)\tPrec 96.094% (88.889%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.5222 (0.5222)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.260% \n",
      "best acc: 85.140000\n",
      "Epoch: [79][0/391]\tTime 0.145 (0.145)\tData 0.116 (0.116)\tLoss 0.5374 (0.5374)\tPrec 85.156% (85.156%)\n",
      "Epoch: [79][100/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.3202 (0.3224)\tPrec 87.500% (89.163%)\n",
      "Epoch: [79][200/391]\tTime 0.025 (0.025)\tData 0.006 (0.005)\tLoss 0.2847 (0.3257)\tPrec 92.188% (88.965%)\n",
      "Epoch: [79][300/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.3403 (0.3237)\tPrec 89.062% (88.974%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4564 (0.4564)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.930% \n",
      "best acc: 85.140000\n",
      "Epoch: [80][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 0.2818 (0.2818)\tPrec 85.156% (85.156%)\n",
      "Epoch: [80][100/391]\tTime 0.028 (0.027)\tData 0.009 (0.006)\tLoss 0.2503 (0.3122)\tPrec 89.844% (89.109%)\n",
      "Epoch: [80][200/391]\tTime 0.028 (0.026)\tData 0.007 (0.005)\tLoss 0.2764 (0.3198)\tPrec 90.625% (88.911%)\n",
      "Epoch: [80][300/391]\tTime 0.029 (0.025)\tData 0.010 (0.005)\tLoss 0.3183 (0.3199)\tPrec 89.062% (88.943%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.4343 (0.4343)\tPrec 85.938% (85.938%)\n",
      " * Prec 84.760% \n",
      "best acc: 85.140000\n",
      "Epoch: [81][0/391]\tTime 0.156 (0.156)\tData 0.119 (0.119)\tLoss 0.3483 (0.3483)\tPrec 86.719% (86.719%)\n",
      "Epoch: [81][100/391]\tTime 0.021 (0.027)\tData 0.000 (0.006)\tLoss 0.3957 (0.3042)\tPrec 89.062% (89.372%)\n",
      "Epoch: [81][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.3123 (0.3061)\tPrec 90.625% (89.381%)\n",
      "Epoch: [81][300/391]\tTime 0.021 (0.025)\tData 0.001 (0.005)\tLoss 0.2698 (0.3135)\tPrec 91.406% (89.120%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.3517 (0.3517)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.640% \n",
      "best acc: 85.140000\n",
      "Epoch: [82][0/391]\tTime 0.153 (0.153)\tData 0.115 (0.115)\tLoss 0.2693 (0.2693)\tPrec 90.625% (90.625%)\n",
      "Epoch: [82][100/391]\tTime 0.028 (0.026)\tData 0.007 (0.005)\tLoss 0.4217 (0.2934)\tPrec 88.281% (90.060%)\n",
      "Epoch: [82][200/391]\tTime 0.027 (0.025)\tData 0.005 (0.004)\tLoss 0.2684 (0.3043)\tPrec 89.844% (89.603%)\n",
      "Epoch: [82][300/391]\tTime 0.029 (0.025)\tData 0.007 (0.004)\tLoss 0.2445 (0.3074)\tPrec 92.188% (89.491%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.3663 (0.3663)\tPrec 86.719% (86.719%)\n",
      " * Prec 85.100% \n",
      "best acc: 85.140000\n",
      "Epoch: [83][0/391]\tTime 0.141 (0.141)\tData 0.112 (0.112)\tLoss 0.3437 (0.3437)\tPrec 87.500% (87.500%)\n",
      "Epoch: [83][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.2954 (0.3048)\tPrec 89.062% (89.380%)\n",
      "Epoch: [83][200/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.2910 (0.3041)\tPrec 87.500% (89.541%)\n",
      "Epoch: [83][300/391]\tTime 0.029 (0.025)\tData 0.010 (0.005)\tLoss 0.2365 (0.3014)\tPrec 89.062% (89.621%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 0.4972 (0.4972)\tPrec 85.156% (85.156%)\n",
      " * Prec 84.370% \n",
      "best acc: 85.140000\n",
      "Epoch: [84][0/391]\tTime 0.150 (0.150)\tData 0.120 (0.120)\tLoss 0.2763 (0.2763)\tPrec 89.844% (89.844%)\n",
      "Epoch: [84][100/391]\tTime 0.030 (0.026)\tData 0.011 (0.006)\tLoss 0.3467 (0.2881)\tPrec 90.625% (90.192%)\n",
      "Epoch: [84][200/391]\tTime 0.028 (0.026)\tData 0.007 (0.005)\tLoss 0.2315 (0.2914)\tPrec 92.188% (90.050%)\n",
      "Epoch: [84][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.4365 (0.2985)\tPrec 84.375% (89.709%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3745 (0.3745)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.590% \n",
      "best acc: 85.590000\n",
      "Epoch: [85][0/391]\tTime 0.150 (0.150)\tData 0.112 (0.112)\tLoss 0.2088 (0.2088)\tPrec 92.969% (92.969%)\n",
      "Epoch: [85][100/391]\tTime 0.031 (0.027)\tData 0.011 (0.005)\tLoss 0.2774 (0.2820)\tPrec 92.188% (90.401%)\n",
      "Epoch: [85][200/391]\tTime 0.028 (0.027)\tData 0.007 (0.004)\tLoss 0.3912 (0.2910)\tPrec 88.281% (89.984%)\n",
      "Epoch: [85][300/391]\tTime 0.028 (0.026)\tData 0.008 (0.004)\tLoss 0.2564 (0.2925)\tPrec 89.844% (90.049%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.5776 (0.5776)\tPrec 82.031% (82.031%)\n",
      " * Prec 83.500% \n",
      "best acc: 85.590000\n",
      "Epoch: [86][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.2377 (0.2377)\tPrec 92.188% (92.188%)\n",
      "Epoch: [86][100/391]\tTime 0.028 (0.027)\tData 0.009 (0.006)\tLoss 0.1610 (0.2793)\tPrec 95.312% (90.246%)\n",
      "Epoch: [86][200/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.2108 (0.2876)\tPrec 92.188% (90.116%)\n",
      "Epoch: [86][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.2204 (0.2918)\tPrec 93.750% (89.984%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3958 (0.3958)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.860% \n",
      "best acc: 85.590000\n",
      "Epoch: [87][0/391]\tTime 0.143 (0.143)\tData 0.113 (0.113)\tLoss 0.2165 (0.2165)\tPrec 91.406% (91.406%)\n",
      "Epoch: [87][100/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.2062 (0.2741)\tPrec 92.188% (90.586%)\n",
      "Epoch: [87][200/391]\tTime 0.029 (0.025)\tData 0.008 (0.004)\tLoss 0.3551 (0.2821)\tPrec 89.062% (90.295%)\n",
      "Epoch: [87][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.004)\tLoss 0.2412 (0.2849)\tPrec 91.406% (90.249%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.5113 (0.5113)\tPrec 84.375% (84.375%)\n",
      " * Prec 85.100% \n",
      "best acc: 85.590000\n",
      "Epoch: [88][0/391]\tTime 0.152 (0.152)\tData 0.122 (0.122)\tLoss 0.2840 (0.2840)\tPrec 90.625% (90.625%)\n",
      "Epoch: [88][100/391]\tTime 0.028 (0.026)\tData 0.007 (0.005)\tLoss 0.3263 (0.2771)\tPrec 88.281% (90.710%)\n",
      "Epoch: [88][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.3310 (0.2810)\tPrec 88.281% (90.501%)\n",
      "Epoch: [88][300/391]\tTime 0.021 (0.025)\tData 0.000 (0.005)\tLoss 0.3581 (0.2849)\tPrec 89.062% (90.358%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.5277 (0.5277)\tPrec 85.156% (85.156%)\n",
      " * Prec 84.000% \n",
      "best acc: 85.590000\n",
      "Epoch: [89][0/391]\tTime 0.152 (0.152)\tData 0.122 (0.122)\tLoss 0.1987 (0.1987)\tPrec 92.969% (92.969%)\n",
      "Epoch: [89][100/391]\tTime 0.031 (0.027)\tData 0.011 (0.006)\tLoss 0.2764 (0.2894)\tPrec 89.844% (90.169%)\n",
      "Epoch: [89][200/391]\tTime 0.021 (0.027)\tData 0.002 (0.005)\tLoss 0.2495 (0.2792)\tPrec 92.188% (90.481%)\n",
      "Epoch: [89][300/391]\tTime 0.031 (0.026)\tData 0.012 (0.006)\tLoss 0.2288 (0.2804)\tPrec 92.969% (90.441%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.089 (0.089)\tLoss 0.5899 (0.5899)\tPrec 82.812% (82.812%)\n",
      " * Prec 84.630% \n",
      "best acc: 85.590000\n",
      "Epoch: [90][0/391]\tTime 0.167 (0.167)\tData 0.137 (0.137)\tLoss 0.3426 (0.3426)\tPrec 89.844% (89.844%)\n",
      "Epoch: [90][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.006)\tLoss 0.2053 (0.2806)\tPrec 91.406% (90.470%)\n",
      "Epoch: [90][200/391]\tTime 0.021 (0.026)\tData 0.000 (0.006)\tLoss 0.2466 (0.2777)\tPrec 92.969% (90.536%)\n",
      "Epoch: [90][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.3080 (0.2801)\tPrec 89.844% (90.537%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.5310 (0.5310)\tPrec 82.812% (82.812%)\n",
      " * Prec 82.980% \n",
      "best acc: 85.590000\n",
      "Epoch: [91][0/391]\tTime 0.146 (0.146)\tData 0.116 (0.116)\tLoss 0.1918 (0.1918)\tPrec 92.188% (92.188%)\n",
      "Epoch: [91][100/391]\tTime 0.022 (0.026)\tData 0.002 (0.006)\tLoss 0.2909 (0.2647)\tPrec 89.844% (90.873%)\n",
      "Epoch: [91][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.2755 (0.2653)\tPrec 89.844% (90.808%)\n",
      "Epoch: [91][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.2255 (0.2692)\tPrec 91.406% (90.685%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.4010 (0.4010)\tPrec 84.375% (84.375%)\n",
      " * Prec 85.350% \n",
      "best acc: 85.590000\n",
      "Epoch: [92][0/391]\tTime 0.160 (0.160)\tData 0.120 (0.120)\tLoss 0.2168 (0.2168)\tPrec 91.406% (91.406%)\n",
      "Epoch: [92][100/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 0.2196 (0.2615)\tPrec 93.750% (91.105%)\n",
      "Epoch: [92][200/391]\tTime 0.029 (0.026)\tData 0.010 (0.005)\tLoss 0.2294 (0.2688)\tPrec 92.188% (90.668%)\n",
      "Epoch: [92][300/391]\tTime 0.030 (0.026)\tData 0.011 (0.005)\tLoss 0.1780 (0.2739)\tPrec 94.531% (90.477%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4138 (0.4138)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.820% \n",
      "best acc: 85.590000\n",
      "Epoch: [93][0/391]\tTime 0.151 (0.151)\tData 0.119 (0.119)\tLoss 0.2589 (0.2589)\tPrec 89.844% (89.844%)\n",
      "Epoch: [93][100/391]\tTime 0.030 (0.026)\tData 0.009 (0.006)\tLoss 0.3066 (0.2488)\tPrec 90.625% (91.306%)\n",
      "Epoch: [93][200/391]\tTime 0.027 (0.026)\tData 0.007 (0.005)\tLoss 0.3036 (0.2569)\tPrec 88.281% (91.115%)\n",
      "Epoch: [93][300/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.2405 (0.2659)\tPrec 89.844% (90.843%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.4092 (0.4092)\tPrec 85.156% (85.156%)\n",
      " * Prec 87.150% \n",
      "best acc: 87.150000\n",
      "Epoch: [94][0/391]\tTime 0.151 (0.151)\tData 0.120 (0.120)\tLoss 0.2121 (0.2121)\tPrec 94.531% (94.531%)\n",
      "Epoch: [94][100/391]\tTime 0.028 (0.026)\tData 0.007 (0.005)\tLoss 0.2434 (0.2448)\tPrec 92.969% (91.576%)\n",
      "Epoch: [94][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.4086 (0.2530)\tPrec 85.938% (91.402%)\n",
      "Epoch: [94][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.3486 (0.2576)\tPrec 89.844% (91.248%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.4689 (0.4689)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.560% \n",
      "best acc: 87.150000\n",
      "Epoch: [95][0/391]\tTime 0.153 (0.153)\tData 0.115 (0.115)\tLoss 0.2616 (0.2616)\tPrec 92.188% (92.188%)\n",
      "Epoch: [95][100/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 0.2430 (0.2661)\tPrec 92.969% (91.035%)\n",
      "Epoch: [95][200/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.2515 (0.2621)\tPrec 89.844% (91.045%)\n",
      "Epoch: [95][300/391]\tTime 0.026 (0.025)\tData 0.005 (0.005)\tLoss 0.2709 (0.2639)\tPrec 89.844% (90.999%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2535 (0.2535)\tPrec 91.406% (91.406%)\n",
      " * Prec 85.490% \n",
      "best acc: 87.150000\n",
      "Epoch: [96][0/391]\tTime 0.154 (0.154)\tData 0.122 (0.122)\tLoss 0.2277 (0.2277)\tPrec 90.625% (90.625%)\n",
      "Epoch: [96][100/391]\tTime 0.029 (0.027)\tData 0.008 (0.006)\tLoss 0.2530 (0.2312)\tPrec 90.625% (91.948%)\n",
      "Epoch: [96][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.1734 (0.2468)\tPrec 93.750% (91.422%)\n",
      "Epoch: [96][300/391]\tTime 0.034 (0.026)\tData 0.014 (0.006)\tLoss 0.1479 (0.2457)\tPrec 95.312% (91.536%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4253 (0.4253)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.210% \n",
      "best acc: 87.150000\n",
      "Epoch: [97][0/391]\tTime 0.154 (0.154)\tData 0.125 (0.125)\tLoss 0.2200 (0.2200)\tPrec 92.188% (92.188%)\n",
      "Epoch: [97][100/391]\tTime 0.028 (0.028)\tData 0.008 (0.005)\tLoss 0.1816 (0.2556)\tPrec 92.969% (91.136%)\n",
      "Epoch: [97][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.005)\tLoss 0.2916 (0.2601)\tPrec 89.062% (91.103%)\n",
      "Epoch: [97][300/391]\tTime 0.030 (0.026)\tData 0.010 (0.005)\tLoss 0.2540 (0.2587)\tPrec 91.406% (91.131%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.088 (0.088)\tLoss 0.3552 (0.3552)\tPrec 89.844% (89.844%)\n",
      " * Prec 84.770% \n",
      "best acc: 87.150000\n",
      "Epoch: [98][0/391]\tTime 0.151 (0.151)\tData 0.114 (0.114)\tLoss 0.2440 (0.2440)\tPrec 95.312% (95.312%)\n",
      "Epoch: [98][100/391]\tTime 0.030 (0.027)\tData 0.009 (0.006)\tLoss 0.3154 (0.2432)\tPrec 89.844% (91.368%)\n",
      "Epoch: [98][200/391]\tTime 0.026 (0.025)\tData 0.007 (0.005)\tLoss 0.1786 (0.2553)\tPrec 94.531% (91.006%)\n",
      "Epoch: [98][300/391]\tTime 0.029 (0.025)\tData 0.008 (0.005)\tLoss 0.1884 (0.2545)\tPrec 92.969% (91.110%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.4180 (0.4180)\tPrec 83.594% (83.594%)\n",
      " * Prec 84.160% \n",
      "best acc: 87.150000\n",
      "Epoch: [99][0/391]\tTime 0.148 (0.148)\tData 0.118 (0.118)\tLoss 0.3591 (0.3591)\tPrec 86.719% (86.719%)\n",
      "Epoch: [99][100/391]\tTime 0.022 (0.026)\tData 0.002 (0.005)\tLoss 0.2861 (0.2445)\tPrec 89.844% (91.399%)\n",
      "Epoch: [99][200/391]\tTime 0.027 (0.026)\tData 0.007 (0.005)\tLoss 0.3990 (0.2499)\tPrec 86.719% (91.418%)\n",
      "Epoch: [99][300/391]\tTime 0.024 (0.025)\tData 0.004 (0.005)\tLoss 0.2583 (0.2510)\tPrec 89.844% (91.305%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.3992 (0.3992)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.340% \n",
      "best acc: 87.150000\n",
      "Epoch: [100][0/391]\tTime 0.148 (0.148)\tData 0.118 (0.118)\tLoss 0.2767 (0.2767)\tPrec 88.281% (88.281%)\n",
      "Epoch: [100][100/391]\tTime 0.031 (0.027)\tData 0.008 (0.005)\tLoss 0.2184 (0.2035)\tPrec 90.625% (92.915%)\n",
      "Epoch: [100][200/391]\tTime 0.031 (0.026)\tData 0.010 (0.005)\tLoss 0.1638 (0.1924)\tPrec 96.094% (93.493%)\n",
      "Epoch: [100][300/391]\tTime 0.030 (0.026)\tData 0.010 (0.005)\tLoss 0.1385 (0.1859)\tPrec 96.094% (93.654%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.3068 (0.3068)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.430% \n",
      "best acc: 88.430000\n",
      "Epoch: [101][0/391]\tTime 0.149 (0.149)\tData 0.113 (0.113)\tLoss 0.0888 (0.0888)\tPrec 96.875% (96.875%)\n",
      "Epoch: [101][100/391]\tTime 0.021 (0.027)\tData 0.000 (0.005)\tLoss 0.1277 (0.1621)\tPrec 96.094% (94.369%)\n",
      "Epoch: [101][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.1720 (0.1605)\tPrec 93.750% (94.516%)\n",
      "Epoch: [101][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.1575 (0.1591)\tPrec 94.531% (94.534%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.2421 (0.2421)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.680% \n",
      "best acc: 88.680000\n",
      "Epoch: [102][0/391]\tTime 0.148 (0.148)\tData 0.119 (0.119)\tLoss 0.1440 (0.1440)\tPrec 95.312% (95.312%)\n",
      "Epoch: [102][100/391]\tTime 0.028 (0.026)\tData 0.007 (0.006)\tLoss 0.1747 (0.1402)\tPrec 95.312% (95.088%)\n",
      "Epoch: [102][200/391]\tTime 0.022 (0.026)\tData 0.002 (0.005)\tLoss 0.0603 (0.1438)\tPrec 97.656% (95.017%)\n",
      "Epoch: [102][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0660 (0.1456)\tPrec 98.438% (94.931%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2353 (0.2353)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.230% \n",
      "best acc: 88.680000\n",
      "Epoch: [103][0/391]\tTime 0.149 (0.149)\tData 0.119 (0.119)\tLoss 0.1344 (0.1344)\tPrec 96.875% (96.875%)\n",
      "Epoch: [103][100/391]\tTime 0.029 (0.027)\tData 0.009 (0.006)\tLoss 0.0986 (0.1290)\tPrec 96.875% (95.599%)\n",
      "Epoch: [103][200/391]\tTime 0.030 (0.026)\tData 0.009 (0.006)\tLoss 0.1461 (0.1343)\tPrec 96.094% (95.414%)\n",
      "Epoch: [103][300/391]\tTime 0.039 (0.026)\tData 0.019 (0.006)\tLoss 0.0685 (0.1369)\tPrec 99.219% (95.338%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4084 (0.4084)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.620% \n",
      "best acc: 88.680000\n",
      "Epoch: [104][0/391]\tTime 0.150 (0.150)\tData 0.120 (0.120)\tLoss 0.1377 (0.1377)\tPrec 96.094% (96.094%)\n",
      "Epoch: [104][100/391]\tTime 0.022 (0.026)\tData 0.002 (0.006)\tLoss 0.2081 (0.1346)\tPrec 92.188% (95.359%)\n",
      "Epoch: [104][200/391]\tTime 0.032 (0.025)\tData 0.008 (0.005)\tLoss 0.1702 (0.1347)\tPrec 92.969% (95.382%)\n",
      "Epoch: [104][300/391]\tTime 0.029 (0.025)\tData 0.010 (0.005)\tLoss 0.1628 (0.1362)\tPrec 92.969% (95.323%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3132 (0.3132)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.470% \n",
      "best acc: 88.680000\n",
      "Epoch: [105][0/391]\tTime 0.145 (0.145)\tData 0.116 (0.116)\tLoss 0.0712 (0.0712)\tPrec 97.656% (97.656%)\n",
      "Epoch: [105][100/391]\tTime 0.020 (0.026)\tData 0.001 (0.005)\tLoss 0.1333 (0.1342)\tPrec 94.531% (95.413%)\n",
      "Epoch: [105][200/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.1009 (0.1333)\tPrec 96.875% (95.402%)\n",
      "Epoch: [105][300/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.1935 (0.1339)\tPrec 90.625% (95.362%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.2604 (0.2604)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.650% \n",
      "best acc: 88.680000\n",
      "Epoch: [106][0/391]\tTime 0.147 (0.147)\tData 0.117 (0.117)\tLoss 0.0878 (0.0878)\tPrec 96.875% (96.875%)\n",
      "Epoch: [106][100/391]\tTime 0.020 (0.027)\tData 0.000 (0.006)\tLoss 0.1758 (0.1271)\tPrec 95.312% (95.777%)\n",
      "Epoch: [106][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.2205 (0.1269)\tPrec 92.188% (95.756%)\n",
      "Epoch: [106][300/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 0.1209 (0.1275)\tPrec 95.312% (95.681%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.2733 (0.2733)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.100% \n",
      "best acc: 89.100000\n",
      "Epoch: [107][0/391]\tTime 0.149 (0.149)\tData 0.120 (0.120)\tLoss 0.1537 (0.1537)\tPrec 95.312% (95.312%)\n",
      "Epoch: [107][100/391]\tTime 0.028 (0.027)\tData 0.008 (0.006)\tLoss 0.0744 (0.1204)\tPrec 96.875% (95.769%)\n",
      "Epoch: [107][200/391]\tTime 0.022 (0.026)\tData 0.002 (0.006)\tLoss 0.0754 (0.1201)\tPrec 98.438% (95.783%)\n",
      "Epoch: [107][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 0.1103 (0.1209)\tPrec 96.094% (95.826%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3098 (0.3098)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.660% \n",
      "best acc: 89.100000\n",
      "Epoch: [108][0/391]\tTime 0.155 (0.155)\tData 0.118 (0.118)\tLoss 0.0790 (0.0790)\tPrec 97.656% (97.656%)\n",
      "Epoch: [108][100/391]\tTime 0.022 (0.027)\tData 0.000 (0.005)\tLoss 0.1742 (0.1221)\tPrec 93.750% (95.769%)\n",
      "Epoch: [108][200/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 0.1296 (0.1198)\tPrec 95.312% (95.779%)\n",
      "Epoch: [108][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0761 (0.1203)\tPrec 97.656% (95.821%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.2891 (0.2891)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.900% \n",
      "best acc: 89.100000\n",
      "Epoch: [109][0/391]\tTime 0.152 (0.152)\tData 0.114 (0.114)\tLoss 0.0806 (0.0806)\tPrec 97.656% (97.656%)\n",
      "Epoch: [109][100/391]\tTime 0.020 (0.027)\tData 0.000 (0.005)\tLoss 0.0621 (0.1148)\tPrec 97.656% (96.233%)\n",
      "Epoch: [109][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.1293 (0.1160)\tPrec 94.531% (96.098%)\n",
      "Epoch: [109][300/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 0.0660 (0.1157)\tPrec 99.219% (96.094%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3526 (0.3526)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.620% \n",
      "best acc: 89.100000\n",
      "Epoch: [110][0/391]\tTime 0.149 (0.149)\tData 0.119 (0.119)\tLoss 0.0642 (0.0642)\tPrec 97.656% (97.656%)\n",
      "Epoch: [110][100/391]\tTime 0.020 (0.027)\tData 0.001 (0.006)\tLoss 0.1891 (0.1145)\tPrec 96.094% (96.086%)\n",
      "Epoch: [110][200/391]\tTime 0.021 (0.026)\tData 0.000 (0.006)\tLoss 0.1933 (0.1187)\tPrec 94.531% (95.896%)\n",
      "Epoch: [110][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.1122 (0.1178)\tPrec 97.656% (95.987%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.089 (0.089)\tLoss 0.2512 (0.2512)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.920% \n",
      "best acc: 89.100000\n",
      "Epoch: [111][0/391]\tTime 0.157 (0.157)\tData 0.120 (0.120)\tLoss 0.1129 (0.1129)\tPrec 93.750% (93.750%)\n",
      "Epoch: [111][100/391]\tTime 0.031 (0.027)\tData 0.010 (0.006)\tLoss 0.1012 (0.1120)\tPrec 96.875% (96.187%)\n",
      "Epoch: [111][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.1119 (0.1141)\tPrec 96.094% (96.144%)\n",
      "Epoch: [111][300/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.1103 (0.1115)\tPrec 96.094% (96.195%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3000 (0.3000)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.060% \n",
      "best acc: 89.100000\n",
      "Epoch: [112][0/391]\tTime 0.152 (0.152)\tData 0.114 (0.114)\tLoss 0.1846 (0.1846)\tPrec 95.312% (95.312%)\n",
      "Epoch: [112][100/391]\tTime 0.020 (0.027)\tData 0.000 (0.006)\tLoss 0.0688 (0.1092)\tPrec 96.875% (96.140%)\n",
      "Epoch: [112][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 0.1026 (0.1150)\tPrec 96.875% (95.985%)\n",
      "Epoch: [112][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 0.1222 (0.1144)\tPrec 95.312% (96.052%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2395 (0.2395)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.920% \n",
      "best acc: 89.100000\n",
      "Epoch: [113][0/391]\tTime 0.146 (0.146)\tData 0.115 (0.115)\tLoss 0.1877 (0.1877)\tPrec 93.750% (93.750%)\n",
      "Epoch: [113][100/391]\tTime 0.020 (0.027)\tData 0.000 (0.005)\tLoss 0.1327 (0.1110)\tPrec 95.312% (96.024%)\n",
      "Epoch: [113][200/391]\tTime 0.023 (0.026)\tData 0.000 (0.005)\tLoss 0.0751 (0.1140)\tPrec 97.656% (95.989%)\n",
      "Epoch: [113][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.1364 (0.1133)\tPrec 95.312% (96.003%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.3414 (0.3414)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.710% \n",
      "best acc: 89.100000\n",
      "Epoch: [114][0/391]\tTime 0.148 (0.148)\tData 0.119 (0.119)\tLoss 0.1369 (0.1369)\tPrec 93.750% (93.750%)\n",
      "Epoch: [114][100/391]\tTime 0.025 (0.027)\tData 0.005 (0.005)\tLoss 0.1485 (0.1136)\tPrec 93.750% (96.001%)\n",
      "Epoch: [114][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.1218 (0.1113)\tPrec 95.312% (96.117%)\n",
      "Epoch: [114][300/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.1923 (0.1094)\tPrec 95.312% (96.182%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.2795 (0.2795)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.810% \n",
      "best acc: 89.100000\n",
      "Epoch: [115][0/391]\tTime 0.143 (0.143)\tData 0.114 (0.114)\tLoss 0.1082 (0.1082)\tPrec 96.875% (96.875%)\n",
      "Epoch: [115][100/391]\tTime 0.034 (0.027)\tData 0.010 (0.006)\tLoss 0.1789 (0.0985)\tPrec 94.531% (96.535%)\n",
      "Epoch: [115][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.0900 (0.1021)\tPrec 97.656% (96.541%)\n",
      "Epoch: [115][300/391]\tTime 0.030 (0.026)\tData 0.010 (0.005)\tLoss 0.1744 (0.1060)\tPrec 94.531% (96.346%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2470 (0.2470)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.740% \n",
      "best acc: 89.100000\n",
      "Epoch: [116][0/391]\tTime 0.151 (0.151)\tData 0.122 (0.122)\tLoss 0.1615 (0.1615)\tPrec 94.531% (94.531%)\n",
      "Epoch: [116][100/391]\tTime 0.020 (0.027)\tData 0.001 (0.005)\tLoss 0.0984 (0.1132)\tPrec 94.531% (96.132%)\n",
      "Epoch: [116][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.1069 (0.1086)\tPrec 95.312% (96.210%)\n",
      "Epoch: [116][300/391]\tTime 0.028 (0.025)\tData 0.001 (0.005)\tLoss 0.1201 (0.1102)\tPrec 95.312% (96.182%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2462 (0.2462)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.880% \n",
      "best acc: 89.100000\n",
      "Epoch: [117][0/391]\tTime 0.160 (0.160)\tData 0.119 (0.119)\tLoss 0.0830 (0.0830)\tPrec 96.875% (96.875%)\n",
      "Epoch: [117][100/391]\tTime 0.029 (0.027)\tData 0.009 (0.006)\tLoss 0.1715 (0.1074)\tPrec 95.312% (96.287%)\n",
      "Epoch: [117][200/391]\tTime 0.030 (0.026)\tData 0.009 (0.005)\tLoss 0.1418 (0.1109)\tPrec 93.750% (96.125%)\n",
      "Epoch: [117][300/391]\tTime 0.028 (0.025)\tData 0.007 (0.005)\tLoss 0.0561 (0.1118)\tPrec 98.438% (96.117%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3477 (0.3477)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.730% \n",
      "best acc: 89.100000\n",
      "Epoch: [118][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.0923 (0.0923)\tPrec 96.875% (96.875%)\n",
      "Epoch: [118][100/391]\tTime 0.026 (0.026)\tData 0.006 (0.005)\tLoss 0.0574 (0.1112)\tPrec 99.219% (96.202%)\n",
      "Epoch: [118][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.1581 (0.1079)\tPrec 94.531% (96.276%)\n",
      "Epoch: [118][300/391]\tTime 0.021 (0.025)\tData 0.000 (0.005)\tLoss 0.1190 (0.1067)\tPrec 96.094% (96.330%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.2048 (0.2048)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.030% \n",
      "best acc: 89.100000\n",
      "Epoch: [119][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.0847 (0.0847)\tPrec 96.094% (96.094%)\n",
      "Epoch: [119][100/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 0.0686 (0.1098)\tPrec 97.656% (96.063%)\n",
      "Epoch: [119][200/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.0620 (0.1089)\tPrec 97.656% (96.074%)\n",
      "Epoch: [119][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.1068 (0.1085)\tPrec 97.656% (96.073%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2406 (0.2406)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.920% \n",
      "best acc: 89.100000\n",
      "Epoch: [120][0/391]\tTime 0.147 (0.147)\tData 0.117 (0.117)\tLoss 0.0692 (0.0692)\tPrec 98.438% (98.438%)\n",
      "Epoch: [120][100/391]\tTime 0.020 (0.027)\tData 0.000 (0.005)\tLoss 0.1361 (0.0995)\tPrec 96.875% (96.620%)\n",
      "Epoch: [120][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0642 (0.1012)\tPrec 97.656% (96.521%)\n",
      "Epoch: [120][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0975 (0.0992)\tPrec 95.312% (96.543%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2685 (0.2685)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.130% \n",
      "best acc: 89.130000\n",
      "Epoch: [121][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.0709 (0.0709)\tPrec 95.312% (95.312%)\n",
      "Epoch: [121][100/391]\tTime 0.034 (0.027)\tData 0.013 (0.005)\tLoss 0.0998 (0.0910)\tPrec 94.531% (96.821%)\n",
      "Epoch: [121][200/391]\tTime 0.031 (0.026)\tData 0.011 (0.005)\tLoss 0.0650 (0.0987)\tPrec 98.438% (96.587%)\n",
      "Epoch: [121][300/391]\tTime 0.030 (0.026)\tData 0.010 (0.005)\tLoss 0.0777 (0.0987)\tPrec 97.656% (96.641%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.3280 (0.3280)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.240% \n",
      "best acc: 89.240000\n",
      "Epoch: [122][0/391]\tTime 0.151 (0.151)\tData 0.122 (0.122)\tLoss 0.0811 (0.0811)\tPrec 98.438% (98.438%)\n",
      "Epoch: [122][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.006)\tLoss 0.1452 (0.0985)\tPrec 94.531% (96.697%)\n",
      "Epoch: [122][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.0882 (0.0994)\tPrec 96.094% (96.591%)\n",
      "Epoch: [122][300/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.0617 (0.0972)\tPrec 96.094% (96.649%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2413 (0.2413)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.950% \n",
      "best acc: 89.240000\n",
      "Epoch: [123][0/391]\tTime 0.152 (0.152)\tData 0.115 (0.115)\tLoss 0.0524 (0.0524)\tPrec 98.438% (98.438%)\n",
      "Epoch: [123][100/391]\tTime 0.028 (0.027)\tData 0.008 (0.006)\tLoss 0.0298 (0.0868)\tPrec 98.438% (97.006%)\n",
      "Epoch: [123][200/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 0.0771 (0.0933)\tPrec 97.656% (96.937%)\n",
      "Epoch: [123][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.0708 (0.0952)\tPrec 96.875% (96.810%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2918 (0.2918)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.110% \n",
      "best acc: 89.240000\n",
      "Epoch: [124][0/391]\tTime 0.153 (0.153)\tData 0.116 (0.116)\tLoss 0.0617 (0.0617)\tPrec 97.656% (97.656%)\n",
      "Epoch: [124][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0796 (0.0944)\tPrec 98.438% (97.006%)\n",
      "Epoch: [124][200/391]\tTime 0.023 (0.026)\tData 0.000 (0.005)\tLoss 0.0857 (0.0958)\tPrec 97.656% (96.852%)\n",
      "Epoch: [124][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0770 (0.0936)\tPrec 96.875% (96.917%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.2835 (0.2835)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.000% \n",
      "best acc: 89.240000\n",
      "Epoch: [125][0/391]\tTime 0.151 (0.151)\tData 0.114 (0.114)\tLoss 0.0582 (0.0582)\tPrec 96.875% (96.875%)\n",
      "Epoch: [125][100/391]\tTime 0.033 (0.029)\tData 0.011 (0.005)\tLoss 0.0589 (0.0919)\tPrec 96.875% (96.790%)\n",
      "Epoch: [125][200/391]\tTime 0.022 (0.027)\tData 0.002 (0.005)\tLoss 0.0671 (0.0897)\tPrec 96.875% (96.852%)\n",
      "Epoch: [125][300/391]\tTime 0.021 (0.026)\tData 0.001 (0.005)\tLoss 0.0407 (0.0909)\tPrec 100.000% (96.854%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2573 (0.2573)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.150% \n",
      "best acc: 89.240000\n",
      "Epoch: [126][0/391]\tTime 0.144 (0.144)\tData 0.115 (0.115)\tLoss 0.0775 (0.0775)\tPrec 96.875% (96.875%)\n",
      "Epoch: [126][100/391]\tTime 0.022 (0.026)\tData 0.002 (0.006)\tLoss 0.0970 (0.0916)\tPrec 96.094% (97.037%)\n",
      "Epoch: [126][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0869 (0.0950)\tPrec 95.312% (96.883%)\n",
      "Epoch: [126][300/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.0979 (0.0927)\tPrec 96.094% (96.901%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2932 (0.2932)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.230% \n",
      "best acc: 89.240000\n",
      "Epoch: [127][0/391]\tTime 0.151 (0.151)\tData 0.113 (0.113)\tLoss 0.0752 (0.0752)\tPrec 96.875% (96.875%)\n",
      "Epoch: [127][100/391]\tTime 0.028 (0.028)\tData 0.009 (0.005)\tLoss 0.1675 (0.0953)\tPrec 94.531% (96.481%)\n",
      "Epoch: [127][200/391]\tTime 0.022 (0.026)\tData 0.002 (0.005)\tLoss 0.1224 (0.0934)\tPrec 97.656% (96.669%)\n",
      "Epoch: [127][300/391]\tTime 0.022 (0.026)\tData 0.002 (0.005)\tLoss 0.1083 (0.0929)\tPrec 96.094% (96.691%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.2029 (0.2029)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.130% \n",
      "best acc: 89.240000\n",
      "Epoch: [128][0/391]\tTime 0.157 (0.157)\tData 0.120 (0.120)\tLoss 0.0899 (0.0899)\tPrec 96.875% (96.875%)\n",
      "Epoch: [128][100/391]\tTime 0.029 (0.027)\tData 0.009 (0.005)\tLoss 0.0569 (0.0942)\tPrec 98.438% (96.999%)\n",
      "Epoch: [128][200/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.0647 (0.0948)\tPrec 96.875% (96.793%)\n",
      "Epoch: [128][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.1325 (0.0945)\tPrec 96.094% (96.792%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.2183 (0.2183)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.100% \n",
      "best acc: 89.240000\n",
      "Epoch: [129][0/391]\tTime 0.147 (0.147)\tData 0.118 (0.118)\tLoss 0.0926 (0.0926)\tPrec 96.875% (96.875%)\n",
      "Epoch: [129][100/391]\tTime 0.023 (0.028)\tData 0.000 (0.005)\tLoss 0.0825 (0.1000)\tPrec 97.656% (96.511%)\n",
      "Epoch: [129][200/391]\tTime 0.021 (0.027)\tData 0.000 (0.005)\tLoss 0.0868 (0.0948)\tPrec 95.312% (96.603%)\n",
      "Epoch: [129][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.1580 (0.0955)\tPrec 95.312% (96.641%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.2307 (0.2307)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.220% \n",
      "best acc: 89.240000\n",
      "Epoch: [130][0/391]\tTime 0.142 (0.142)\tData 0.112 (0.112)\tLoss 0.2230 (0.2230)\tPrec 92.969% (92.969%)\n",
      "Epoch: [130][100/391]\tTime 0.033 (0.027)\tData 0.010 (0.006)\tLoss 0.1060 (0.0972)\tPrec 96.094% (96.682%)\n",
      "Epoch: [130][200/391]\tTime 0.026 (0.026)\tData 0.006 (0.005)\tLoss 0.0845 (0.0935)\tPrec 96.875% (96.809%)\n",
      "Epoch: [130][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.0658 (0.0923)\tPrec 96.875% (96.836%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.3180 (0.3180)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.270% \n",
      "best acc: 89.270000\n",
      "Epoch: [131][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 0.0684 (0.0684)\tPrec 97.656% (97.656%)\n",
      "Epoch: [131][100/391]\tTime 0.020 (0.028)\tData 0.000 (0.005)\tLoss 0.0880 (0.0984)\tPrec 96.094% (96.805%)\n",
      "Epoch: [131][200/391]\tTime 0.031 (0.027)\tData 0.012 (0.005)\tLoss 0.1137 (0.0968)\tPrec 96.094% (96.665%)\n",
      "Epoch: [131][300/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.1356 (0.0934)\tPrec 96.875% (96.740%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2601 (0.2601)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.250% \n",
      "best acc: 89.270000\n",
      "Epoch: [132][0/391]\tTime 0.143 (0.143)\tData 0.114 (0.114)\tLoss 0.0839 (0.0839)\tPrec 97.656% (97.656%)\n",
      "Epoch: [132][100/391]\tTime 0.033 (0.027)\tData 0.011 (0.005)\tLoss 0.0687 (0.0897)\tPrec 97.656% (96.976%)\n",
      "Epoch: [132][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0514 (0.0883)\tPrec 97.656% (97.019%)\n",
      "Epoch: [132][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0713 (0.0891)\tPrec 96.875% (96.968%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2734 (0.2734)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.260% \n",
      "best acc: 89.270000\n",
      "Epoch: [133][0/391]\tTime 0.147 (0.147)\tData 0.117 (0.117)\tLoss 0.0291 (0.0291)\tPrec 100.000% (100.000%)\n",
      "Epoch: [133][100/391]\tTime 0.020 (0.027)\tData 0.000 (0.005)\tLoss 0.1243 (0.0925)\tPrec 96.094% (96.860%)\n",
      "Epoch: [133][200/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 0.0789 (0.0908)\tPrec 96.875% (96.867%)\n",
      "Epoch: [133][300/391]\tTime 0.027 (0.025)\tData 0.006 (0.005)\tLoss 0.0476 (0.0907)\tPrec 99.219% (96.867%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2973 (0.2973)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.100% \n",
      "best acc: 89.270000\n",
      "Epoch: [134][0/391]\tTime 0.148 (0.148)\tData 0.117 (0.117)\tLoss 0.0782 (0.0782)\tPrec 96.875% (96.875%)\n",
      "Epoch: [134][100/391]\tTime 0.035 (0.026)\tData 0.013 (0.005)\tLoss 0.1188 (0.0941)\tPrec 95.312% (96.720%)\n",
      "Epoch: [134][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0773 (0.0941)\tPrec 96.875% (96.723%)\n",
      "Epoch: [134][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.1211 (0.0943)\tPrec 93.750% (96.748%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2822 (0.2822)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.690% \n",
      "best acc: 89.270000\n",
      "Epoch: [135][0/391]\tTime 0.151 (0.151)\tData 0.114 (0.114)\tLoss 0.0889 (0.0889)\tPrec 98.438% (98.438%)\n",
      "Epoch: [135][100/391]\tTime 0.026 (0.026)\tData 0.006 (0.005)\tLoss 0.0480 (0.0918)\tPrec 98.438% (96.821%)\n",
      "Epoch: [135][200/391]\tTime 0.029 (0.026)\tData 0.010 (0.005)\tLoss 0.0932 (0.0871)\tPrec 96.875% (97.003%)\n",
      "Epoch: [135][300/391]\tTime 0.029 (0.026)\tData 0.009 (0.005)\tLoss 0.0976 (0.0904)\tPrec 96.875% (96.922%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2642 (0.2642)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.420% \n",
      "best acc: 89.420000\n",
      "Epoch: [136][0/391]\tTime 0.141 (0.141)\tData 0.112 (0.112)\tLoss 0.1274 (0.1274)\tPrec 95.312% (95.312%)\n",
      "Epoch: [136][100/391]\tTime 0.029 (0.026)\tData 0.001 (0.005)\tLoss 0.0588 (0.0870)\tPrec 96.094% (96.937%)\n",
      "Epoch: [136][200/391]\tTime 0.021 (0.026)\tData 0.001 (0.004)\tLoss 0.1077 (0.0884)\tPrec 96.875% (96.926%)\n",
      "Epoch: [136][300/391]\tTime 0.021 (0.026)\tData 0.000 (0.004)\tLoss 0.0482 (0.0893)\tPrec 98.438% (96.942%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2467 (0.2467)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.040% \n",
      "best acc: 89.420000\n",
      "Epoch: [137][0/391]\tTime 0.144 (0.144)\tData 0.114 (0.114)\tLoss 0.0990 (0.0990)\tPrec 96.094% (96.094%)\n",
      "Epoch: [137][100/391]\tTime 0.028 (0.026)\tData 0.006 (0.005)\tLoss 0.1081 (0.0909)\tPrec 96.094% (96.829%)\n",
      "Epoch: [137][200/391]\tTime 0.032 (0.026)\tData 0.004 (0.004)\tLoss 0.0604 (0.0948)\tPrec 96.094% (96.657%)\n",
      "Epoch: [137][300/391]\tTime 0.024 (0.026)\tData 0.004 (0.004)\tLoss 0.0835 (0.0929)\tPrec 96.094% (96.761%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.2652 (0.2652)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.850% \n",
      "best acc: 89.420000\n",
      "Epoch: [138][0/391]\tTime 0.155 (0.155)\tData 0.125 (0.125)\tLoss 0.0513 (0.0513)\tPrec 96.875% (96.875%)\n",
      "Epoch: [138][100/391]\tTime 0.029 (0.027)\tData 0.000 (0.005)\tLoss 0.0270 (0.0896)\tPrec 100.000% (96.790%)\n",
      "Epoch: [138][200/391]\tTime 0.023 (0.028)\tData 0.001 (0.004)\tLoss 0.1070 (0.0868)\tPrec 97.656% (96.914%)\n",
      "Epoch: [138][300/391]\tTime 0.022 (0.027)\tData 0.001 (0.004)\tLoss 0.0978 (0.0877)\tPrec 96.094% (96.922%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.2213 (0.2213)\tPrec 94.531% (94.531%)\n",
      " * Prec 89.180% \n",
      "best acc: 89.420000\n",
      "Epoch: [139][0/391]\tTime 0.154 (0.154)\tData 0.124 (0.124)\tLoss 0.1099 (0.1099)\tPrec 94.531% (94.531%)\n",
      "Epoch: [139][100/391]\tTime 0.022 (0.026)\tData 0.000 (0.005)\tLoss 0.1052 (0.0876)\tPrec 95.312% (96.666%)\n",
      "Epoch: [139][200/391]\tTime 0.030 (0.026)\tData 0.009 (0.005)\tLoss 0.0940 (0.0869)\tPrec 94.531% (96.793%)\n",
      "Epoch: [139][300/391]\tTime 0.030 (0.026)\tData 0.009 (0.004)\tLoss 0.0543 (0.0882)\tPrec 98.438% (96.815%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 0.2610 (0.2610)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.160% \n",
      "best acc: 89.420000\n",
      "Epoch: [140][0/391]\tTime 0.146 (0.146)\tData 0.116 (0.116)\tLoss 0.0639 (0.0639)\tPrec 98.438% (98.438%)\n",
      "Epoch: [140][100/391]\tTime 0.026 (0.027)\tData 0.002 (0.005)\tLoss 0.0463 (0.0950)\tPrec 99.219% (96.689%)\n",
      "Epoch: [140][200/391]\tTime 0.025 (0.026)\tData 0.000 (0.004)\tLoss 0.0623 (0.0898)\tPrec 97.656% (96.887%)\n",
      "Epoch: [140][300/391]\tTime 0.021 (0.026)\tData 0.000 (0.004)\tLoss 0.1070 (0.0918)\tPrec 97.656% (96.782%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2958 (0.2958)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.130% \n",
      "best acc: 89.420000\n",
      "Epoch: [141][0/391]\tTime 0.145 (0.145)\tData 0.116 (0.116)\tLoss 0.0447 (0.0447)\tPrec 97.656% (97.656%)\n",
      "Epoch: [141][100/391]\tTime 0.029 (0.028)\tData 0.008 (0.005)\tLoss 0.0743 (0.0894)\tPrec 97.656% (96.798%)\n",
      "Epoch: [141][200/391]\tTime 0.027 (0.026)\tData 0.007 (0.005)\tLoss 0.1329 (0.0870)\tPrec 96.875% (96.992%)\n",
      "Epoch: [141][300/391]\tTime 0.030 (0.026)\tData 0.009 (0.004)\tLoss 0.0581 (0.0878)\tPrec 97.656% (96.945%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2527 (0.2527)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.080% \n",
      "best acc: 89.420000\n",
      "Epoch: [142][0/391]\tTime 0.146 (0.146)\tData 0.117 (0.117)\tLoss 0.0591 (0.0591)\tPrec 96.875% (96.875%)\n",
      "Epoch: [142][100/391]\tTime 0.031 (0.027)\tData 0.002 (0.005)\tLoss 0.0911 (0.0856)\tPrec 96.094% (97.115%)\n",
      "Epoch: [142][200/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 0.0726 (0.0903)\tPrec 96.094% (96.828%)\n",
      "Epoch: [142][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.004)\tLoss 0.0690 (0.0916)\tPrec 98.438% (96.800%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.2903 (0.2903)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.510% \n",
      "best acc: 89.510000\n",
      "Epoch: [143][0/391]\tTime 0.151 (0.151)\tData 0.114 (0.114)\tLoss 0.0960 (0.0960)\tPrec 95.312% (95.312%)\n",
      "Epoch: [143][100/391]\tTime 0.021 (0.027)\tData 0.000 (0.004)\tLoss 0.0979 (0.0916)\tPrec 96.094% (96.829%)\n",
      "Epoch: [143][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0490 (0.0874)\tPrec 98.438% (96.964%)\n",
      "Epoch: [143][300/391]\tTime 0.026 (0.026)\tData 0.001 (0.005)\tLoss 0.0581 (0.0895)\tPrec 96.875% (96.911%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.2956 (0.2956)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.330% \n",
      "best acc: 89.510000\n",
      "Epoch: [144][0/391]\tTime 0.142 (0.142)\tData 0.113 (0.113)\tLoss 0.1245 (0.1245)\tPrec 97.656% (97.656%)\n",
      "Epoch: [144][100/391]\tTime 0.021 (0.027)\tData 0.000 (0.005)\tLoss 0.0759 (0.0886)\tPrec 97.656% (96.836%)\n",
      "Epoch: [144][200/391]\tTime 0.030 (0.026)\tData 0.008 (0.005)\tLoss 0.0559 (0.0872)\tPrec 96.875% (96.879%)\n",
      "Epoch: [144][300/391]\tTime 0.027 (0.026)\tData 0.007 (0.005)\tLoss 0.0915 (0.0883)\tPrec 96.094% (96.867%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.2805 (0.2805)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.200% \n",
      "best acc: 89.510000\n",
      "Epoch: [145][0/391]\tTime 0.152 (0.152)\tData 0.123 (0.123)\tLoss 0.1310 (0.1310)\tPrec 95.312% (95.312%)\n",
      "Epoch: [145][100/391]\tTime 0.030 (0.027)\tData 0.010 (0.005)\tLoss 0.0338 (0.0877)\tPrec 99.219% (96.999%)\n",
      "Epoch: [145][200/391]\tTime 0.037 (0.028)\tData 0.007 (0.005)\tLoss 0.0673 (0.0884)\tPrec 99.219% (96.980%)\n",
      "Epoch: [145][300/391]\tTime 0.031 (0.027)\tData 0.010 (0.005)\tLoss 0.1844 (0.0880)\tPrec 95.312% (97.018%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.2549 (0.2549)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.900% \n",
      "best acc: 89.510000\n",
      "Epoch: [146][0/391]\tTime 0.154 (0.154)\tData 0.115 (0.115)\tLoss 0.0783 (0.0783)\tPrec 97.656% (97.656%)\n",
      "Epoch: [146][100/391]\tTime 0.021 (0.027)\tData 0.000 (0.005)\tLoss 0.0492 (0.0842)\tPrec 99.219% (96.929%)\n",
      "Epoch: [146][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.004)\tLoss 0.0992 (0.0839)\tPrec 97.656% (97.042%)\n",
      "Epoch: [146][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.004)\tLoss 0.0549 (0.0851)\tPrec 98.438% (97.015%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.3052 (0.3052)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.020% \n",
      "best acc: 89.510000\n",
      "Epoch: [147][0/391]\tTime 0.145 (0.145)\tData 0.116 (0.116)\tLoss 0.0756 (0.0756)\tPrec 96.875% (96.875%)\n",
      "Epoch: [147][100/391]\tTime 0.022 (0.027)\tData 0.002 (0.005)\tLoss 0.0951 (0.0904)\tPrec 96.094% (96.875%)\n",
      "Epoch: [147][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0605 (0.0906)\tPrec 97.656% (96.801%)\n",
      "Epoch: [147][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.1291 (0.0873)\tPrec 94.531% (96.893%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2654 (0.2654)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.020% \n",
      "best acc: 89.510000\n",
      "Epoch: [148][0/391]\tTime 0.158 (0.158)\tData 0.121 (0.121)\tLoss 0.0431 (0.0431)\tPrec 98.438% (98.438%)\n",
      "Epoch: [148][100/391]\tTime 0.022 (0.027)\tData 0.002 (0.004)\tLoss 0.1520 (0.0847)\tPrec 94.531% (97.092%)\n",
      "Epoch: [148][200/391]\tTime 0.028 (0.026)\tData 0.008 (0.004)\tLoss 0.0624 (0.0886)\tPrec 96.875% (96.964%)\n",
      "Epoch: [148][300/391]\tTime 0.026 (0.025)\tData 0.007 (0.004)\tLoss 0.0761 (0.0890)\tPrec 96.875% (96.919%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.3034 (0.3034)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.480% \n",
      "best acc: 89.510000\n",
      "Epoch: [149][0/391]\tTime 0.152 (0.152)\tData 0.115 (0.115)\tLoss 0.0418 (0.0418)\tPrec 99.219% (99.219%)\n",
      "Epoch: [149][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.006)\tLoss 0.0607 (0.0836)\tPrec 98.438% (97.084%)\n",
      "Epoch: [149][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.005)\tLoss 0.0682 (0.0862)\tPrec 97.656% (97.003%)\n",
      "Epoch: [149][300/391]\tTime 0.030 (0.026)\tData 0.011 (0.006)\tLoss 0.0585 (0.0869)\tPrec 98.438% (96.989%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 0.3030 (0.3030)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.000% \n",
      "best acc: 89.510000\n"
     ]
    }
   ],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 150\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "YQg2o7MPawrh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1561,
     "status": "ok",
     "timestamp": 1763966384991,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "YQg2o7MPawrh",
    "outputId": "7b479a33-92a6-4dc1-db7e-3d4e285166ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8939/10000 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"./result/VGG16_quant2b4b/model_best.pth.tar\"\n",
    "model_name = \"VGG16_project_2b4b\"\n",
    "model = VGG16_project()\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceramic-nigeria",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1763965324957,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "ceramic-nigeria",
    "outputId": "98e52941-9f12-435b-88d9-67e01abaef52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 1\n",
      "7 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 2\n",
      "12 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 3\n",
      "16 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 4\n",
      "21 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 5\n",
      "25 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 6\n",
      "29 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 7\n",
      "34 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 8\n",
      "38 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 9\n",
      "41 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 10\n",
      "46 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 11\n",
      "50 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 12\n",
      "54 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "\n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "counter = 0\n",
    "for layer in model.modules():\n",
    "    i+=1\n",
    "    # print(i,\"-th layer:\",layer)\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        counter+=1\n",
    "        print(layer, counter)\n",
    "        layer.register_forward_pre_hook(save_output)\n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spoken-worst",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1763965390270,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "spoken-worst",
    "outputId": "83479d0b-6350-4532-9ec5-af3e49f0628a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Int Shape: torch.Size([16, 16, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.features[27].weight_q # quantized value is stored during the training\n",
    "w_alpha = model.features[27].weight_quant.wgt_alpha   # alpha is defined in your model already. bring it out here\n",
    "w_delta = w_alpha/(2**(w_bit-1)-1)   # delta can be calculated by using alpha and w_bit\n",
    "weight_int = weight_q/w_delta # w_int can be calculated by weight_q and w_delta\n",
    "# print(weight_int) # you should see clean integer numbers\n",
    "print(f\"Weight Int Shape: {weight_int.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0a6888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-6.0000, -4.0000, -5.0000],\n",
      "         [ 1.0000, -1.0000, -7.0000],\n",
      "         [-7.0000, -6.0000, -4.0000]],\n",
      "\n",
      "        [[ 5.0000,  3.0000,  1.0000],\n",
      "         [ 7.0000,  1.0000,  1.0000],\n",
      "         [ 7.0000,  4.0000, -1.0000]],\n",
      "\n",
      "        [[-2.0000, -3.0000, -2.0000],\n",
      "         [-5.0000, -6.0000, -6.0000],\n",
      "         [-4.0000, -7.0000, -4.0000]],\n",
      "\n",
      "        [[-0.0000,  1.0000,  2.0000],\n",
      "         [ 1.0000, -4.0000, -2.0000],\n",
      "         [-3.0000, -3.0000,  1.0000]],\n",
      "\n",
      "        [[-2.0000, -5.0000, -6.0000],\n",
      "         [ 4.0000,  7.0000,  7.0000],\n",
      "         [ 1.0000,  5.0000,  2.0000]],\n",
      "\n",
      "        [[-3.0000,  0.0000,  2.0000],\n",
      "         [-3.0000, -7.0000,  1.0000],\n",
      "         [-2.0000,  2.0000,  7.0000]],\n",
      "\n",
      "        [[-4.0000, -5.0000, -3.0000],\n",
      "         [-1.0000, -2.0000,  7.0000],\n",
      "         [ 1.0000,  3.0000,  7.0000]],\n",
      "\n",
      "        [[-2.0000, -6.0000, -3.0000],\n",
      "         [-5.0000, -4.0000, -2.0000],\n",
      "         [-2.0000, -7.0000, -7.0000]],\n",
      "\n",
      "        [[ 4.0000,  6.0000,  7.0000],\n",
      "         [ 2.0000,  7.0000,  7.0000],\n",
      "         [-3.0000,  2.0000,  0.0000]],\n",
      "\n",
      "        [[ 1.0000, -1.0000,  5.0000],\n",
      "         [ 5.0000,  0.0000,  7.0000],\n",
      "         [-3.0000, -4.0000,  2.0000]],\n",
      "\n",
      "        [[-4.0000, -7.0000, -3.0000],\n",
      "         [-0.0000, -2.0000, -1.0000],\n",
      "         [ 7.0000,  7.0000,  7.0000]],\n",
      "\n",
      "        [[-4.0000, -7.0000, -7.0000],\n",
      "         [-1.0000, -1.0000, -1.0000],\n",
      "         [-7.0000, -4.0000,  2.0000]],\n",
      "\n",
      "        [[-2.0000, -3.0000, -3.0000],\n",
      "         [ 0.0000,  0.0000,  2.0000],\n",
      "         [-2.0000,  2.0000,  7.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  2.0000],\n",
      "         [-4.0000, -5.0000, -5.0000],\n",
      "         [-2.0000, -3.0000, -2.0000]],\n",
      "\n",
      "        [[-3.0000, -2.0000, -4.0000],\n",
      "         [-5.0000, -7.0000, -2.0000],\n",
      "         [-3.0000, -7.0000, -7.0000]],\n",
      "\n",
      "        [[ 3.0000,  4.0000,  2.0000],\n",
      "         [ 1.0000,  2.0000,  1.0000],\n",
      "         [ 1.0000,  2.0000,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(weight_int[0][:][:][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interior-oxygen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1763965392140,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "interior-oxygen",
    "outputId": "b7d42500-4537-453c-88b7-0f37fa0d7262",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([128, 16, 4, 4])\n",
      "Input Int Sample: tensor([2.0000, 3.0000, 2.0000, 2.0000], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_bit = 2\n",
    "x = save_output.outputs[8][0]  # input of the 2nd conv layer\n",
    "print(f\"Input Shape: {x.shape}\")\n",
    "x_alpha  = model.features[27].act_alpha\n",
    "x_delta = x_alpha/(2**x_bit-1)\n",
    "\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x_q = act_quant_fn(x, x_alpha)         # create the quantized value for x\n",
    "\n",
    "x_int = x_q/x_delta\n",
    "print(f\"Input Int Sample: {x_int[0,0,0,:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abd6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "designed-auction",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1763965409165,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "designed-auction"
   },
   "outputs": [],
   "source": [
    "#### input floating number / weight quantized version\n",
    "\n",
    "conv_ref = torch.nn.Conv2d(in_channels = 16, out_channels=16, kernel_size = 3, padding=1, bias = False)\n",
    "conv_ref.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "output_int = conv_ref(x_int)\n",
    "\n",
    "output_recovered = output_int*x_delta*w_delta\n",
    "relu = nn.ReLU(inplace=True)\n",
    "relu_output_recovered = relu(output_recovered)\n",
    "\n",
    "output_ref = save_output.outputs[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157dffd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1763965410934,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "157dffd8",
    "outputId": "95a536cc-ca17-445e-afc7-3e2eac3f6bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1046e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "difference = abs( output_ref - relu_output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "significant-whole",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1763965425110,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "significant-whole",
    "outputId": "f0419622-4a17-462c-8423-b20e7db14b04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 36])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad = torch.zeros(128, 16, 6, 6).to(x_int.device)\n",
    "x_pad[:, :, 1:5, 1:5] = x_int\n",
    "x_pad_in = x_pad[0]\n",
    "X = x_pad_in.reshape(x_pad_in.size(0), -1)\n",
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb82069f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 16, 6, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "corresponding-significance",
   "metadata": {
    "id": "corresponding-significance"
   },
   "outputs": [],
   "source": [
    "bit_precision = 2\n",
    "file_path = 'activation2b4b.txt'\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write('//Format:[Row15_MSB...Row0_LSB](Each-row-is-4-bit)\\n')\n",
    "    f.write('//Time-step-0-to-35\\n')\n",
    "\n",
    "    for i in range(X.size(1)):\n",
    "        line_bin = \"\"\n",
    "\n",
    "        for j in range(X.size(0)):\n",
    "            val = int(round(X[15-j, i].item()))\n",
    "\n",
    "            val_2s = val & 0xF\n",
    "\n",
    "            line_bin += f'{val_2s:04b}'\n",
    "\n",
    "        f.write(line_bin + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "P-anPbG6Kl6z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1763674061094,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "P-anPbG6Kl6z",
    "outputId": "ce040843-0955-441d-e67c-55ec147fa71e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 3, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_int.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "minimal-serbia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1763674036585,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "minimal-serbia",
    "outputId": "830c4097-e654-4056-8a95-455c226d8227"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))\n",
    "W.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7780ff3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 9])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = weight_int.reshape(weight_int.size(0), weight_int.size(1), -1)\n",
    "W.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "W0o2upN-KvJm",
   "metadata": {
    "id": "W0o2upN-KvJm"
   },
   "outputs": [],
   "source": [
    "\n",
    "bit_precision = 4\n",
    "file_path = 'weight2b4b.txt'\n",
    "\n",
    "och_tile=8\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write('//Format:[Row15_MSB...Row0_LSB]for_specific_Col_and_Kernel_idx\\n')\n",
    "    f.write('//Layout:K_ij->Output_Ch(Col)->Input_Ch(Row)\\n')\n",
    "\n",
    "    for kij in range(W.size(2)):\n",
    "        for och_t in range(int(W.size(0)/och_tile)):\n",
    "            for i in range(och_tile):\n",
    "                line_bin = \"\"\n",
    "\n",
    "                for j in range(W.size(1)):\n",
    "                    val = int(round(W[i+och_t*och_tile, 15-j, kij].item()))\n",
    "\n",
    "                    val_2s = val & 0xF\n",
    "\n",
    "                    line_bin += f'{val_2s:04b}'\n",
    "\n",
    "                f.write(line_bin + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pxR9Na_VLDAp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1763674174852,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "pxR9Na_VLDAp",
    "outputId": "b9e369df-4f53-423c-ed0b-093aaa7c5033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.,  5., -2., -0., -2., -3., -4., -2.,  4.,  1., -4., -4., -2.,  1.,\n",
       "        -3.,  3.], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b97ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 36, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psum = torch.zeros(16, X.size(1), 9).to(device)\n",
    "psum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4jMH_fdkLJtd",
   "metadata": {
    "id": "4jMH_fdkLJtd"
   },
   "outputs": [],
   "source": [
    "\n",
    "for kij in range(9):\n",
    "    W_k = W[:, :, kij]\n",
    "\n",
    "\n",
    "    psum_slice = torch.matmul(W_k.float(), X.float())\n",
    "\n",
    "    psum[:, :, kij] = psum_slice\n",
    "\n",
    "bit_precision = 16\n",
    "file_path = 'psum.txt'\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write('//Format:[Col7_MSB...Col0_LSB](Each 16-bit)\\n')\n",
    "    f.write('//Order:LoopKernel(9)->LoopTime(36)\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "    for kij in range(9):\n",
    "        for och_t in range(int(W.size(0)/och_tile)):\n",
    "            for i in range(psum.size(1)):\n",
    "                line_bin = \"\"\n",
    "\n",
    "                for j in range(och_tile):\n",
    "                    val = int(round(psum[7-j+och_t*och_tile, i, kij].item()))\n",
    "\n",
    "                    val_2s = val & 0xFFFF\n",
    "\n",
    "                    line_bin += f'{val_2s:016b}'\n",
    "\n",
    "                f.write(line_bin + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb147609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = output_int[0]\n",
    "out = out.reshape(out.size(0), -1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "822c3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "_1SmPoKDMmpE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1763674621565,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "_1SmPoKDMmpE",
    "outputId": "c837755e-1af2-4da1-aa7c-1f6f578c3501"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # out_relu = F.relu(output_int)\n",
    "# out = output_int[0]\n",
    "# out = out.reshape(out.size(0), -1)\n",
    "\n",
    "\n",
    "bit_precision = 16\n",
    "file_path = 'output2b4b.txt'\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write('//Format:[Col7_MSB...Col0_LSB](Each16-bit)\\n')\n",
    "    f.write('//FinalOutput\\n')\n",
    "\n",
    "    for och_t in range(int(W.size(0)/och_tile)):\n",
    "\n",
    "        for i in range(out.size(1)):\n",
    "            line_bin = \"\"\n",
    "\n",
    "            # Loop Channel (Row 7 -> Row 0)\n",
    "            for j in range(och_tile):\n",
    "                val = int(round(out[7-j+och_t*och_tile, i].item()))\n",
    "\n",
    "                val_bin = val & 0xFFFF\n",
    "\n",
    "                line_bin += f'{val_bin:016b}'\n",
    "\n",
    "            f.write(line_bin + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "810b3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'output2b4b.txt'\n",
    "output_hex_path = 'output_hex.txt'\n",
    "\n",
    "with open(file_path, 'r') as f_in, open(output_hex_path, 'w') as f_out:\n",
    "    for line in f_in:\n",
    "        line = line.strip()\n",
    "        if line.startswith('//'):\n",
    "            # f_out.write(line + '\\n')\n",
    "            continue\n",
    "        else:\n",
    "            # Convert 128-bit binary string to hex\n",
    "            hex_value = hex(int(line, 2))[2:].upper().zfill(32)\n",
    "            f_out.write(hex_value + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "w = weight_int[0]              # : [in_channels, 3, 3]\n",
    "x = x_pad[0,:, 0:3, 0:3]         # : [in_channels, 3, 3]\n",
    "\n",
    "# \n",
    "w_flat = w.reshape(w.size(0), -1)      # [in_channels, 9]\n",
    "x_flat = x.reshape(x.size(0), -1)      # [in_channels, 9]\n",
    "\n",
    "print(w_flat.shape)\n",
    "print(x_flat.shape)\n",
    "\n",
    "# output_int: \n",
    "oout = torch.sum(w_flat * x_flat, dim=0)  # [9]\n",
    "\n",
    "print(oout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1fd1628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from notebook context...\n",
      "Tensors moved to device: cuda\n",
      "x_pad_in device: cuda:0\n",
      "weight_int device: cuda:0\n",
      "=== Systolic Array Simulation with Detailed Output ===\n",
      "Device: cuda:0\n",
      "Input shape: torch.Size([16, 6, 6])\n",
      "Weight shape: torch.Size([16, 16, 3, 3])\n",
      "OCH tile size: 8\n",
      "\n",
      "Simulation parameters:\n",
      "- Total output channels: 16\n",
      "- Number of OCH tiles: 2\n",
      "- Spatial positions (nij): 16\n",
      "- Kernel elements (kij): 9\n",
      "\n",
      "--- Processing kij = 0 ---\n",
      "  --- Processing och_tile = 0 ---\n",
      "    Weight tile shape for kij=0: torch.Size([8, 16])\n",
      "    Cycle 0: nij=0\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 1: nij=1\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 2: nij=2\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 3: nij=3\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 4: nij=4\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 5: nij=5\n",
      "      och[ 0]: FFF5\n",
      "      och[ 1]: FFF1\n",
      "      och[ 2]: 0003\n",
      "      och[ 3]: 0016\n",
      "      och[ 4]: 0025\n",
      "      och[ 5]: 0005\n",
      "      och[ 6]: FFF5\n",
      "      och[ 7]: 0005\n",
      "    Cycle 6: nij=6\n",
      "      och[ 0]: FFE2\n",
      "      och[ 1]: FFF9\n",
      "      och[ 2]: 0003\n",
      "      och[ 3]: 0024\n",
      "      och[ 4]: 002A\n",
      "      och[ 5]: 0004\n",
      "      och[ 6]: FFFE\n",
      "      och[ 7]: 0000\n",
      "    Cycle 7: nij=7\n",
      "      och[ 0]: FFF0\n",
      "      och[ 1]: FFEF\n",
      "      och[ 2]: 0002\n",
      "      och[ 3]: 001F\n",
      "      och[ 4]: 002D\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: FFEA\n",
      "      och[ 7]: 0009\n",
      "    Cycle 8: nij=8\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 9: nij=9\n",
      "      och[ 0]: FFE5\n",
      "      och[ 1]: 0002\n",
      "      och[ 2]: FFFA\n",
      "      och[ 3]: 0025\n",
      "      och[ 4]: 0019\n",
      "      och[ 5]: 0003\n",
      "      och[ 6]: 0008\n",
      "      och[ 7]: FFEF\n",
      "    Cycle 10: nij=10\n",
      "      och[ 0]: FFDF\n",
      "      och[ 1]: FFF6\n",
      "      och[ 2]: FFFD\n",
      "      och[ 3]: 0029\n",
      "      och[ 4]: 0027\n",
      "      och[ 5]: FFFB\n",
      "      och[ 6]: FFFB\n",
      "      och[ 7]: FFF9\n",
      "    Cycle 11: nij=11\n",
      "      och[ 0]: FFDF\n",
      "      och[ 1]: FFF7\n",
      "      och[ 2]: FFFD\n",
      "      och[ 3]: 0024\n",
      "      och[ 4]: 0024\n",
      "      och[ 5]: FFF4\n",
      "      och[ 6]: FFF4\n",
      "      och[ 7]: FFFA\n",
      "    Cycle 12: nij=12\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 13: nij=13\n",
      "      och[ 0]: FFE3\n",
      "      och[ 1]: FFF3\n",
      "      och[ 2]: FFFD\n",
      "      och[ 3]: 0014\n",
      "      och[ 4]: 001F\n",
      "      och[ 5]: FFEF\n",
      "      och[ 6]: FFF7\n",
      "      och[ 7]: FFF3\n",
      "    Cycle 14: nij=14\n",
      "      och[ 0]: FFDD\n",
      "      och[ 1]: FFEB\n",
      "      och[ 2]: FFF2\n",
      "      och[ 3]: 0022\n",
      "      och[ 4]: 0026\n",
      "      och[ 5]: FFF8\n",
      "      och[ 6]: FFFA\n",
      "      och[ 7]: 0000\n",
      "    Cycle 15: nij=15\n",
      "      och[ 0]: FFDF\n",
      "      och[ 1]: FFEE\n",
      "      och[ 2]: FFF9\n",
      "      och[ 3]: 0029\n",
      "      och[ 4]: 002A\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: FFF1\n",
      "      och[ 7]: 0004\n",
      "    Completed processing 16 time steps for och_tile 0\n",
      "  --- Processing och_tile = 1 ---\n",
      "    Weight tile shape for kij=0: torch.Size([8, 16])\n",
      "    Cycle 16: nij=0\n",
      "      och[ 8]: 0000\n",
      "      och[ 9]: 0000\n",
      "      och[10]: 0000\n",
      "      och[11]: 0000\n",
      "      och[12]: 0000\n",
      "      och[13]: 0000\n",
      "      och[14]: 0000\n",
      "      och[15]: 0000\n",
      "    Cycle 17: nij=1\n",
      "      och[ 8]: 0000\n",
      "      och[ 9]: 0000\n",
      "      och[10]: 0000\n",
      "      och[11]: 0000\n",
      "      och[12]: 0000\n",
      "      och[13]: 0000\n",
      "      och[14]: 0000\n",
      "      och[15]: 0000\n",
      "    Cycle 18: nij=2\n",
      "      och[ 8]: 0000\n",
      "      och[ 9]: 0000\n",
      "      och[10]: 0000\n",
      "      och[11]: 0000\n",
      "      och[12]: 0000\n",
      "      och[13]: 0000\n",
      "      och[14]: 0000\n",
      "      och[15]: 0000\n",
      "    Cycle 19: nij=3\n",
      "      och[ 8]: 0000\n",
      "      och[ 9]: 0000\n",
      "      och[10]: 0000\n",
      "      och[11]: 0000\n",
      "      och[12]: 0000\n",
      "      och[13]: 0000\n",
      "      och[14]: 0000\n",
      "      och[15]: 0000\n",
      "    Completed processing 16 time steps for och_tile 1\n",
      "\n",
      "--- Processing kij = 1 ---\n",
      "  --- Processing och_tile = 0 ---\n",
      "    Weight tile shape for kij=1: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 0\n",
      "  --- Processing och_tile = 1 ---\n",
      "    Weight tile shape for kij=1: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 1\n",
      "\n",
      "--- Processing kij = 2 ---\n",
      "  --- Processing och_tile = 0 ---\n",
      "    Weight tile shape for kij=2: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 0\n",
      "  --- Processing och_tile = 1 ---\n",
      "    Weight tile shape for kij=2: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 1\n",
      "\n",
      "--- Processing kij = 3 ---\n",
      "  --- Processing och_tile = 0 ---\n",
      "    Weight tile shape for kij=3: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 0\n",
      "  --- Processing och_tile = 1 ---\n",
      "    Weight tile shape for kij=3: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 1\n",
      "\n",
      "--- Processing kij = 4 ---\n",
      "  --- Processing och_tile = 0 ---\n",
      "    Weight tile shape for kij=4: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 0\n",
      "  --- Processing och_tile = 1 ---\n",
      "    Weight tile shape for kij=4: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 1\n",
      "\n",
      "--- Processing kij = 5 ---\n",
      "  --- Processing och_tile = 0 ---\n",
      "    Weight tile shape for kij=5: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 0\n",
      "  --- Processing och_tile = 1 ---\n",
      "    Weight tile shape for kij=5: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 1\n",
      "\n",
      "--- Processing kij = 6 ---\n",
      "  --- Processing och_tile = 0 ---\n",
      "    Weight tile shape for kij=6: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 0\n",
      "  --- Processing och_tile = 1 ---\n",
      "    Weight tile shape for kij=6: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 1\n",
      "\n",
      "--- Processing kij = 7 ---\n",
      "  --- Processing och_tile = 0 ---\n",
      "    Weight tile shape for kij=7: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 0\n",
      "  --- Processing och_tile = 1 ---\n",
      "    Weight tile shape for kij=7: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 1\n",
      "\n",
      "--- Processing kij = 8 ---\n",
      "  --- Processing och_tile = 0 ---\n",
      "    Weight tile shape for kij=8: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 0\n",
      "  --- Processing och_tile = 1 ---\n",
      "    Weight tile shape for kij=8: torch.Size([8, 16])\n",
      "    Completed processing 16 time steps for och_tile 1\n",
      "\n",
      "=== First 8 Cycles Detailed Output ===\n",
      "\n",
      "Cycle 0: kij=0, nij=0\n",
      "  Partial sums for all output channels:\n",
      "    och[0]: 0.0\n",
      "    och[1]: 0.0\n",
      "    och[2]: 0.0\n",
      "    och[3]: 0.0\n",
      "    och[4]: 0.0\n",
      "    och[5]: 0.0\n",
      "    och[6]: 0.0\n",
      "    och[7]: 0.0\n",
      "    och[8]: 0.0\n",
      "    och[9]: 0.0\n",
      "    och[10]: 0.0\n",
      "    och[11]: 0.0\n",
      "    och[12]: 0.0\n",
      "    och[13]: 0.0\n",
      "    och[14]: 0.0\n",
      "    och[15]: 0.0\n",
      "\n",
      "Cycle 1: kij=0, nij=1\n",
      "  Partial sums for all output channels:\n",
      "    och[0]: 0.0\n",
      "    och[1]: 0.0\n",
      "    och[2]: 0.0\n",
      "    och[3]: 0.0\n",
      "    och[4]: 0.0\n",
      "    och[5]: 0.0\n",
      "    och[6]: 0.0\n",
      "    och[7]: 0.0\n",
      "    och[8]: 0.0\n",
      "    och[9]: 0.0\n",
      "    och[10]: 0.0\n",
      "    och[11]: 0.0\n",
      "    och[12]: 0.0\n",
      "    och[13]: 0.0\n",
      "    och[14]: 0.0\n",
      "    och[15]: 0.0\n",
      "\n",
      "Cycle 2: kij=0, nij=2\n",
      "  Partial sums for all output channels:\n",
      "    och[0]: 0.0\n",
      "    och[1]: 0.0\n",
      "    och[2]: 0.0\n",
      "    och[3]: 0.0\n",
      "    och[4]: 0.0\n",
      "    och[5]: 0.0\n",
      "    och[6]: 0.0\n",
      "    och[7]: 0.0\n",
      "    och[8]: 0.0\n",
      "    och[9]: 0.0\n",
      "    och[10]: 0.0\n",
      "    och[11]: 0.0\n",
      "    och[12]: 0.0\n",
      "    och[13]: 0.0\n",
      "    och[14]: 0.0\n",
      "    och[15]: 0.0\n",
      "\n",
      "Cycle 3: kij=0, nij=3\n",
      "  Partial sums for all output channels:\n",
      "    och[0]: 0.0\n",
      "    och[1]: 0.0\n",
      "    och[2]: 0.0\n",
      "    och[3]: 0.0\n",
      "    och[4]: 0.0\n",
      "    och[5]: 0.0\n",
      "    och[6]: 0.0\n",
      "    och[7]: 0.0\n",
      "    och[8]: 0.0\n",
      "    och[9]: 0.0\n",
      "    och[10]: 0.0\n",
      "    och[11]: 0.0\n",
      "    och[12]: 0.0\n",
      "    och[13]: 0.0\n",
      "    och[14]: 0.0\n",
      "    och[15]: 0.0\n",
      "\n",
      "Cycle 4: kij=0, nij=4\n",
      "  Partial sums for all output channels:\n",
      "    och[0]: 0.0\n",
      "    och[1]: 0.0\n",
      "    och[2]: 0.0\n",
      "    och[3]: 0.0\n",
      "    och[4]: 0.0\n",
      "    och[5]: 0.0\n",
      "    och[6]: 0.0\n",
      "    och[7]: 0.0\n",
      "    och[8]: 0.0\n",
      "    och[9]: 0.0\n",
      "    och[10]: 0.0\n",
      "    och[11]: 0.0\n",
      "    och[12]: 0.0\n",
      "    och[13]: 0.0\n",
      "    och[14]: 0.0\n",
      "    och[15]: 0.0\n",
      "\n",
      "Cycle 5: kij=0, nij=5\n",
      "  Partial sums for all output channels:\n",
      "    och[0]: -11.0\n",
      "    och[1]: -15.0\n",
      "    och[2]: 3.000000476837158\n",
      "    och[3]: 22.0\n",
      "    och[4]: 37.0\n",
      "    och[5]: 4.999999523162842\n",
      "    och[6]: -11.0\n",
      "    och[7]: 5.0\n",
      "    och[8]: 2.0\n",
      "    och[9]: 26.0\n",
      "    och[10]: -8.0\n",
      "    och[11]: 16.0\n",
      "    och[12]: -3.000000476837158\n",
      "    och[13]: -19.0\n",
      "    och[14]: -7.0\n",
      "    och[15]: 4.000000476837158\n",
      "\n",
      "Cycle 6: kij=0, nij=6\n",
      "  Partial sums for all output channels:\n",
      "    och[0]: -29.999996185302734\n",
      "    och[1]: -7.0\n",
      "    och[2]: 2.999999523162842\n",
      "    och[3]: 36.0\n",
      "    och[4]: 41.999996185302734\n",
      "    och[5]: 4.000001907348633\n",
      "    och[6]: -1.9999980926513672\n",
      "    och[7]: 9.5367431640625e-07\n",
      "    och[8]: -1.0\n",
      "    och[9]: 29.999996185302734\n",
      "    och[10]: -4.999999523162842\n",
      "    och[11]: 28.999996185302734\n",
      "    och[12]: 0.999997615814209\n",
      "    och[13]: -31.999996185302734\n",
      "    och[14]: -9.000000953674316\n",
      "    och[15]: 1.9999980926513672\n",
      "\n",
      "Cycle 7: kij=0, nij=7\n",
      "  Partial sums for all output channels:\n",
      "    och[0]: -16.0\n",
      "    och[1]: -17.0\n",
      "    och[2]: 2.0000009536743164\n",
      "    och[3]: 30.999996185302734\n",
      "    och[4]: 44.99999237060547\n",
      "    och[5]: -4.76837158203125e-07\n",
      "    och[6]: -22.0\n",
      "    och[7]: 8.999999046325684\n",
      "    och[8]: -6.999999046325684\n",
      "    och[9]: 28.0\n",
      "    och[10]: -8.0\n",
      "    och[11]: 36.999996185302734\n",
      "    och[12]: -16.999996185302734\n",
      "    och[13]: -19.0\n",
      "    och[14]: -13.999998092651367\n",
      "    och[15]: 28.999996185302734\n",
      "\n",
      "=== Accumulating Partial Sums ===\n",
      "Accumulated psum shape: torch.Size([16, 16])\n",
      "Final output shape: torch.Size([16, 4, 4])\n",
      "\n",
      "=== Generating Expected Output ===\n",
      "Expected output shape: torch.Size([16, 4, 4])\n",
      "\n",
      "=== Verification Results ===\n",
      "Max difference: 3.0517578125e-05\n",
      "Outputs match: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def simulate_systolic_array_detailed(x_pad_in, weight_int, och_tile_size=8):\n",
    "    \"\"\"\n",
    "    Simulate systolic array with detailed cycle-by-cycle output printing\n",
    "    Ensuring all operations are on the same device\n",
    "    \"\"\"\n",
    "    # Ensure both tensors are on the same device\n",
    "    device = x_pad_in.device\n",
    "    weight_int = weight_int.to(device)\n",
    "    \n",
    "    print(\"=== Systolic Array Simulation with Detailed Output ===\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Input shape: {x_pad_in.shape}\")\n",
    "    print(f\"Weight shape: {weight_int.shape}\")\n",
    "    print(f\"OCH tile size: {och_tile_size}\")\n",
    "    \n",
    "    # Prepare input data - extract 4x4 output region from 6x6 padded input\n",
    "    input_patches = torch.zeros(16, 4, 4, 3, 3, device=device)  # [in_ch, H_out, W_out, kH, kW]\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            input_patches[:, i, j, :, :] = x_pad_in[:, i:i+3, j:j+3]\n",
    "    \n",
    "    # Reshape to [in_ch, spatial_pos, kernel_elements]\n",
    "    input_matrix = input_patches.view(16, 16, 9)  # [16, 16, 9]\n",
    "    \n",
    "    # Reshape weights to [out_ch, in_ch, kernel_elements]\n",
    "    W = weight_int.view(weight_int.size(0), weight_int.size(1), 9)  # [16, 16, 9]\n",
    "    \n",
    "    total_output_channels = W.size(0)  # 16\n",
    "    num_och_tiles = total_output_channels // och_tile_size  # 16//8 = 2\n",
    "    \n",
    "    # Storage for partial sums - ensure on same device\n",
    "    psum_memory = torch.zeros(total_output_channels, 16, 9, device=device)  # [out_ch, spatial_pos, kij]\n",
    "    \n",
    "    print(f\"\\nSimulation parameters:\")\n",
    "    print(f\"- Total output channels: {total_output_channels}\")\n",
    "    print(f\"- Number of OCH tiles: {num_och_tiles}\")\n",
    "    print(f\"- Spatial positions (nij): {input_matrix.size(1)}\")\n",
    "    print(f\"- Kernel elements (kij): {input_matrix.size(2)}\")\n",
    "    \n",
    "    cycle_count = 0\n",
    "    \n",
    "    # Exact loop structure matching your Verilog testbench\n",
    "    for kij in range(9):  # Kernel element index (0-8)\n",
    "        print(f\"\\n--- Processing kij = {kij} ---\")\n",
    "        \n",
    "        for och_t in range(num_och_tiles):  # Output channel tile (0 to num_och_tiles-1)\n",
    "            print(f\"  --- Processing och_tile = {och_t} ---\")\n",
    "            \n",
    "            # Calculate output channel range for this tile\n",
    "            och_start = och_t * och_tile_size\n",
    "            och_end = (och_t + 1) * och_tile_size\n",
    "            \n",
    "            # Extract weights for current tile and kernel element\n",
    "            w_tile_kij = W[och_start:och_end, :, kij]  # [8, 16]\n",
    "            print(f\"    Weight tile shape for kij={kij}: {w_tile_kij.shape}\")\n",
    "            \n",
    "            # Process each time step (spatial position)\n",
    "            for nij in range(16):  # Time steps/spatial positions (0-15)\n",
    "                # Get input at this position and kernel element\n",
    "                x_nij_kij = input_matrix[:, nij, kij]  # [16]\n",
    "                \n",
    "                # Compute matrix multiplication: [och_tile_size] = [och_tile_size, in_ch]  [in_ch]\n",
    "                psum_result = torch.matmul(w_tile_kij, x_nij_kij)  # [8]\n",
    "                \n",
    "                # Store partial sums in memory\n",
    "                psum_memory[och_start:och_end, nij, kij] = psum_result\n",
    "                \n",
    "                # Print first few cycles in detail\n",
    "                if cycle_count < 20:\n",
    "                    print(f\"    Cycle {cycle_count}: nij={nij}\")\n",
    "                    # Convert to 16-bit signed integers and then to hex\n",
    "                    for idx, val in enumerate(psum_result):\n",
    "                        och_index = och_start + idx\n",
    "                        # Convert to 16-bit signed integer (same as Verilog)\n",
    "                        int_val = int(round(val.item()))\n",
    "                        # Handle negative numbers for 16-bit two's complement\n",
    "                        if int_val < 0:\n",
    "                            hex_val = format(int_val & 0xFFFF, '04X')  # 16-bit two's complement\n",
    "                        else:\n",
    "                            hex_val = format(int_val & 0xFFFF, '04X')  # Mask to 16 bits\n",
    "                        print(f\"      och[{och_index:2d}]: {hex_val}\")\n",
    "                    # print(f\"    Cycle {cycle_count}: nij={nij}, och[{och_start}:{och_end}] = {psum_result.tolist()}\")\n",
    "                \n",
    "                cycle_count += 1\n",
    "                \n",
    "            print(f\"    Completed processing {input_matrix.size(1)} time steps for och_tile {och_t}\")\n",
    "    \n",
    "    return psum_memory\n",
    "\n",
    "def print_first_cycles_detailed(psum_memory, num_cycles=10):\n",
    "    \"\"\"\n",
    "    Print detailed information for the first several cycles\n",
    "    \"\"\"\n",
    "    device = psum_memory.device\n",
    "    print(f\"\\n=== First {num_cycles} Cycles Detailed Output ===\")\n",
    "    \n",
    "    count = 0\n",
    "    for kij in range(9):\n",
    "        for nij in range(16):\n",
    "            if count >= num_cycles:\n",
    "                return\n",
    "            \n",
    "            print(f\"\\nCycle {count}: kij={kij}, nij={nij}\")\n",
    "            print(f\"  Partial sums for all output channels:\")\n",
    "            for och in range(16):\n",
    "                psum_val = psum_memory[och, nij, kij].item()\n",
    "                print(f\"    och[{och}]: {psum_val}\")\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "def accumulate_and_verify(psum_memory, weight_int, x_pad_in):\n",
    "    \"\"\"\n",
    "    Accumulate partial sums and verify with PyTorch convolution\n",
    "    \"\"\"\n",
    "    device = psum_memory.device\n",
    "    weight_int = weight_int.to(device)\n",
    "    x_pad_in = x_pad_in.to(device)\n",
    "    \n",
    "    print(\"\\n=== Accumulating Partial Sums ===\")\n",
    "    \n",
    "    # Accumulate across kernel elements (kij dimension)\n",
    "    accumulated_psum = torch.sum(psum_memory, dim=2)  # [16, 16]\n",
    "    print(f\"Accumulated psum shape: {accumulated_psum.shape}\")\n",
    "    \n",
    "    # Reshape to spatial dimensions [16, 4, 4]\n",
    "    final_output_simulated = accumulated_psum.view(16, 4, 4)\n",
    "    print(f\"Final output shape: {final_output_simulated.shape}\")\n",
    "    \n",
    "    # Generate expected output using PyTorch\n",
    "    print(\"\\n=== Generating Expected Output ===\")\n",
    "    conv_ref = torch.nn.Conv2d(\n",
    "        in_channels=16, \n",
    "        out_channels=16, \n",
    "        kernel_size=3, \n",
    "        padding=0,  # No padding in actual convolution\n",
    "        bias=False\n",
    "    ).to(device)\n",
    "    \n",
    "    # Set weights\n",
    "    conv_ref.weight = torch.nn.Parameter(weight_int)\n",
    "    \n",
    "    # Perform convolution\n",
    "    with torch.no_grad():\n",
    "        expected_output = conv_ref(x_pad_in.unsqueeze(0)).squeeze(0)  # Remove batch dimension\n",
    "    \n",
    "    print(f\"Expected output shape: {expected_output.shape}\")\n",
    "    \n",
    "    # Compare results\n",
    "    diff = torch.abs(final_output_simulated - expected_output)\n",
    "    max_diff = torch.max(diff)\n",
    "    \n",
    "    print(f\"\\n=== Verification Results ===\")\n",
    "    print(f\"Max difference: {max_diff.item()}\")\n",
    "    print(f\"Outputs match: {torch.allclose(final_output_simulated, expected_output, atol=1e-5)}\")\n",
    "    \n",
    "    return final_output_simulated, expected_output\n",
    "\n",
    "# Example usage with your data:\n",
    "def main_simulation():\n",
    "    \"\"\"\n",
    "    Main function to run the complete simulation\n",
    "    \"\"\"\n",
    "    print(\"Starting systolic array simulation...\")\n",
    "    \n",
    "    # Assuming you have these variables from your notebook:\n",
    "    # x_pad_in: [16, 6, 6] - input activations\n",
    "    # weight_int: [16, 16, 3, 3] - quantized weights\n",
    "    \n",
    "    # Make sure both tensors are on CUDA\n",
    "    global x_pad_in, weight_int\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Move tensors to device if they exist\n",
    "    if 'x_pad_in' in globals():\n",
    "        x_pad_in = x_pad_in.to(device)\n",
    "    else:\n",
    "        print(\"Creating sample x_pad_in data...\")\n",
    "        x_pad_in = torch.randint(0, 4, (16, 6, 6), device=device).float()  # 2-bit activations (0-3)\n",
    "    \n",
    "    if 'weight_int' in globals():\n",
    "        weight_int = weight_int.to(device)\n",
    "    else:\n",
    "        print(\"Creating sample weight_int data...\")\n",
    "        weight_int = torch.randint(-8, 8, (16, 16, 3, 3), device=device).float()  # 4-bit weights\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Run detailed simulation\n",
    "    psum_memory = simulate_systolic_array_detailed(x_pad_in, weight_int, och_tile_size=8)\n",
    "    \n",
    "    # Print first cycles in detail\n",
    "    print_first_cycles_detailed(psum_memory, num_cycles=5)\n",
    "    \n",
    "    # Accumulate and verify\n",
    "    final_sim, expected = accumulate_and_verify(psum_memory, weight_int, x_pad_in)\n",
    "    \n",
    "    return psum_memory, final_sim, expected\n",
    "\n",
    "# Alternative: If you want to run with your specific data from the notebook\n",
    "def run_with_notebook_data():\n",
    "    \"\"\"\n",
    "    Run simulation with data from your notebook\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Using data from notebook context...\")\n",
    "        # Make sure these variables are available and on the correct device\n",
    "        global x_pad_in, weight_int, x_pad\n",
    "        \n",
    "        # Ensure all tensors are on the same device\n",
    "        if 'x_pad_in' not in globals():\n",
    "            # Create x_pad_in from x_pad if needed\n",
    "            x_pad_in = x_pad[0].to(device)  # Taking first batch item\n",
    "        \n",
    "        x_pad_in = x_pad_in.to(device)\n",
    "        weight_int = weight_int.to(device)\n",
    "        \n",
    "        print(f\"Tensors moved to device: {device}\")\n",
    "        print(f\"x_pad_in device: {x_pad_in.device}\")\n",
    "        print(f\"weight_int device: {weight_int.device}\")\n",
    "        \n",
    "        psum_memory = simulate_systolic_array_detailed(x_pad_in, weight_int)\n",
    "        print_first_cycles_detailed(psum_memory, num_cycles=8)\n",
    "        final_sim, expected = accumulate_and_verify(psum_memory, weight_int, x_pad_in)\n",
    "        return psum_memory, final_sim, expected\n",
    "    except NameError as e:\n",
    "        print(f\"Notebook data not fully available: {e}\")\n",
    "        print(\"Running with sample data instead...\")\n",
    "        return main_simulation()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during simulation: {e}\")\n",
    "        print(\"Running with sample data instead...\")\n",
    "        return main_simulation()\n",
    "\n",
    "# To execute the simulation:\n",
    "# Uncomment one of the following lines:\n",
    "\n",
    "# For using your notebook data:\n",
    "psum_memory, final_output, expected_output = run_with_notebook_data()\n",
    "\n",
    "# For using sample data:\n",
    "# psum_memory, final_output, expected_output = main_simulation()\n",
    "\n",
    "# To examine specific parts of the result:\n",
    "# print(\"Partial sums for first kernel element:\")\n",
    "# print(psum_memory[:, :, 0])  # All output channels, all positions, kij=0\n",
    "\n",
    "# Additional debugging function to check tensor devices\n",
    "def check_tensor_devices():\n",
    "    \"\"\"\n",
    "    Check and print the devices of all relevant tensors\n",
    "    \"\"\"\n",
    "    tensors_to_check = ['x_pad_in', 'weight_int', 'x_pad', 'W', 'X']\n",
    "    \n",
    "    print(\"=== Tensor Device Check ===\")\n",
    "    for tensor_name in tensors_to_check:\n",
    "        if tensor_name in globals():\n",
    "            tensor = globals()[tensor_name]\n",
    "            if hasattr(tensor, 'device'):\n",
    "                print(f\"{tensor_name}: {tensor.device}\")\n",
    "            else:\n",
    "                print(f\"{tensor_name}: Not a tensor or no device attribute\")\n",
    "        else:\n",
    "            print(f\"{tensor_name}: Not found in global scope\")\n",
    "\n",
    "# Call this to check tensor devices:\n",
    "# check_tensor_devices()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ece284fa25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
