{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 18852,
     "status": "ok",
     "timestamp": 1764040191831,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "radical-fifty",
    "outputId": "89629fe0-d07c-491a-ce6c-56a2c369910c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (33): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (41): ReLU(inplace=True)\n",
      "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "model_name = \"VGG16_project\"\n",
    "model = VGG16_project()\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107ceeb",
   "metadata": {
    "id": "2107ceeb"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [60, 80]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-reminder",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1141625,
     "status": "ok",
     "timestamp": 1763673064939,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "junior-reminder",
    "outputId": "acebe3e4-e18b-4204-adb6-4d85fbe5e809"
   },
   "outputs": [],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "entertaining-queensland",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7370,
     "status": "ok",
     "timestamp": 1764040357208,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "entertaining-queensland",
    "outputId": "6fdf2180-ca74-42ee-eabe-6f6e95779b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9112/10000 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"./result/VGG16_quant4b4b/model_best.pth.tar\"\n",
    "model_name = \"VGG16_project\"\n",
    "model = VGG16_project()\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceramic-nigeria",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1764040369503,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "ceramic-nigeria",
    "outputId": "2b6800cc-f1ef-43c3-e200-299732c06aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 1\n",
      "7 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 2\n",
      "12 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 3\n",
      "16 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 4\n",
      "21 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 5\n",
      "25 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 6\n",
      "29 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 7\n",
      "34 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 8\n",
      "38 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 9\n",
      "41 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 10\n",
      "46 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 11\n",
      "50 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 12\n",
      "54 -th layer prehooked\n",
      "QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "\n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "counter = 0\n",
    "for layer in model.modules():\n",
    "    i+=1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        counter+=1\n",
    "        print(layer, counter)\n",
    "        layer.register_forward_pre_hook(save_output)\n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spoken-worst",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1764040373863,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "spoken-worst",
    "outputId": "88f90002-7208-4fe0-c284-80a06a675566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Int Shape: torch.Size([8, 8, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.features[27].weight_q # quantized value is stored during the training\n",
    "w_alpha = model.features[27].weight_quant.wgt_alpha   # alpha is defined in your model already. bring it out here\n",
    "w_delta = w_alpha/(2**(w_bit-1)-1)   # delta can be calculated by using alpha and w_bit\n",
    "weight_int = weight_q/w_delta # w_int can be calculated by weight_q and w_delta\n",
    "# print(weight_int) # you should see clean integer numbers\n",
    "print(f\"Weight Int Shape: {weight_int.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "interior-oxygen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1764040470512,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "interior-oxygen",
    "outputId": "c0a8fd18-9b08-48ad-c452-685312b0cb89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([128, 8, 4, 4])\n",
      "Input Int Sample: tensor([3.0000, 0.0000, 0.0000, 0.0000], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_bit = 4\n",
    "x = save_output.outputs[8][0]  # input of the 2nd conv layer\n",
    "print(f\"Input Shape: {x.shape}\")\n",
    "x_alpha  = model.features[27].act_alpha\n",
    "x_delta = x_alpha/(2**x_bit-1)\n",
    "\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x_q = act_quant_fn(x, x_alpha)         # create the quantized value for x\n",
    "\n",
    "x_int = x_q/x_delta\n",
    "print(f\"Input Int Sample: {x_int[0,0,0,:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "designed-auction",
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1764040478224,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "designed-auction"
   },
   "outputs": [],
   "source": [
    "#### input floating number / weight quantized version\n",
    "\n",
    "conv_ref = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1, bias = False)\n",
    "conv_ref.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "output_int = conv_ref(x_int)\n",
    "\n",
    "output_recovered = output_int*x_delta*w_delta\n",
    "relu = nn.ReLU(inplace=True)\n",
    "relu_output_recovered = relu(output_recovered)\n",
    "\n",
    "output_ref = save_output.outputs[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "157dffd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1764040479789,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "157dffd8",
    "outputId": "2eecc1be-3f3a-40f5-ca5c-8846645ac3ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7784e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "difference = abs( output_ref - relu_output_recovered )\n",
    "# difference = abs( output_ref - output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "significant-whole",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1764043241170,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "significant-whole",
    "outputId": "66275cc5-3687-44fe-974e-f2a0585233c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 36])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad = torch.zeros(128, 8, 6, 6).to(x_int.device)\n",
    "x_pad[:, :, 1:5, 1:5] = x_int\n",
    "X = x_pad[0]\n",
    "x_pad_in=X\n",
    "X = X.reshape(X.size(0), -1)\n",
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "corresponding-significance",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1764043242489,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "corresponding-significance"
   },
   "outputs": [],
   "source": [
    "tile_id = 0\n",
    "nij = 200 # just a random number\n",
    "#X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n",
    "\n",
    "bit_precision = 8\n",
    "file = open('activation4b4b.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "# file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:08b}'.format(int(X[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])\n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "P-anPbG6Kl6z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1764043245530,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "P-anPbG6Kl6z",
    "outputId": "bb5094ac-5b0e-45be-d037-165686b5a9db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8, 3, 3])\n",
      "torch.Size([8, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(weight_int.size())\n",
    "W = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))\n",
    "print(W.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "W0o2upN-KvJm",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1764043246674,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "W0o2upN-KvJm"
   },
   "outputs": [],
   "source": [
    "\n",
    "bit_precision = 8\n",
    "file = open('weight4b4b.txt', 'w') #write to file\n",
    "file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "# file.write('#................#\\n')\n",
    "for kij in range(9):\n",
    "    for i in range(W.size(0)):\n",
    "        for j in range(W.size(1)):\n",
    "            if (W[i, 7-j, kij].item()<0):\n",
    "                W_bin = '{0:08b}'.format(int(W[i,7-j,kij].item()+2**bit_precision+0.001))\n",
    "            else:\n",
    "                W_bin = '{0:08b}'.format(int(W[i,7-j,kij].item()+0.001))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])\n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "pxR9Na_VLDAp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1764043249145,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "pxR9Na_VLDAp",
    "outputId": "960885ad-b067-4201-9136-c53803f1bb5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.0000, -0.0000,  2.0000,  7.0000,  7.0000,  3.0000, -3.0000,  2.0000],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4jMH_fdkLJtd",
   "metadata": {
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1764043250921,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "4jMH_fdkLJtd"
   },
   "outputs": [],
   "source": [
    "p_nijg = range(X.size(1)) ## psum nij group\n",
    "psum = torch.zeros(8, len(p_nijg), 9).cuda()\n",
    "for kij in range(9):\n",
    "    for nij in p_nijg:       # time domain, sequentially given input\n",
    "        m = nn.Linear(8, 8, bias=False)\n",
    "        m.weight = torch.nn.Parameter(W[:,:,kij])\n",
    "        psum[:, nij, kij] = m(X[:,nij]).cuda()\n",
    "bit_precision = 16\n",
    "file = open('psum.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "for kij in range(9):\n",
    "    for i in range(psum.size(1)):\n",
    "        for j in range(psum.size(0)):\n",
    "            if (psum[7-j,i,kij].item()<0):\n",
    "                P_bin = '{0:016b}'.format(int(psum[7-j,i,kij].item()+2**bit_precision+0.001))\n",
    "            else:\n",
    "                P_bin = '{0:016b}'.format(int(psum[7-j,i,kij].item()+0.001))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(P_bin[k])\n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "_1SmPoKDMmpE",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1764044840440,
     "user": {
      "displayName": "Wenhao Zhao",
      "userId": "11291250091384836440"
     },
     "user_tz": 480
    },
    "id": "_1SmPoKDMmpE"
   },
   "outputs": [],
   "source": [
    "# out = relu(output_int[0])\n",
    "out = output_int[0]\n",
    "out = torch.reshape(out, (out.size(0), -1))\n",
    "bit_precision = 16\n",
    "file = open('output4b4b.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "# file.write('#................#\\n')\n",
    "\n",
    "for i in range(out.size(1)):\n",
    "    for j in range(out.size(0)):\n",
    "        if (out[7-j,i].item()<0):\n",
    "            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+2**bit_precision+0.001))\n",
    "        else:\n",
    "            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(O_bin[k])\n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa3078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight shape after reshape: torch.Size([8, 8, 9])\n",
      "Input shape after flatten: torch.Size([8, 36])\n",
      "\n",
      "Simulation parameters:\n",
      "- Total output channels: 8\n",
      "- Input channels: 8\n",
      "- Spatial positions (nij): 36\n",
      "- Kernel elements (kij): 9\n",
      "\n",
      "--- Processing kij = 0 ---\n",
      "  Weight tile shape for kij=0: torch.Size([8, 8])\n",
      "    Cycle 0: nij=0\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 1: nij=1\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 2: nij=2\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 3: nij=3\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 4: nij=4\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 5: nij=5\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 6: nij=6\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 7: nij=7\n",
      "      och[ 0]: 0014\n",
      "      och[ 1]: FFE0\n",
      "      och[ 2]: 0001\n",
      "      och[ 3]: FFD7\n",
      "      och[ 4]: FFAF\n",
      "      och[ 5]: FFB7\n",
      "      och[ 6]: 001A\n",
      "      och[ 7]: 004C\n",
      "    Cycle 8: nij=8\n",
      "      och[ 0]: 0031\n",
      "      och[ 1]: FFCF\n",
      "      och[ 2]: FFE4\n",
      "      och[ 3]: FFCF\n",
      "      och[ 4]: FFAC\n",
      "      och[ 5]: FF89\n",
      "      och[ 6]: 0031\n",
      "      och[ 7]: 004D\n",
      "    Cycle 9: nij=9\n",
      "      och[ 0]: 0014\n",
      "      och[ 1]: FFF4\n",
      "      och[ 2]: FFE4\n",
      "      och[ 3]: FFE6\n",
      "      och[ 4]: FFCC\n",
      "      och[ 5]: FFA6\n",
      "      och[ 6]: 001E\n",
      "      och[ 7]: 0030\n",
      "    Cycle 10: nij=10\n",
      "      och[ 0]: 001E\n",
      "      och[ 1]: 0009\n",
      "      och[ 2]: FFED\n",
      "      och[ 3]: FFF5\n",
      "      och[ 4]: FFD8\n",
      "      och[ 5]: FFAE\n",
      "      och[ 6]: 0029\n",
      "      och[ 7]: 0038\n",
      "    Cycle 11: nij=11\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 12: nij=12\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 13: nij=13\n",
      "      och[ 0]: 003B\n",
      "      och[ 1]: FFC9\n",
      "      och[ 2]: FFDC\n",
      "      och[ 3]: FFCE\n",
      "      och[ 4]: FFAA\n",
      "      och[ 5]: FF86\n",
      "      och[ 6]: 0034\n",
      "      och[ 7]: 0059\n",
      "    Cycle 14: nij=14\n",
      "      och[ 0]: 0031\n",
      "      och[ 1]: FFCF\n",
      "      och[ 2]: FFE3\n",
      "      och[ 3]: FFCD\n",
      "      och[ 4]: FFA8\n",
      "      och[ 5]: FF82\n",
      "      och[ 6]: 0033\n",
      "      och[ 7]: 004F\n",
      "    Cycle 15: nij=15\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: FFFA\n",
      "      och[ 3]: FFF4\n",
      "      och[ 4]: FFE8\n",
      "      och[ 5]: FFD6\n",
      "      och[ 6]: 000C\n",
      "      och[ 7]: 000C\n",
      "    Cycle 16: nij=16\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: FFF9\n",
      "      och[ 3]: FFF2\n",
      "      och[ 4]: FFE4\n",
      "      och[ 5]: FFCF\n",
      "      och[ 6]: 000E\n",
      "      och[ 7]: 000E\n",
      "    Cycle 17: nij=17\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 18: nij=18\n",
      "      och[ 0]: 0000\n",
      "      och[ 1]: 0000\n",
      "      och[ 2]: 0000\n",
      "      och[ 3]: 0000\n",
      "      och[ 4]: 0000\n",
      "      och[ 5]: 0000\n",
      "      och[ 6]: 0000\n",
      "      och[ 7]: 0000\n",
      "    Cycle 19: nij=19\n",
      "      och[ 0]: 003B\n",
      "      och[ 1]: FFC9\n",
      "      och[ 2]: FFE3\n",
      "      och[ 3]: FFDC\n",
      "      och[ 4]: FFC6\n",
      "      och[ 5]: FFB7\n",
      "      och[ 6]: 0026\n",
      "      och[ 7]: 004B\n",
      "\n",
      "--- Processing kij = 1 ---\n",
      "  Weight tile shape for kij=1: torch.Size([8, 8])\n",
      "\n",
      "--- Processing kij = 2 ---\n",
      "  Weight tile shape for kij=2: torch.Size([8, 8])\n",
      "\n",
      "--- Processing kij = 3 ---\n",
      "  Weight tile shape for kij=3: torch.Size([8, 8])\n",
      "\n",
      "--- Processing kij = 4 ---\n",
      "  Weight tile shape for kij=4: torch.Size([8, 8])\n",
      "\n",
      "--- Processing kij = 5 ---\n",
      "  Weight tile shape for kij=5: torch.Size([8, 8])\n",
      "\n",
      "--- Processing kij = 6 ---\n",
      "  Weight tile shape for kij=6: torch.Size([8, 8])\n",
      "\n",
      "--- Processing kij = 7 ---\n",
      "  Weight tile shape for kij=7: torch.Size([8, 8])\n",
      "\n",
      "--- Processing kij = 8 ---\n",
      "  Weight tile shape for kij=8: torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "# Modified code to show MAC array output (8x16) for each cycle in hex format\n",
    "import torch\n",
    "\n",
    "def generate_debug_data_4b4b_with_mac_output(x_pad_in, weight_int):\n",
    "    \"\"\"\n",
    "    Generate debug data for 4b4b systolic array simulation with MAC array output\n",
    "    \n",
    "    Args:\n",
    "        x_pad_in: Input activations with padding [8, 6, 6]\n",
    "        weight_int: Quantized weights [8, 8, 3, 3]\n",
    "    \"\"\"\n",
    "    \n",
    "    device = x_pad_in.device\n",
    "    \n",
    "    # Reshape weights to [out_ch, in_ch, kij]\n",
    "    W = weight_int.reshape(weight_int.size(0), weight_int.size(1), -1)\n",
    "    print(f\"Weight shape after reshape: {W.shape}\")  # Should be [8, 8, 9]\n",
    "    \n",
    "    # Flatten input activations\n",
    "    X = x_pad_in.reshape(x_pad_in.size(0), -1)\n",
    "    print(f\"Input shape after flatten: {X.shape}\")  # Should be [8, 36]\n",
    "    \n",
    "    # Initialize partial sum memory [out_ch, spatial_pos, kij]\n",
    "    psum_memory = torch.zeros(8, 36, 9, device=device)\n",
    "    \n",
    "    print(\"\\nSimulation parameters:\")\n",
    "    print(f\"- Total output channels: {W.size(0)}\")\n",
    "    print(f\"- Input channels: {W.size(1)}\")\n",
    "    print(f\"- Spatial positions (nij): {X.size(1)}\")\n",
    "    print(f\"- Kernel elements (kij): {W.size(2)}\")\n",
    "    \n",
    "    cycle_count = 0\n",
    "    \n",
    "    # Process each kernel element\n",
    "    for kij in range(9):\n",
    "        print(f\"\\n--- Processing kij = {kij} ---\")\n",
    "        \n",
    "        # Get weight tile for this kernel element [out_ch, in_ch]\n",
    "        w_tile_kij = W[:, :, kij]  # [8, 8]\n",
    "        print(f\"  Weight tile shape for kij={kij}: {w_tile_kij.shape}\")\n",
    "        \n",
    "        # Process each spatial position\n",
    "        for nij in range(X.size(1)):\n",
    "            # Get input at this position and kernel element\n",
    "            x_nij_kij = X[:, nij]  # [8]\n",
    "            \n",
    "            # Compute matrix multiplication: [out_ch] = [out_ch, in_ch] Ã— [in_ch]\n",
    "            # This represents the MAC array output (8 outputs for 8 output channels)\n",
    "            mac_result = torch.matmul(w_tile_kij, x_nij_kij)  # [8]\n",
    "            \n",
    "            # Display MAC array output in hex format\n",
    "            if cycle_count < 30:  # Show first 30 cycles\n",
    "                print(f\"    Cycle {cycle_count}: kij={kij}, nij={nij}\")\n",
    "                print(f\"      MAC Array Output (8 channels):\")\n",
    "                mac_output_line = \"      \"\n",
    "                for idx, val in enumerate(mac_result):\n",
    "                    int_val = int(round(val.item()))\n",
    "                    # Convert to 16-bit two's complement hex\n",
    "                    if int_val < 0:\n",
    "                        hex_val = format(int_val & 0xFFFF, '04X')  # 16-bit two's complement\n",
    "                    else:\n",
    "                        hex_val = format(int_val & 0xFFFF, '04X')\n",
    "                    mac_output_line += f\"och[{idx}]:{hex_val} \"\n",
    "                print(mac_output_line)\n",
    "            \n",
    "            # Store partial sums in memory\n",
    "            psum_memory[:, nij, kij] = mac_result\n",
    "            \n",
    "            cycle_count += 1\n",
    "    \n",
    "    return psum_memory\n",
    "\n",
    "# Alternative function with more compact display\n",
    "def generate_debug_data_compact_mac_output(x_pad_in, weight_int):\n",
    "    \"\"\"\n",
    "    Generate debug data with compact MAC array output display\n",
    "    \"\"\"\n",
    "    \n",
    "    device = x_pad_in.device\n",
    "    \n",
    "    # Reshape weights to [out_ch, in_ch, kij]\n",
    "    W = weight_int.reshape(weight_int.size(0), weight_int.size(1), -1)\n",
    "    \n",
    "    # Flatten input activations\n",
    "    X = x_pad_in.reshape(x_pad_in.size(0), -1)\n",
    "    \n",
    "    # Initialize partial sum memory [out_ch, spatial_pos, kij]\n",
    "    psum_memory = torch.zeros(8, 36, 9, device=device)\n",
    "    \n",
    "    cycle_count = 0\n",
    "    \n",
    "    # Process each kernel element\n",
    "    for kij in range(9):\n",
    "        # Process each spatial position\n",
    "        for nij in range(X.size(1)):\n",
    "            # Get input at this position and kernel element\n",
    "            x_nij_kij = X[:, nij]  # [8]\n",
    "            \n",
    "            # Compute matrix multiplication\n",
    "            mac_result = torch.matmul(W[:, :, kij], x_nij_kij)  # [8]\n",
    "            \n",
    "            # Display MAC array output in hex format (compact)\n",
    "            if cycle_count < 20:  # Show first 20 cycles\n",
    "                print(f\"Cycle {cycle_count:2d} | \", end=\"\")\n",
    "                for idx, val in enumerate(mac_result):\n",
    "                    int_val = int(round(val.item()))\n",
    "                    hex_val = format(int_val & 0xFFFF, '04X')\n",
    "                    print(f\"{hex_val} \", end=\"\")\n",
    "                print()  # New line\n",
    "            \n",
    "            # Store partial sums in memory\n",
    "            psum_memory[:, nij, kij] = mac_result\n",
    "            \n",
    "            cycle_count += 1\n",
    "    \n",
    "    return psum_memory\n",
    "\n",
    "# Function to save MAC outputs to file\n",
    "def save_mac_outputs_to_file(x_pad_in, weight_int, filename='mac_outputs_4b4b.txt'):\n",
    "    \"\"\"\n",
    "    Save all MAC array outputs to a file\n",
    "    \"\"\"\n",
    "    \n",
    "    device = x_pad_in.device\n",
    "    \n",
    "    # Reshape weights to [out_ch, in_ch, kij]\n",
    "    W = weight_int.reshape(weight_int.size(0), weight_int.size(1), -1)\n",
    "    \n",
    "    # Flatten input activations\n",
    "    X = x_pad_in.reshape(x_pad_in.size(0), -1)\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"// MAC Array Outputs for 4b4b Systolic Array\\n\")\n",
    "        f.write(\"// Format: Cycle | och0 | och1 | och2 | och3 | och4 | och5 | och6 | och7\\n\")\n",
    "        \n",
    "        cycle_count = 0\n",
    "        \n",
    "        # Process each kernel element\n",
    "        for kij in range(9):\n",
    "            # Process each spatial position\n",
    "            for nij in range(X.size(1)):\n",
    "                # Get input at this position and kernel element\n",
    "                x_nij_kij = X[:, nij]  # [8]\n",
    "                \n",
    "                # Compute matrix multiplication\n",
    "                mac_result = torch.matmul(W[:, :, kij], x_nij_kij)  # [8]\n",
    "                \n",
    "                # Write to file\n",
    "                line = f\"{cycle_count:3d} \"\n",
    "                for val in mac_result:\n",
    "                    int_val = int(round(val.item()))\n",
    "                    hex_val = format(int_val & 0xFFFF, '04X')\n",
    "                    line += f\"{hex_val} \"\n",
    "                f.write(line.strip() + \"\\n\")\n",
    "                \n",
    "                cycle_count += 1\n",
    "    \n",
    "    print(f\"MAC outputs saved to {filename}\")\n",
    "\n",
    "# Usage example with your existing data:\n",
    "# Assuming x_pad_in and weight_int are available from your context\n",
    "\n",
    "# Method 1: Verbose display\n",
    "print(\"=== Method 1: Verbose MAC Output Display ===\")\n",
    "psum_memory = generate_debug_data_4b4b_with_mac_output(x_pad_in, weight_int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== Method 2: Compact MAC Output Display ===\")\n",
    "# Method 2: Compact display\n",
    "psum_memory_compact = generate_debug_data_compact_mac_output(x_pad_in, weight_int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "# Method 3: Save to file\n",
    "print(\"=== Method 3: Saving MAC Outputs to File ===\")\n",
    "save_mac_outputs_to_file(x_pad_in, weight_int)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ece284fa25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
