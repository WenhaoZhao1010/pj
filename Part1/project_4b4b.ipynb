{"cells":[{"cell_type":"code","execution_count":2,"id":"radical-fifty","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"radical-fifty","executionInfo":{"status":"ok","timestamp":1764040191831,"user_tz":480,"elapsed":18852,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"89629fe0-d07c-491a-ce6c-56a2c369910c","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["=> Building model...\n","VGG_quant(\n","  (features): Sequential(\n","    (0): QuantConv2d(\n","      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): QuantConv2d(\n","      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): QuantConv2d(\n","      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): QuantConv2d(\n","      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): QuantConv2d(\n","      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): QuantConv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): QuantConv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): QuantConv2d(\n","      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace=True)\n","    (27): QuantConv2d(\n","      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (28): ReLU(inplace=True)\n","    (29): QuantConv2d(\n","      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (31): ReLU(inplace=True)\n","    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (33): QuantConv2d(\n","      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (35): ReLU(inplace=True)\n","    (36): QuantConv2d(\n","      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (38): ReLU(inplace=True)\n","    (39): QuantConv2d(\n","      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (weight_quant): weight_quantize_fn()\n","    )\n","    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (41): ReLU(inplace=True)\n","    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","  )\n","  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:06<00:00, 27.3MB/s]\n"]}],"source":["import argparse\n","import os\n","import time\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from models import *\n","\n","\n","global best_prec\n","use_gpu = torch.cuda.is_available()\n","print('=> Building model...')\n","\n","\n","\n","batch_size = 128\n","model_name = \"VGG16_project\"\n","model = VGG16_project()\n","\n","print(model)\n","\n","normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n","\n","\n","train_dataset = torchvision.datasets.CIFAR10(\n","    root='./data',\n","    train=True,\n","    download=True,\n","    transform=transforms.Compose([\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]))\n","trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","\n","test_dataset = torchvision.datasets.CIFAR10(\n","    root='./data',\n","    train=False,\n","    download=True,\n","    transform=transforms.Compose([\n","        transforms.ToTensor(),\n","        normalize,\n","    ]))\n","\n","testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","\n","print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n","# CIFAR10 has 50,000 training data, and 10,000 validation data.\n","\n","def train(trainloader, model, criterion, optimizer, epoch):\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(trainloader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        input, target = input.cuda(), target.cuda()\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss\n","        prec = accuracy(output, target)[0]\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(prec.item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","\n","        if i % print_freq == 0:\n","            print('Epoch: [{0}][{1}/{2}]\\t'\n","                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n","                   epoch, i, len(trainloader), batch_time=batch_time,\n","                   data_time=data_time, loss=losses, top1=top1))\n","\n","\n","\n","def validate(val_loader, model, criterion ):\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    end = time.time()\n","    with torch.no_grad():\n","        for i, (input, target) in enumerate(val_loader):\n","\n","            input, target = input.cuda(), target.cuda()\n","\n","            # compute output\n","            output = model(input)\n","            loss = criterion(output, target)\n","\n","            # measure accuracy and record loss\n","            prec = accuracy(output, target)[0]\n","            losses.update(loss.item(), input.size(0))\n","            top1.update(prec.item(), input.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n","                print('Test: [{0}/{1}]\\t'\n","                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n","                   i, len(val_loader), batch_time=batch_time, loss=losses,\n","                   top1=top1))\n","\n","    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n","    return top1.avg\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def save_checkpoint(state, is_best, fdir):\n","    filepath = os.path.join(fdir, 'checkpoint.pth')\n","    torch.save(state, filepath)\n","    if is_best:\n","        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n","\n","#model = nn.DataParallel(model).cuda()\n","#all_params = checkpoint['state_dict']\n","#model.load_state_dict(all_params, strict=False)\n","#criterion = nn.CrossEntropyLoss().cuda()\n","#validate(testloader, model, criterion)"]},{"cell_type":"code","execution_count":null,"id":"2107ceeb","metadata":{"id":"2107ceeb"},"outputs":[],"source":["def adjust_learning_rate(optimizer, epoch):\n","    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n","    adjust_list = [60, 80]\n","    if epoch in adjust_list:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = param_group['lr'] * 0.1"]},{"cell_type":"code","execution_count":null,"id":"junior-reminder","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"junior-reminder","executionInfo":{"status":"ok","timestamp":1763673064939,"user_tz":480,"elapsed":1141625,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"acebe3e4-e18b-4204-adb6-4d85fbe5e809","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [0][0/391]\tTime 0.727 (0.727)\tData 0.114 (0.114)\tLoss 2.7576 (2.7576)\tPrec 6.250% (6.250%)\n","Epoch: [0][100/391]\tTime 0.023 (0.031)\tData 0.002 (0.004)\tLoss 2.2631 (3.2371)\tPrec 15.625% (11.239%)\n","Epoch: [0][200/391]\tTime 0.022 (0.028)\tData 0.001 (0.004)\tLoss 2.2255 (2.7506)\tPrec 10.938% (12.310%)\n","Epoch: [0][300/391]\tTime 0.023 (0.028)\tData 0.001 (0.004)\tLoss 2.1637 (2.5610)\tPrec 12.500% (13.489%)\n","Validation starts\n","Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.9992 (1.9992)\tPrec 25.781% (25.781%)\n"," * Prec 23.890% \n","best acc: 23.890000\n","Epoch: [1][0/391]\tTime 0.159 (0.159)\tData 0.126 (0.126)\tLoss 2.0727 (2.0727)\tPrec 18.750% (18.750%)\n","Epoch: [1][100/391]\tTime 0.027 (0.026)\tData 0.005 (0.004)\tLoss 1.9641 (2.0087)\tPrec 18.750% (24.010%)\n","Epoch: [1][200/391]\tTime 0.033 (0.026)\tData 0.007 (0.004)\tLoss 1.8855 (1.9793)\tPrec 25.000% (24.351%)\n","Epoch: [1][300/391]\tTime 0.028 (0.026)\tData 0.006 (0.003)\tLoss 1.8949 (1.9505)\tPrec 28.125% (24.961%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.7862 (1.7862)\tPrec 33.594% (33.594%)\n"," * Prec 31.710% \n","best acc: 31.710000\n","Epoch: [2][0/391]\tTime 0.156 (0.156)\tData 0.126 (0.126)\tLoss 1.7624 (1.7624)\tPrec 27.344% (27.344%)\n","Epoch: [2][100/391]\tTime 0.027 (0.026)\tData 0.005 (0.004)\tLoss 1.6989 (1.8058)\tPrec 33.594% (30.956%)\n","Epoch: [2][200/391]\tTime 0.025 (0.025)\tData 0.002 (0.004)\tLoss 1.8278 (1.7851)\tPrec 32.031% (31.973%)\n","Epoch: [2][300/391]\tTime 0.024 (0.026)\tData 0.002 (0.003)\tLoss 1.6233 (1.7602)\tPrec 43.750% (33.303%)\n","Validation starts\n","Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.6709 (1.6709)\tPrec 38.281% (38.281%)\n"," * Prec 36.610% \n","best acc: 36.610000\n","Epoch: [3][0/391]\tTime 0.169 (0.169)\tData 0.132 (0.132)\tLoss 1.7451 (1.7451)\tPrec 39.844% (39.844%)\n","Epoch: [3][100/391]\tTime 0.028 (0.027)\tData 0.006 (0.005)\tLoss 1.5547 (1.6084)\tPrec 48.438% (40.091%)\n","Epoch: [3][200/391]\tTime 0.028 (0.026)\tData 0.006 (0.004)\tLoss 1.6634 (1.5759)\tPrec 42.969% (41.305%)\n","Epoch: [3][300/391]\tTime 0.022 (0.026)\tData 0.001 (0.004)\tLoss 1.6200 (1.5516)\tPrec 40.625% (42.011%)\n","Validation starts\n","Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.4282 (1.4282)\tPrec 47.656% (47.656%)\n"," * Prec 44.980% \n","best acc: 44.980000\n","Epoch: [4][0/391]\tTime 0.150 (0.150)\tData 0.121 (0.121)\tLoss 1.4798 (1.4798)\tPrec 43.750% (43.750%)\n","Epoch: [4][100/391]\tTime 0.029 (0.026)\tData 0.008 (0.005)\tLoss 1.4768 (1.4004)\tPrec 44.531% (47.517%)\n","Epoch: [4][200/391]\tTime 0.022 (0.026)\tData 0.001 (0.004)\tLoss 1.3511 (1.3788)\tPrec 55.469% (48.562%)\n","Epoch: [4][300/391]\tTime 0.021 (0.026)\tData 0.001 (0.004)\tLoss 1.4234 (1.3618)\tPrec 43.750% (49.447%)\n","Validation starts\n","Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.2444 (1.2444)\tPrec 52.344% (52.344%)\n"," * Prec 54.060% \n","best acc: 54.060000\n","Epoch: [5][0/391]\tTime 0.150 (0.150)\tData 0.121 (0.121)\tLoss 1.2382 (1.2382)\tPrec 52.344% (52.344%)\n","Epoch: [5][100/391]\tTime 0.031 (0.026)\tData 0.010 (0.005)\tLoss 1.0295 (1.2440)\tPrec 67.188% (54.440%)\n","Epoch: [5][200/391]\tTime 0.027 (0.026)\tData 0.004 (0.004)\tLoss 1.2688 (1.2367)\tPrec 53.125% (54.967%)\n","Epoch: [5][300/391]\tTime 0.028 (0.026)\tData 0.006 (0.004)\tLoss 1.2357 (1.2166)\tPrec 54.688% (55.539%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.0753 (1.0753)\tPrec 60.938% (60.938%)\n"," * Prec 56.720% \n","best acc: 56.720000\n","Epoch: [6][0/391]\tTime 0.155 (0.155)\tData 0.126 (0.126)\tLoss 1.0527 (1.0527)\tPrec 59.375% (59.375%)\n","Epoch: [6][100/391]\tTime 0.024 (0.026)\tData 0.003 (0.004)\tLoss 1.0934 (1.0901)\tPrec 57.812% (60.295%)\n","Epoch: [6][200/391]\tTime 0.026 (0.025)\tData 0.002 (0.004)\tLoss 0.9498 (1.0862)\tPrec 65.625% (60.650%)\n","Epoch: [6][300/391]\tTime 0.023 (0.025)\tData 0.002 (0.004)\tLoss 1.1131 (1.0751)\tPrec 61.719% (61.184%)\n","Validation starts\n","Test: [0/79]\tTime 0.104 (0.104)\tLoss 0.9853 (0.9853)\tPrec 61.719% (61.719%)\n"," * Prec 61.460% \n","best acc: 61.460000\n","Epoch: [7][0/391]\tTime 0.162 (0.162)\tData 0.125 (0.125)\tLoss 0.9723 (0.9723)\tPrec 64.062% (64.062%)\n","Epoch: [7][100/391]\tTime 0.028 (0.026)\tData 0.005 (0.004)\tLoss 0.8207 (0.9819)\tPrec 73.438% (64.790%)\n","Epoch: [7][200/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 0.9020 (0.9603)\tPrec 64.844% (65.633%)\n","Epoch: [7][300/391]\tTime 0.021 (0.026)\tData 0.001 (0.004)\tLoss 0.8182 (0.9532)\tPrec 77.344% (66.048%)\n","Validation starts\n","Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.0521 (1.0521)\tPrec 59.375% (59.375%)\n"," * Prec 64.190% \n","best acc: 64.190000\n","Epoch: [8][0/391]\tTime 0.153 (0.153)\tData 0.125 (0.125)\tLoss 0.7905 (0.7905)\tPrec 71.875% (71.875%)\n","Epoch: [8][100/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 0.7690 (0.8781)\tPrec 68.750% (68.874%)\n","Epoch: [8][200/391]\tTime 0.022 (0.025)\tData 0.001 (0.004)\tLoss 0.8254 (0.8672)\tPrec 64.844% (69.337%)\n","Epoch: [8][300/391]\tTime 0.021 (0.025)\tData 0.001 (0.004)\tLoss 0.7795 (0.8597)\tPrec 71.094% (69.557%)\n","Validation starts\n","Test: [0/79]\tTime 0.104 (0.104)\tLoss 0.8161 (0.8161)\tPrec 67.188% (67.188%)\n"," * Prec 67.420% \n","best acc: 67.420000\n","Epoch: [9][0/391]\tTime 0.158 (0.158)\tData 0.121 (0.121)\tLoss 0.7810 (0.7810)\tPrec 71.875% (71.875%)\n","Epoch: [9][100/391]\tTime 0.026 (0.026)\tData 0.005 (0.004)\tLoss 0.6293 (0.7995)\tPrec 78.125% (72.215%)\n","Epoch: [9][200/391]\tTime 0.021 (0.026)\tData 0.000 (0.004)\tLoss 0.7613 (0.8011)\tPrec 73.438% (72.128%)\n","Epoch: [9][300/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 0.7916 (0.7972)\tPrec 73.438% (72.161%)\n","Validation starts\n","Test: [0/79]\tTime 0.105 (0.105)\tLoss 0.7109 (0.7109)\tPrec 73.438% (73.438%)\n"," * Prec 71.680% \n","best acc: 71.680000\n","Epoch: [10][0/391]\tTime 0.151 (0.151)\tData 0.121 (0.121)\tLoss 0.6801 (0.6801)\tPrec 77.344% (77.344%)\n","Epoch: [10][100/391]\tTime 0.026 (0.026)\tData 0.005 (0.004)\tLoss 0.7838 (0.7429)\tPrec 72.656% (73.731%)\n","Epoch: [10][200/391]\tTime 0.026 (0.025)\tData 0.005 (0.004)\tLoss 0.8531 (0.7358)\tPrec 71.094% (74.168%)\n","Epoch: [10][300/391]\tTime 0.027 (0.025)\tData 0.006 (0.004)\tLoss 0.4470 (0.7336)\tPrec 86.719% (74.434%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.7071 (0.7071)\tPrec 76.562% (76.562%)\n"," * Prec 73.370% \n","best acc: 73.370000\n","Epoch: [11][0/391]\tTime 0.158 (0.158)\tData 0.129 (0.129)\tLoss 0.7250 (0.7250)\tPrec 72.656% (72.656%)\n","Epoch: [11][100/391]\tTime 0.028 (0.026)\tData 0.006 (0.005)\tLoss 0.6505 (0.6908)\tPrec 79.688% (75.913%)\n","Epoch: [11][200/391]\tTime 0.026 (0.026)\tData 0.004 (0.004)\tLoss 0.6905 (0.6846)\tPrec 71.875% (76.271%)\n","Epoch: [11][300/391]\tTime 0.024 (0.025)\tData 0.002 (0.004)\tLoss 0.6696 (0.6816)\tPrec 72.656% (76.420%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.8356 (0.8356)\tPrec 73.438% (73.438%)\n"," * Prec 74.250% \n","best acc: 74.250000\n","Epoch: [12][0/391]\tTime 0.149 (0.149)\tData 0.120 (0.120)\tLoss 0.6546 (0.6546)\tPrec 77.344% (77.344%)\n","Epoch: [12][100/391]\tTime 0.026 (0.026)\tData 0.005 (0.004)\tLoss 0.6461 (0.6387)\tPrec 78.906% (77.924%)\n","Epoch: [12][200/391]\tTime 0.023 (0.025)\tData 0.002 (0.003)\tLoss 0.7465 (0.6358)\tPrec 74.219% (78.133%)\n","Epoch: [12][300/391]\tTime 0.028 (0.025)\tData 0.007 (0.003)\tLoss 0.5723 (0.6384)\tPrec 78.906% (78.086%)\n","Validation starts\n","Test: [0/79]\tTime 0.105 (0.105)\tLoss 0.6889 (0.6889)\tPrec 75.000% (75.000%)\n"," * Prec 77.690% \n","best acc: 77.690000\n","Epoch: [13][0/391]\tTime 0.148 (0.148)\tData 0.119 (0.119)\tLoss 0.6529 (0.6529)\tPrec 82.031% (82.031%)\n","Epoch: [13][100/391]\tTime 0.028 (0.026)\tData 0.007 (0.004)\tLoss 0.4339 (0.6006)\tPrec 87.500% (79.394%)\n","Epoch: [13][200/391]\tTime 0.031 (0.026)\tData 0.008 (0.004)\tLoss 0.6827 (0.5992)\tPrec 77.344% (79.513%)\n","Epoch: [13][300/391]\tTime 0.029 (0.025)\tData 0.006 (0.004)\tLoss 0.7290 (0.5963)\tPrec 75.781% (79.625%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.7076 (0.7076)\tPrec 74.219% (74.219%)\n"," * Prec 76.050% \n","best acc: 77.690000\n","Epoch: [14][0/391]\tTime 0.150 (0.150)\tData 0.122 (0.122)\tLoss 0.5337 (0.5337)\tPrec 80.469% (80.469%)\n","Epoch: [14][100/391]\tTime 0.023 (0.026)\tData 0.002 (0.005)\tLoss 0.5641 (0.5711)\tPrec 82.031% (80.569%)\n","Epoch: [14][200/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.5715 (0.5668)\tPrec 78.906% (80.772%)\n","Epoch: [14][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.5024 (0.5671)\tPrec 80.469% (80.824%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.7577 (0.7577)\tPrec 75.000% (75.000%)\n"," * Prec 74.810% \n","best acc: 77.690000\n","Epoch: [15][0/391]\tTime 0.153 (0.153)\tData 0.118 (0.118)\tLoss 0.6014 (0.6014)\tPrec 78.906% (78.906%)\n","Epoch: [15][100/391]\tTime 0.027 (0.026)\tData 0.005 (0.005)\tLoss 0.6038 (0.5401)\tPrec 77.344% (81.459%)\n","Epoch: [15][200/391]\tTime 0.029 (0.025)\tData 0.006 (0.004)\tLoss 0.4504 (0.5388)\tPrec 85.938% (81.759%)\n","Epoch: [15][300/391]\tTime 0.029 (0.025)\tData 0.007 (0.004)\tLoss 0.5739 (0.5345)\tPrec 82.031% (81.863%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.6842 (0.6842)\tPrec 76.562% (76.562%)\n"," * Prec 78.450% \n","best acc: 78.450000\n","Epoch: [16][0/391]\tTime 0.150 (0.150)\tData 0.121 (0.121)\tLoss 0.4350 (0.4350)\tPrec 85.156% (85.156%)\n","Epoch: [16][100/391]\tTime 0.026 (0.026)\tData 0.004 (0.004)\tLoss 0.5600 (0.5176)\tPrec 80.469% (81.969%)\n","Epoch: [16][200/391]\tTime 0.025 (0.025)\tData 0.002 (0.003)\tLoss 0.3594 (0.5165)\tPrec 86.719% (82.311%)\n","Epoch: [16][300/391]\tTime 0.027 (0.025)\tData 0.006 (0.003)\tLoss 0.5676 (0.5118)\tPrec 78.125% (82.400%)\n","Validation starts\n","Test: [0/79]\tTime 0.108 (0.108)\tLoss 0.4903 (0.4903)\tPrec 85.156% (85.156%)\n"," * Prec 80.930% \n","best acc: 80.930000\n","Epoch: [17][0/391]\tTime 0.159 (0.159)\tData 0.121 (0.121)\tLoss 0.4536 (0.4536)\tPrec 85.156% (85.156%)\n","Epoch: [17][100/391]\tTime 0.028 (0.027)\tData 0.006 (0.004)\tLoss 0.5495 (0.4871)\tPrec 81.250% (83.679%)\n","Epoch: [17][200/391]\tTime 0.028 (0.026)\tData 0.007 (0.004)\tLoss 0.6001 (0.4808)\tPrec 78.125% (83.757%)\n","Epoch: [17][300/391]\tTime 0.026 (0.026)\tData 0.004 (0.003)\tLoss 0.5315 (0.4834)\tPrec 84.375% (83.513%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.5575 (0.5575)\tPrec 81.250% (81.250%)\n"," * Prec 78.610% \n","best acc: 80.930000\n","Epoch: [18][0/391]\tTime 0.148 (0.148)\tData 0.119 (0.119)\tLoss 0.4060 (0.4060)\tPrec 86.719% (86.719%)\n","Epoch: [18][100/391]\tTime 0.027 (0.026)\tData 0.005 (0.004)\tLoss 0.3922 (0.4617)\tPrec 85.938% (84.182%)\n","Epoch: [18][200/391]\tTime 0.023 (0.025)\tData 0.002 (0.004)\tLoss 0.4645 (0.4583)\tPrec 85.938% (84.433%)\n","Epoch: [18][300/391]\tTime 0.028 (0.025)\tData 0.006 (0.003)\tLoss 0.3450 (0.4604)\tPrec 89.062% (84.367%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.5035 (0.5035)\tPrec 83.594% (83.594%)\n"," * Prec 82.100% \n","best acc: 82.100000\n","Epoch: [19][0/391]\tTime 0.150 (0.150)\tData 0.122 (0.122)\tLoss 0.4263 (0.4263)\tPrec 87.500% (87.500%)\n","Epoch: [19][100/391]\tTime 0.021 (0.026)\tData 0.001 (0.005)\tLoss 0.5084 (0.4422)\tPrec 85.938% (85.125%)\n","Epoch: [19][200/391]\tTime 0.024 (0.025)\tData 0.002 (0.004)\tLoss 0.5009 (0.4426)\tPrec 85.156% (85.094%)\n","Epoch: [19][300/391]\tTime 0.028 (0.025)\tData 0.006 (0.004)\tLoss 0.3793 (0.4411)\tPrec 89.062% (85.073%)\n","Validation starts\n","Test: [0/79]\tTime 0.108 (0.108)\tLoss 0.4473 (0.4473)\tPrec 84.375% (84.375%)\n"," * Prec 81.420% \n","best acc: 82.100000\n","Epoch: [20][0/391]\tTime 0.152 (0.152)\tData 0.123 (0.123)\tLoss 0.4421 (0.4421)\tPrec 82.812% (82.812%)\n","Epoch: [20][100/391]\tTime 0.024 (0.026)\tData 0.002 (0.005)\tLoss 0.4731 (0.4193)\tPrec 82.031% (85.644%)\n","Epoch: [20][200/391]\tTime 0.023 (0.025)\tData 0.002 (0.004)\tLoss 0.4679 (0.4228)\tPrec 82.031% (85.553%)\n","Epoch: [20][300/391]\tTime 0.027 (0.025)\tData 0.006 (0.004)\tLoss 0.5220 (0.4245)\tPrec 82.031% (85.564%)\n","Validation starts\n","Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.4024 (0.4024)\tPrec 85.938% (85.938%)\n"," * Prec 82.460% \n","best acc: 82.460000\n","Epoch: [21][0/391]\tTime 0.148 (0.148)\tData 0.120 (0.120)\tLoss 0.5299 (0.5299)\tPrec 84.375% (84.375%)\n","Epoch: [21][100/391]\tTime 0.026 (0.026)\tData 0.004 (0.004)\tLoss 0.3735 (0.4028)\tPrec 86.719% (86.804%)\n","Epoch: [21][200/391]\tTime 0.025 (0.025)\tData 0.004 (0.004)\tLoss 0.4031 (0.4087)\tPrec 89.062% (86.466%)\n","Epoch: [21][300/391]\tTime 0.021 (0.025)\tData 0.001 (0.004)\tLoss 0.3520 (0.4075)\tPrec 89.062% (86.311%)\n","Validation starts\n","Test: [0/79]\tTime 0.104 (0.104)\tLoss 0.3897 (0.3897)\tPrec 85.938% (85.938%)\n"," * Prec 83.170% \n","best acc: 83.170000\n","Epoch: [22][0/391]\tTime 0.154 (0.154)\tData 0.125 (0.125)\tLoss 0.4098 (0.4098)\tPrec 85.156% (85.156%)\n","Epoch: [22][100/391]\tTime 0.023 (0.026)\tData 0.002 (0.004)\tLoss 0.3602 (0.3733)\tPrec 88.281% (87.438%)\n","Epoch: [22][200/391]\tTime 0.021 (0.026)\tData 0.001 (0.004)\tLoss 0.4156 (0.3818)\tPrec 86.719% (86.960%)\n","Epoch: [22][300/391]\tTime 0.022 (0.026)\tData 0.001 (0.004)\tLoss 0.4418 (0.3819)\tPrec 82.812% (86.890%)\n","Validation starts\n","Test: [0/79]\tTime 0.105 (0.105)\tLoss 0.4660 (0.4660)\tPrec 84.375% (84.375%)\n"," * Prec 81.540% \n","best acc: 83.170000\n","Epoch: [23][0/391]\tTime 0.152 (0.152)\tData 0.123 (0.123)\tLoss 0.5323 (0.5323)\tPrec 83.594% (83.594%)\n","Epoch: [23][100/391]\tTime 0.028 (0.026)\tData 0.006 (0.004)\tLoss 0.2898 (0.3590)\tPrec 88.281% (87.864%)\n","Epoch: [23][200/391]\tTime 0.028 (0.025)\tData 0.006 (0.004)\tLoss 0.2956 (0.3655)\tPrec 91.406% (87.582%)\n","Epoch: [23][300/391]\tTime 0.024 (0.025)\tData 0.003 (0.003)\tLoss 0.3378 (0.3720)\tPrec 87.500% (87.407%)\n","Validation starts\n","Test: [0/79]\tTime 0.105 (0.105)\tLoss 0.4018 (0.4018)\tPrec 89.062% (89.062%)\n"," * Prec 84.120% \n","best acc: 84.120000\n","Epoch: [24][0/391]\tTime 0.150 (0.150)\tData 0.122 (0.122)\tLoss 0.2889 (0.2889)\tPrec 91.406% (91.406%)\n","Epoch: [24][100/391]\tTime 0.023 (0.026)\tData 0.002 (0.004)\tLoss 0.4449 (0.3531)\tPrec 89.062% (88.127%)\n","Epoch: [24][200/391]\tTime 0.029 (0.026)\tData 0.007 (0.004)\tLoss 0.4288 (0.3603)\tPrec 85.156% (87.698%)\n","Epoch: [24][300/391]\tTime 0.025 (0.026)\tData 0.003 (0.004)\tLoss 0.2085 (0.3604)\tPrec 92.188% (87.632%)\n","Validation starts\n","Test: [0/79]\tTime 0.106 (0.106)\tLoss 0.5566 (0.5566)\tPrec 82.812% (82.812%)\n"," * Prec 81.080% \n","best acc: 84.120000\n","Epoch: [25][0/391]\tTime 0.157 (0.157)\tData 0.121 (0.121)\tLoss 0.4013 (0.4013)\tPrec 84.375% (84.375%)\n","Epoch: [25][100/391]\tTime 0.027 (0.026)\tData 0.006 (0.004)\tLoss 0.3936 (0.3410)\tPrec 86.719% (88.506%)\n","Epoch: [25][200/391]\tTime 0.027 (0.025)\tData 0.006 (0.004)\tLoss 0.3414 (0.3432)\tPrec 85.938% (88.371%)\n","Epoch: [25][300/391]\tTime 0.024 (0.025)\tData 0.002 (0.004)\tLoss 0.3839 (0.3457)\tPrec 88.281% (88.276%)\n","Validation starts\n","Test: [0/79]\tTime 0.110 (0.110)\tLoss 0.5161 (0.5161)\tPrec 82.812% (82.812%)\n"," * Prec 84.360% \n","best acc: 84.360000\n","Epoch: [26][0/391]\tTime 0.155 (0.155)\tData 0.126 (0.126)\tLoss 0.3351 (0.3351)\tPrec 89.062% (89.062%)\n","Epoch: [26][100/391]\tTime 0.027 (0.026)\tData 0.005 (0.005)\tLoss 0.2916 (0.3300)\tPrec 91.406% (88.769%)\n","Epoch: [26][200/391]\tTime 0.029 (0.026)\tData 0.008 (0.004)\tLoss 0.3340 (0.3290)\tPrec 86.719% (88.732%)\n","Epoch: [26][300/391]\tTime 0.029 (0.026)\tData 0.007 (0.004)\tLoss 0.3396 (0.3299)\tPrec 88.281% (88.816%)\n","Validation starts\n","Test: [0/79]\tTime 0.104 (0.104)\tLoss 0.3289 (0.3289)\tPrec 89.062% (89.062%)\n"," * Prec 85.260% \n","best acc: 85.260000\n","Epoch: [27][0/391]\tTime 0.148 (0.148)\tData 0.119 (0.119)\tLoss 0.2601 (0.2601)\tPrec 92.969% (92.969%)\n","Epoch: [27][100/391]\tTime 0.028 (0.026)\tData 0.006 (0.004)\tLoss 0.2829 (0.3040)\tPrec 92.188% (89.828%)\n","Epoch: [27][200/391]\tTime 0.027 (0.025)\tData 0.006 (0.004)\tLoss 0.3569 (0.3081)\tPrec 89.844% (89.688%)\n","Epoch: [27][300/391]\tTime 0.031 (0.026)\tData 0.008 (0.004)\tLoss 0.3176 (0.3183)\tPrec 86.719% (89.369%)\n","Validation starts\n","Test: [0/79]\tTime 0.106 (0.106)\tLoss 0.3917 (0.3917)\tPrec 87.500% (87.500%)\n"," * Prec 84.920% \n","best acc: 85.260000\n","Epoch: [28][0/391]\tTime 0.162 (0.162)\tData 0.125 (0.125)\tLoss 0.2246 (0.2246)\tPrec 92.969% (92.969%)\n","Epoch: [28][100/391]\tTime 0.026 (0.026)\tData 0.005 (0.004)\tLoss 0.2380 (0.2877)\tPrec 91.406% (89.975%)\n","Epoch: [28][200/391]\tTime 0.025 (0.025)\tData 0.004 (0.003)\tLoss 0.2980 (0.3025)\tPrec 89.844% (89.591%)\n","Epoch: [28][300/391]\tTime 0.031 (0.026)\tData 0.002 (0.003)\tLoss 0.2887 (0.3053)\tPrec 86.719% (89.587%)\n","Validation starts\n","Test: [0/79]\tTime 0.105 (0.105)\tLoss 0.3935 (0.3935)\tPrec 85.156% (85.156%)\n"," * Prec 84.590% \n","best acc: 85.260000\n","Epoch: [29][0/391]\tTime 0.157 (0.157)\tData 0.128 (0.128)\tLoss 0.3156 (0.3156)\tPrec 91.406% (91.406%)\n","Epoch: [29][100/391]\tTime 0.029 (0.027)\tData 0.007 (0.005)\tLoss 0.3104 (0.2940)\tPrec 92.188% (90.053%)\n","Epoch: [29][200/391]\tTime 0.028 (0.026)\tData 0.006 (0.005)\tLoss 0.3622 (0.2969)\tPrec 86.719% (89.902%)\n","Epoch: [29][300/391]\tTime 0.028 (0.026)\tData 0.007 (0.004)\tLoss 0.2202 (0.2984)\tPrec 89.844% (89.800%)\n","Validation starts\n","Test: [0/79]\tTime 0.103 (0.103)\tLoss 0.3967 (0.3967)\tPrec 88.281% (88.281%)\n"," * Prec 85.290% \n","best acc: 85.290000\n","Epoch: [30][0/391]\tTime 0.150 (0.150)\tData 0.119 (0.119)\tLoss 0.3313 (0.3313)\tPrec 89.844% (89.844%)\n","Epoch: [30][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.2678 (0.2706)\tPrec 92.188% (90.710%)\n","Epoch: [30][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.2449 (0.2854)\tPrec 91.406% (90.213%)\n","Epoch: [30][300/391]\tTime 0.026 (0.026)\tData 0.007 (0.004)\tLoss 0.4143 (0.2854)\tPrec 87.500% (90.173%)\n","Validation starts\n","Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.3473 (0.3473)\tPrec 91.406% (91.406%)\n"," * Prec 84.990% \n","best acc: 85.290000\n","Epoch: [31][0/391]\tTime 0.145 (0.145)\tData 0.118 (0.118)\tLoss 0.2256 (0.2256)\tPrec 91.406% (91.406%)\n","Epoch: [31][100/391]\tTime 0.026 (0.025)\tData 0.007 (0.005)\tLoss 0.2300 (0.2654)\tPrec 91.406% (90.780%)\n","Epoch: [31][200/391]\tTime 0.025 (0.025)\tData 0.005 (0.005)\tLoss 0.1392 (0.2680)\tPrec 95.312% (90.940%)\n","Epoch: [31][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.3055 (0.2734)\tPrec 89.844% (90.648%)\n","Validation starts\n","Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.3909 (0.3909)\tPrec 86.719% (86.719%)\n"," * Prec 85.680% \n","best acc: 85.680000\n","Epoch: [32][0/391]\tTime 0.148 (0.148)\tData 0.120 (0.120)\tLoss 0.3050 (0.3050)\tPrec 89.844% (89.844%)\n","Epoch: [32][100/391]\tTime 0.028 (0.025)\tData 0.008 (0.006)\tLoss 0.2849 (0.2502)\tPrec 89.062% (91.414%)\n","Epoch: [32][200/391]\tTime 0.029 (0.025)\tData 0.010 (0.005)\tLoss 0.2410 (0.2606)\tPrec 92.188% (91.056%)\n","Epoch: [32][300/391]\tTime 0.019 (0.025)\tData 0.000 (0.005)\tLoss 0.3274 (0.2636)\tPrec 88.281% (90.988%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.3635 (0.3635)\tPrec 88.281% (88.281%)\n"," * Prec 87.110% \n","best acc: 87.110000\n","Epoch: [33][0/391]\tTime 0.143 (0.143)\tData 0.116 (0.116)\tLoss 0.3047 (0.3047)\tPrec 85.156% (85.156%)\n","Epoch: [33][100/391]\tTime 0.020 (0.025)\tData 0.000 (0.006)\tLoss 0.2406 (0.2496)\tPrec 95.312% (91.499%)\n","Epoch: [33][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.2314 (0.2562)\tPrec 92.188% (91.352%)\n","Epoch: [33][300/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.3420 (0.2586)\tPrec 87.500% (91.240%)\n","Validation starts\n","Test: [0/79]\tTime 0.105 (0.105)\tLoss 0.3011 (0.3011)\tPrec 89.844% (89.844%)\n"," * Prec 85.210% \n","best acc: 87.110000\n","Epoch: [34][0/391]\tTime 0.144 (0.144)\tData 0.117 (0.117)\tLoss 0.2414 (0.2414)\tPrec 92.188% (92.188%)\n","Epoch: [34][100/391]\tTime 0.019 (0.026)\tData 0.000 (0.006)\tLoss 0.4892 (0.2414)\tPrec 86.719% (91.894%)\n","Epoch: [34][200/391]\tTime 0.019 (0.025)\tData 0.000 (0.006)\tLoss 0.3961 (0.2530)\tPrec 86.719% (91.476%)\n","Epoch: [34][300/391]\tTime 0.022 (0.025)\tData 0.000 (0.006)\tLoss 0.2710 (0.2526)\tPrec 93.750% (91.536%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.3853 (0.3853)\tPrec 87.500% (87.500%)\n"," * Prec 85.130% \n","best acc: 87.110000\n","Epoch: [35][0/391]\tTime 0.147 (0.147)\tData 0.120 (0.120)\tLoss 0.3034 (0.3034)\tPrec 89.844% (89.844%)\n","Epoch: [35][100/391]\tTime 0.030 (0.026)\tData 0.003 (0.006)\tLoss 0.3316 (0.2374)\tPrec 89.062% (92.033%)\n","Epoch: [35][200/391]\tTime 0.020 (0.028)\tData 0.000 (0.005)\tLoss 0.1313 (0.2453)\tPrec 96.094% (91.861%)\n","Epoch: [35][300/391]\tTime 0.029 (0.027)\tData 0.005 (0.005)\tLoss 0.1782 (0.2455)\tPrec 91.406% (91.674%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.4656 (0.4656)\tPrec 86.719% (86.719%)\n"," * Prec 86.330% \n","best acc: 87.110000\n","Epoch: [36][0/391]\tTime 0.144 (0.144)\tData 0.118 (0.118)\tLoss 0.1726 (0.1726)\tPrec 92.969% (92.969%)\n","Epoch: [36][100/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 0.2337 (0.2335)\tPrec 92.188% (91.909%)\n","Epoch: [36][200/391]\tTime 0.027 (0.025)\tData 0.008 (0.005)\tLoss 0.2969 (0.2393)\tPrec 90.625% (91.873%)\n","Epoch: [36][300/391]\tTime 0.027 (0.025)\tData 0.001 (0.005)\tLoss 0.1792 (0.2410)\tPrec 95.312% (91.899%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.3172 (0.3172)\tPrec 90.625% (90.625%)\n"," * Prec 86.040% \n","best acc: 87.110000\n","Epoch: [37][0/391]\tTime 0.150 (0.150)\tData 0.122 (0.122)\tLoss 0.1922 (0.1922)\tPrec 92.969% (92.969%)\n","Epoch: [37][100/391]\tTime 0.030 (0.026)\tData 0.011 (0.006)\tLoss 0.2663 (0.2316)\tPrec 91.406% (91.979%)\n","Epoch: [37][200/391]\tTime 0.027 (0.026)\tData 0.001 (0.005)\tLoss 0.1360 (0.2332)\tPrec 96.094% (92.013%)\n","Epoch: [37][300/391]\tTime 0.021 (0.026)\tData 0.002 (0.005)\tLoss 0.2764 (0.2367)\tPrec 90.625% (91.925%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2579 (0.2579)\tPrec 92.188% (92.188%)\n"," * Prec 86.050% \n","best acc: 87.110000\n","Epoch: [38][0/391]\tTime 0.147 (0.147)\tData 0.120 (0.120)\tLoss 0.2782 (0.2782)\tPrec 91.406% (91.406%)\n","Epoch: [38][100/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.3353 (0.2176)\tPrec 90.625% (92.667%)\n","Epoch: [38][200/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.2169 (0.2223)\tPrec 92.969% (92.463%)\n","Epoch: [38][300/391]\tTime 0.026 (0.025)\tData 0.005 (0.005)\tLoss 0.1556 (0.2295)\tPrec 96.094% (92.226%)\n","Validation starts\n","Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2334 (0.2334)\tPrec 92.188% (92.188%)\n"," * Prec 86.380% \n","best acc: 87.110000\n","Epoch: [39][0/391]\tTime 0.151 (0.151)\tData 0.116 (0.116)\tLoss 0.1371 (0.1371)\tPrec 96.094% (96.094%)\n","Epoch: [39][100/391]\tTime 0.022 (0.026)\tData 0.002 (0.005)\tLoss 0.1838 (0.2126)\tPrec 93.750% (93.162%)\n","Epoch: [39][200/391]\tTime 0.027 (0.025)\tData 0.008 (0.005)\tLoss 0.2490 (0.2181)\tPrec 92.188% (92.685%)\n","Epoch: [39][300/391]\tTime 0.043 (0.025)\tData 0.012 (0.005)\tLoss 0.2370 (0.2215)\tPrec 93.750% (92.582%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.3408 (0.3408)\tPrec 88.281% (88.281%)\n"," * Prec 86.120% \n","best acc: 87.110000\n","Epoch: [40][0/391]\tTime 0.144 (0.144)\tData 0.116 (0.116)\tLoss 0.1393 (0.1393)\tPrec 95.312% (95.312%)\n","Epoch: [40][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 0.2458 (0.2149)\tPrec 89.062% (92.860%)\n","Epoch: [40][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.006)\tLoss 0.2464 (0.2203)\tPrec 89.844% (92.545%)\n","Epoch: [40][300/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.2118 (0.2178)\tPrec 92.969% (92.650%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2867 (0.2867)\tPrec 90.625% (90.625%)\n"," * Prec 87.200% \n","best acc: 87.200000\n","Epoch: [41][0/391]\tTime 0.143 (0.143)\tData 0.116 (0.116)\tLoss 0.2327 (0.2327)\tPrec 90.625% (90.625%)\n","Epoch: [41][100/391]\tTime 0.030 (0.025)\tData 0.011 (0.006)\tLoss 0.1267 (0.2008)\tPrec 96.875% (93.139%)\n","Epoch: [41][200/391]\tTime 0.028 (0.025)\tData 0.009 (0.005)\tLoss 0.1409 (0.2051)\tPrec 96.094% (93.035%)\n","Epoch: [41][300/391]\tTime 0.028 (0.025)\tData 0.009 (0.005)\tLoss 0.2703 (0.2060)\tPrec 92.969% (92.974%)\n","Validation starts\n","Test: [0/79]\tTime 0.105 (0.105)\tLoss 0.3368 (0.3368)\tPrec 89.062% (89.062%)\n"," * Prec 85.680% \n","best acc: 87.200000\n","Epoch: [42][0/391]\tTime 0.152 (0.152)\tData 0.116 (0.116)\tLoss 0.2108 (0.2108)\tPrec 92.188% (92.188%)\n","Epoch: [42][100/391]\tTime 0.026 (0.026)\tData 0.007 (0.005)\tLoss 0.2599 (0.1984)\tPrec 91.406% (93.162%)\n","Epoch: [42][200/391]\tTime 0.027 (0.025)\tData 0.008 (0.005)\tLoss 0.2608 (0.2067)\tPrec 92.969% (92.809%)\n","Epoch: [42][300/391]\tTime 0.027 (0.025)\tData 0.008 (0.005)\tLoss 0.2929 (0.2090)\tPrec 89.844% (92.790%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.3467 (0.3467)\tPrec 86.719% (86.719%)\n"," * Prec 87.210% \n","best acc: 87.210000\n","Epoch: [43][0/391]\tTime 0.148 (0.148)\tData 0.120 (0.120)\tLoss 0.1319 (0.1319)\tPrec 95.312% (95.312%)\n","Epoch: [43][100/391]\tTime 0.020 (0.026)\tData 0.001 (0.006)\tLoss 0.1896 (0.1844)\tPrec 94.531% (93.371%)\n","Epoch: [43][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.006)\tLoss 0.1253 (0.1898)\tPrec 96.094% (93.319%)\n","Epoch: [43][300/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.2249 (0.1977)\tPrec 92.188% (93.114%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2533 (0.2533)\tPrec 93.750% (93.750%)\n"," * Prec 88.020% \n","best acc: 88.020000\n","Epoch: [44][0/391]\tTime 0.156 (0.156)\tData 0.121 (0.121)\tLoss 0.1725 (0.1725)\tPrec 94.531% (94.531%)\n","Epoch: [44][100/391]\tTime 0.022 (0.026)\tData 0.001 (0.005)\tLoss 0.0971 (0.1724)\tPrec 96.094% (94.052%)\n","Epoch: [44][200/391]\tTime 0.026 (0.025)\tData 0.006 (0.005)\tLoss 0.2710 (0.1825)\tPrec 92.188% (93.715%)\n","Epoch: [44][300/391]\tTime 0.025 (0.025)\tData 0.005 (0.005)\tLoss 0.1893 (0.1852)\tPrec 95.312% (93.659%)\n","Validation starts\n","Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.1997 (0.1997)\tPrec 92.188% (92.188%)\n"," * Prec 86.690% \n","best acc: 88.020000\n","Epoch: [45][0/391]\tTime 0.145 (0.145)\tData 0.117 (0.117)\tLoss 0.0940 (0.0940)\tPrec 97.656% (97.656%)\n","Epoch: [45][100/391]\tTime 0.027 (0.025)\tData 0.008 (0.005)\tLoss 0.2243 (0.1780)\tPrec 91.406% (93.905%)\n","Epoch: [45][200/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.2466 (0.1904)\tPrec 91.406% (93.548%)\n","Epoch: [45][300/391]\tTime 0.020 (0.024)\tData 0.000 (0.005)\tLoss 0.1527 (0.1939)\tPrec 93.750% (93.340%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.3200 (0.3200)\tPrec 91.406% (91.406%)\n"," * Prec 86.520% \n","best acc: 88.020000\n","Epoch: [46][0/391]\tTime 0.146 (0.146)\tData 0.119 (0.119)\tLoss 0.1345 (0.1345)\tPrec 96.094% (96.094%)\n","Epoch: [46][100/391]\tTime 0.027 (0.025)\tData 0.008 (0.005)\tLoss 0.1958 (0.1819)\tPrec 92.188% (93.889%)\n","Epoch: [46][200/391]\tTime 0.030 (0.025)\tData 0.009 (0.005)\tLoss 0.2090 (0.1812)\tPrec 92.969% (93.797%)\n","Epoch: [46][300/391]\tTime 0.032 (0.025)\tData 0.012 (0.005)\tLoss 0.2699 (0.1853)\tPrec 89.062% (93.618%)\n","Validation starts\n","Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.3583 (0.3583)\tPrec 89.844% (89.844%)\n"," * Prec 86.840% \n","best acc: 88.020000\n","Epoch: [47][0/391]\tTime 0.146 (0.146)\tData 0.118 (0.118)\tLoss 0.2351 (0.2351)\tPrec 91.406% (91.406%)\n","Epoch: [47][100/391]\tTime 0.028 (0.025)\tData 0.008 (0.006)\tLoss 0.1256 (0.1718)\tPrec 96.094% (94.175%)\n","Epoch: [47][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.2411 (0.1756)\tPrec 92.188% (94.053%)\n","Epoch: [47][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.3444 (0.1750)\tPrec 89.844% (94.090%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.3985 (0.3985)\tPrec 85.938% (85.938%)\n"," * Prec 85.900% \n","best acc: 88.020000\n","Epoch: [48][0/391]\tTime 0.146 (0.146)\tData 0.118 (0.118)\tLoss 0.2046 (0.2046)\tPrec 92.969% (92.969%)\n","Epoch: [48][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.006)\tLoss 0.1821 (0.1793)\tPrec 92.969% (93.704%)\n","Epoch: [48][200/391]\tTime 0.021 (0.025)\tData 0.000 (0.005)\tLoss 0.1993 (0.1776)\tPrec 92.969% (93.820%)\n","Epoch: [48][300/391]\tTime 0.021 (0.025)\tData 0.001 (0.005)\tLoss 0.1742 (0.1759)\tPrec 94.531% (93.919%)\n","Validation starts\n","Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.4988 (0.4988)\tPrec 87.500% (87.500%)\n"," * Prec 86.680% \n","best acc: 88.020000\n","Epoch: [49][0/391]\tTime 0.154 (0.154)\tData 0.118 (0.118)\tLoss 0.1563 (0.1563)\tPrec 93.750% (93.750%)\n","Epoch: [49][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.005)\tLoss 0.1742 (0.1570)\tPrec 93.750% (94.454%)\n","Epoch: [49][200/391]\tTime 0.028 (0.025)\tData 0.007 (0.005)\tLoss 0.1263 (0.1679)\tPrec 96.875% (94.181%)\n","Epoch: [49][300/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.1526 (0.1699)\tPrec 95.312% (94.194%)\n","Validation starts\n","Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.3529 (0.3529)\tPrec 90.625% (90.625%)\n"," * Prec 87.550% \n","best acc: 88.020000\n","Epoch: [50][0/391]\tTime 0.155 (0.155)\tData 0.124 (0.124)\tLoss 0.1376 (0.1376)\tPrec 94.531% (94.531%)\n","Epoch: [50][100/391]\tTime 0.026 (0.025)\tData 0.006 (0.005)\tLoss 0.1348 (0.1626)\tPrec 94.531% (94.493%)\n","Epoch: [50][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.1744 (0.1650)\tPrec 92.969% (94.450%)\n","Epoch: [50][300/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.1889 (0.1690)\tPrec 94.531% (94.324%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.4079 (0.4079)\tPrec 85.938% (85.938%)\n"," * Prec 87.430% \n","best acc: 88.020000\n","Epoch: [51][0/391]\tTime 0.154 (0.154)\tData 0.125 (0.125)\tLoss 0.1039 (0.1039)\tPrec 96.094% (96.094%)\n","Epoch: [51][100/391]\tTime 0.026 (0.026)\tData 0.006 (0.006)\tLoss 0.2347 (0.1550)\tPrec 89.844% (94.686%)\n","Epoch: [51][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.3719 (0.1636)\tPrec 88.281% (94.403%)\n","Epoch: [51][300/391]\tTime 0.019 (0.025)\tData 0.000 (0.005)\tLoss 0.2663 (0.1708)\tPrec 90.625% (94.108%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.3192 (0.3192)\tPrec 91.406% (91.406%)\n"," * Prec 87.580% \n","best acc: 88.020000\n","Epoch: [52][0/391]\tTime 0.142 (0.142)\tData 0.115 (0.115)\tLoss 0.2066 (0.2066)\tPrec 92.969% (92.969%)\n","Epoch: [52][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 0.1490 (0.1483)\tPrec 95.312% (94.848%)\n","Epoch: [52][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.006)\tLoss 0.1898 (0.1556)\tPrec 95.312% (94.574%)\n","Epoch: [52][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.1860 (0.1615)\tPrec 94.531% (94.391%)\n","Validation starts\n","Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.2872 (0.2872)\tPrec 93.750% (93.750%)\n"," * Prec 88.340% \n","best acc: 88.340000\n","Epoch: [53][0/391]\tTime 0.153 (0.153)\tData 0.117 (0.117)\tLoss 0.0622 (0.0622)\tPrec 98.438% (98.438%)\n","Epoch: [53][100/391]\tTime 0.021 (0.026)\tData 0.001 (0.005)\tLoss 0.1244 (0.1451)\tPrec 96.875% (94.995%)\n","Epoch: [53][200/391]\tTime 0.026 (0.025)\tData 0.007 (0.005)\tLoss 0.1271 (0.1520)\tPrec 95.312% (94.792%)\n","Epoch: [53][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.1925 (0.1530)\tPrec 93.750% (94.791%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.3184 (0.3184)\tPrec 89.062% (89.062%)\n"," * Prec 87.880% \n","best acc: 88.340000\n","Epoch: [54][0/391]\tTime 0.146 (0.146)\tData 0.118 (0.118)\tLoss 0.1134 (0.1134)\tPrec 96.875% (96.875%)\n","Epoch: [54][100/391]\tTime 0.026 (0.027)\tData 0.007 (0.005)\tLoss 0.3014 (0.1476)\tPrec 90.625% (95.073%)\n","Epoch: [54][200/391]\tTime 0.029 (0.026)\tData 0.010 (0.005)\tLoss 0.1811 (0.1470)\tPrec 93.750% (94.943%)\n","Epoch: [54][300/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.0986 (0.1540)\tPrec 96.875% (94.757%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.2604 (0.2604)\tPrec 92.969% (92.969%)\n"," * Prec 87.420% \n","best acc: 88.340000\n","Epoch: [55][0/391]\tTime 0.158 (0.158)\tData 0.122 (0.122)\tLoss 0.0996 (0.0996)\tPrec 96.094% (96.094%)\n","Epoch: [55][100/391]\tTime 0.021 (0.026)\tData 0.002 (0.005)\tLoss 0.1355 (0.1560)\tPrec 95.312% (94.663%)\n","Epoch: [55][200/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.1568 (0.1620)\tPrec 92.188% (94.395%)\n","Epoch: [55][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.2369 (0.1582)\tPrec 90.625% (94.573%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.3461 (0.3461)\tPrec 89.062% (89.062%)\n"," * Prec 88.030% \n","best acc: 88.340000\n","Epoch: [56][0/391]\tTime 0.147 (0.147)\tData 0.120 (0.120)\tLoss 0.1591 (0.1591)\tPrec 92.969% (92.969%)\n","Epoch: [56][100/391]\tTime 0.029 (0.026)\tData 0.009 (0.006)\tLoss 0.1636 (0.1330)\tPrec 92.188% (95.459%)\n","Epoch: [56][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.1277 (0.1387)\tPrec 95.312% (95.250%)\n","Epoch: [56][300/391]\tTime 0.030 (0.025)\tData 0.011 (0.006)\tLoss 0.1897 (0.1431)\tPrec 92.969% (95.061%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.4002 (0.4002)\tPrec 87.500% (87.500%)\n"," * Prec 88.070% \n","best acc: 88.340000\n","Epoch: [57][0/391]\tTime 0.144 (0.144)\tData 0.116 (0.116)\tLoss 0.1500 (0.1500)\tPrec 95.312% (95.312%)\n","Epoch: [57][100/391]\tTime 0.027 (0.025)\tData 0.004 (0.005)\tLoss 0.0976 (0.1281)\tPrec 96.875% (95.653%)\n","Epoch: [57][200/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.1944 (0.1397)\tPrec 94.531% (95.285%)\n","Epoch: [57][300/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.2098 (0.1427)\tPrec 92.969% (95.123%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.4708 (0.4708)\tPrec 86.719% (86.719%)\n"," * Prec 87.510% \n","best acc: 88.340000\n","Epoch: [58][0/391]\tTime 0.144 (0.144)\tData 0.116 (0.116)\tLoss 0.1036 (0.1036)\tPrec 97.656% (97.656%)\n","Epoch: [58][100/391]\tTime 0.030 (0.025)\tData 0.010 (0.005)\tLoss 0.1749 (0.1390)\tPrec 92.969% (95.220%)\n","Epoch: [58][200/391]\tTime 0.026 (0.025)\tData 0.006 (0.005)\tLoss 0.0945 (0.1392)\tPrec 96.094% (95.149%)\n","Epoch: [58][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.1250 (0.1420)\tPrec 95.312% (95.092%)\n","Validation starts\n","Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.3009 (0.3009)\tPrec 93.750% (93.750%)\n"," * Prec 87.680% \n","best acc: 88.340000\n","Epoch: [59][0/391]\tTime 0.154 (0.154)\tData 0.116 (0.116)\tLoss 0.1044 (0.1044)\tPrec 97.656% (97.656%)\n","Epoch: [59][100/391]\tTime 0.021 (0.025)\tData 0.000 (0.005)\tLoss 0.1778 (0.1287)\tPrec 94.531% (95.521%)\n","Epoch: [59][200/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.1191 (0.1350)\tPrec 94.531% (95.305%)\n","Epoch: [59][300/391]\tTime 0.028 (0.025)\tData 0.009 (0.005)\tLoss 0.1721 (0.1418)\tPrec 96.094% (95.043%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.3302 (0.3302)\tPrec 89.062% (89.062%)\n"," * Prec 88.230% \n","best acc: 88.340000\n","Epoch: [60][0/391]\tTime 0.147 (0.147)\tData 0.120 (0.120)\tLoss 0.1325 (0.1325)\tPrec 95.312% (95.312%)\n","Epoch: [60][100/391]\tTime 0.024 (0.027)\tData 0.000 (0.005)\tLoss 0.1219 (0.1011)\tPrec 96.094% (96.620%)\n","Epoch: [60][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.004)\tLoss 0.0639 (0.0916)\tPrec 98.438% (96.894%)\n","Epoch: [60][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.004)\tLoss 0.1051 (0.0872)\tPrec 96.094% (97.033%)\n","Validation starts\n","Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2579 (0.2579)\tPrec 92.188% (92.188%)\n"," * Prec 90.830% \n","best acc: 90.830000\n","Epoch: [61][0/391]\tTime 0.144 (0.144)\tData 0.116 (0.116)\tLoss 0.0813 (0.0813)\tPrec 96.094% (96.094%)\n","Epoch: [61][100/391]\tTime 0.030 (0.025)\tData 0.011 (0.006)\tLoss 0.0546 (0.0597)\tPrec 97.656% (98.004%)\n","Epoch: [61][200/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.0788 (0.0583)\tPrec 96.094% (98.041%)\n","Epoch: [61][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0180 (0.0566)\tPrec 100.000% (98.147%)\n","Validation starts\n","Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.2659 (0.2659)\tPrec 92.188% (92.188%)\n"," * Prec 90.730% \n","best acc: 90.830000\n","Epoch: [62][0/391]\tTime 0.148 (0.148)\tData 0.120 (0.120)\tLoss 0.0256 (0.0256)\tPrec 100.000% (100.000%)\n","Epoch: [62][100/391]\tTime 0.019 (0.026)\tData 0.000 (0.006)\tLoss 0.0316 (0.0478)\tPrec 98.438% (98.499%)\n","Epoch: [62][200/391]\tTime 0.019 (0.026)\tData 0.000 (0.006)\tLoss 0.0719 (0.0483)\tPrec 96.875% (98.465%)\n","Epoch: [62][300/391]\tTime 0.019 (0.025)\tData 0.000 (0.005)\tLoss 0.0493 (0.0500)\tPrec 98.438% (98.380%)\n","Validation starts\n","Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.3020 (0.3020)\tPrec 92.188% (92.188%)\n"," * Prec 90.860% \n","best acc: 90.860000\n","Epoch: [63][0/391]\tTime 0.153 (0.153)\tData 0.118 (0.118)\tLoss 0.0383 (0.0383)\tPrec 99.219% (99.219%)\n","Epoch: [63][100/391]\tTime 0.027 (0.026)\tData 0.004 (0.006)\tLoss 0.0492 (0.0424)\tPrec 98.438% (98.577%)\n","Epoch: [63][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.0220 (0.0449)\tPrec 99.219% (98.507%)\n","Epoch: [63][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0411 (0.0445)\tPrec 98.438% (98.526%)\n","Validation starts\n","Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2833 (0.2833)\tPrec 92.969% (92.969%)\n"," * Prec 90.970% \n","best acc: 90.970000\n","Epoch: [64][0/391]\tTime 0.146 (0.146)\tData 0.118 (0.118)\tLoss 0.0616 (0.0616)\tPrec 95.312% (95.312%)\n","Epoch: [64][100/391]\tTime 0.031 (0.026)\tData 0.012 (0.007)\tLoss 0.0384 (0.0410)\tPrec 98.438% (98.523%)\n","Epoch: [64][200/391]\tTime 0.027 (0.026)\tData 0.006 (0.006)\tLoss 0.0933 (0.0394)\tPrec 96.875% (98.616%)\n","Epoch: [64][300/391]\tTime 0.030 (0.025)\tData 0.011 (0.006)\tLoss 0.0137 (0.0399)\tPrec 100.000% (98.617%)\n","Validation starts\n","Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.2343 (0.2343)\tPrec 93.750% (93.750%)\n"," * Prec 90.910% \n","best acc: 90.970000\n","Epoch: [65][0/391]\tTime 0.155 (0.155)\tData 0.120 (0.120)\tLoss 0.0100 (0.0100)\tPrec 100.000% (100.000%)\n","Epoch: [65][100/391]\tTime 0.029 (0.026)\tData 0.010 (0.005)\tLoss 0.0094 (0.0364)\tPrec 100.000% (98.809%)\n","Epoch: [65][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.0703 (0.0376)\tPrec 99.219% (98.725%)\n","Epoch: [65][300/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.0504 (0.0376)\tPrec 98.438% (98.752%)\n","Validation starts\n","Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.2581 (0.2581)\tPrec 92.969% (92.969%)\n"," * Prec 91.130% \n","best acc: 91.130000\n","Epoch: [66][0/391]\tTime 0.146 (0.146)\tData 0.118 (0.118)\tLoss 0.0479 (0.0479)\tPrec 98.438% (98.438%)\n","Epoch: [66][100/391]\tTime 0.020 (0.025)\tData 0.000 (0.006)\tLoss 0.0864 (0.0358)\tPrec 96.094% (98.817%)\n","Epoch: [66][200/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.0063 (0.0358)\tPrec 100.000% (98.760%)\n","Epoch: [66][300/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.0181 (0.0355)\tPrec 99.219% (98.785%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.2953 (0.2953)\tPrec 93.750% (93.750%)\n"," * Prec 91.110% \n","best acc: 91.130000\n","Epoch: [67][0/391]\tTime 0.146 (0.146)\tData 0.119 (0.119)\tLoss 0.0068 (0.0068)\tPrec 100.000% (100.000%)\n","Epoch: [67][100/391]\tTime 0.026 (0.025)\tData 0.006 (0.005)\tLoss 0.0356 (0.0326)\tPrec 99.219% (98.948%)\n","Epoch: [67][200/391]\tTime 0.031 (0.025)\tData 0.010 (0.005)\tLoss 0.0194 (0.0336)\tPrec 99.219% (98.865%)\n","Epoch: [67][300/391]\tTime 0.029 (0.025)\tData 0.010 (0.005)\tLoss 0.0129 (0.0340)\tPrec 100.000% (98.824%)\n","Validation starts\n","Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.2573 (0.2573)\tPrec 90.625% (90.625%)\n"," * Prec 90.960% \n","best acc: 91.130000\n","Epoch: [68][0/391]\tTime 0.156 (0.156)\tData 0.121 (0.121)\tLoss 0.0384 (0.0384)\tPrec 99.219% (99.219%)\n","Epoch: [68][100/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.0934 (0.0309)\tPrec 97.656% (99.002%)\n","Epoch: [68][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0784 (0.0300)\tPrec 96.875% (98.966%)\n","Epoch: [68][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0323 (0.0313)\tPrec 99.219% (98.902%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2978 (0.2978)\tPrec 91.406% (91.406%)\n"," * Prec 91.120% \n","best acc: 91.130000\n","Epoch: [69][0/391]\tTime 0.145 (0.145)\tData 0.118 (0.118)\tLoss 0.0488 (0.0488)\tPrec 98.438% (98.438%)\n","Epoch: [69][100/391]\tTime 0.022 (0.025)\tData 0.003 (0.005)\tLoss 0.0173 (0.0313)\tPrec 99.219% (98.871%)\n","Epoch: [69][200/391]\tTime 0.025 (0.025)\tData 0.005 (0.005)\tLoss 0.0265 (0.0314)\tPrec 99.219% (98.916%)\n","Epoch: [69][300/391]\tTime 0.019 (0.025)\tData 0.000 (0.005)\tLoss 0.0029 (0.0298)\tPrec 100.000% (99.006%)\n","Validation starts\n","Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.2411 (0.2411)\tPrec 92.188% (92.188%)\n"," * Prec 91.090% \n","best acc: 91.130000\n","Epoch: [70][0/391]\tTime 0.143 (0.143)\tData 0.116 (0.116)\tLoss 0.0140 (0.0140)\tPrec 98.438% (98.438%)\n","Epoch: [70][100/391]\tTime 0.023 (0.025)\tData 0.003 (0.006)\tLoss 0.0098 (0.0249)\tPrec 100.000% (99.196%)\n","Epoch: [70][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.006)\tLoss 0.0270 (0.0271)\tPrec 98.438% (99.063%)\n","Epoch: [70][300/391]\tTime 0.029 (0.025)\tData 0.003 (0.005)\tLoss 0.0360 (0.0278)\tPrec 98.438% (99.019%)\n","Validation starts\n","Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.2044 (0.2044)\tPrec 93.750% (93.750%)\n"," * Prec 91.150% \n","best acc: 91.150000\n","Epoch: [71][0/391]\tTime 0.149 (0.149)\tData 0.114 (0.114)\tLoss 0.0198 (0.0198)\tPrec 99.219% (99.219%)\n","Epoch: [71][100/391]\tTime 0.027 (0.028)\tData 0.007 (0.005)\tLoss 0.0313 (0.0325)\tPrec 98.438% (98.925%)\n","Epoch: [71][200/391]\tTime 0.029 (0.026)\tData 0.010 (0.005)\tLoss 0.0170 (0.0284)\tPrec 99.219% (99.087%)\n","Epoch: [71][300/391]\tTime 0.032 (0.026)\tData 0.012 (0.005)\tLoss 0.0486 (0.0271)\tPrec 98.438% (99.099%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.2662 (0.2662)\tPrec 91.406% (91.406%)\n"," * Prec 91.170% \n","best acc: 91.170000\n","Epoch: [72][0/391]\tTime 0.147 (0.147)\tData 0.120 (0.120)\tLoss 0.0130 (0.0130)\tPrec 99.219% (99.219%)\n","Epoch: [72][100/391]\tTime 0.030 (0.026)\tData 0.011 (0.007)\tLoss 0.0250 (0.0287)\tPrec 98.438% (98.948%)\n","Epoch: [72][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.006)\tLoss 0.0209 (0.0273)\tPrec 99.219% (99.036%)\n","Epoch: [72][300/391]\tTime 0.020 (0.026)\tData 0.001 (0.006)\tLoss 0.0049 (0.0276)\tPrec 100.000% (99.055%)\n","Validation starts\n","Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.3403 (0.3403)\tPrec 91.406% (91.406%)\n"," * Prec 91.160% \n","best acc: 91.170000\n","Epoch: [73][0/391]\tTime 0.150 (0.150)\tData 0.123 (0.123)\tLoss 0.0179 (0.0179)\tPrec 99.219% (99.219%)\n","Epoch: [73][100/391]\tTime 0.029 (0.025)\tData 0.009 (0.006)\tLoss 0.0113 (0.0218)\tPrec 100.000% (99.250%)\n","Epoch: [73][200/391]\tTime 0.030 (0.025)\tData 0.009 (0.005)\tLoss 0.0122 (0.0228)\tPrec 99.219% (99.207%)\n","Epoch: [73][300/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.0658 (0.0239)\tPrec 98.438% (99.188%)\n","Validation starts\n","Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.2953 (0.2953)\tPrec 89.062% (89.062%)\n"," * Prec 90.920% \n","best acc: 91.170000\n","Epoch: [74][0/391]\tTime 0.151 (0.151)\tData 0.123 (0.123)\tLoss 0.0203 (0.0203)\tPrec 99.219% (99.219%)\n","Epoch: [74][100/391]\tTime 0.029 (0.026)\tData 0.010 (0.006)\tLoss 0.0159 (0.0252)\tPrec 99.219% (99.103%)\n","Epoch: [74][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.006)\tLoss 0.0221 (0.0244)\tPrec 99.219% (99.137%)\n","Epoch: [74][300/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.0050 (0.0237)\tPrec 100.000% (99.154%)\n","Validation starts\n","Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2147 (0.2147)\tPrec 92.188% (92.188%)\n"," * Prec 91.170% \n","best acc: 91.170000\n","Epoch: [75][0/391]\tTime 0.146 (0.146)\tData 0.118 (0.118)\tLoss 0.0206 (0.0206)\tPrec 99.219% (99.219%)\n","Epoch: [75][100/391]\tTime 0.030 (0.026)\tData 0.011 (0.006)\tLoss 0.0152 (0.0241)\tPrec 100.000% (99.157%)\n","Epoch: [75][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.006)\tLoss 0.0047 (0.0253)\tPrec 100.000% (99.122%)\n","Epoch: [75][300/391]\tTime 0.033 (0.025)\tData 0.010 (0.006)\tLoss 0.0126 (0.0246)\tPrec 99.219% (99.154%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2195 (0.2195)\tPrec 94.531% (94.531%)\n"," * Prec 91.010% \n","best acc: 91.170000\n","Epoch: [76][0/391]\tTime 0.145 (0.145)\tData 0.117 (0.117)\tLoss 0.0020 (0.0020)\tPrec 100.000% (100.000%)\n","Epoch: [76][100/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.0086 (0.0243)\tPrec 99.219% (99.234%)\n","Epoch: [76][200/391]\tTime 0.031 (0.025)\tData 0.009 (0.005)\tLoss 0.0417 (0.0226)\tPrec 98.438% (99.265%)\n","Epoch: [76][300/391]\tTime 0.027 (0.025)\tData 0.008 (0.005)\tLoss 0.0040 (0.0223)\tPrec 100.000% (99.273%)\n","Validation starts\n","Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2264 (0.2264)\tPrec 94.531% (94.531%)\n"," * Prec 90.980% \n","best acc: 91.170000\n","Epoch: [77][0/391]\tTime 0.145 (0.145)\tData 0.118 (0.118)\tLoss 0.0190 (0.0190)\tPrec 99.219% (99.219%)\n","Epoch: [77][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.006)\tLoss 0.0415 (0.0216)\tPrec 98.438% (99.172%)\n","Epoch: [77][200/391]\tTime 0.031 (0.025)\tData 0.011 (0.005)\tLoss 0.0167 (0.0221)\tPrec 99.219% (99.195%)\n","Epoch: [77][300/391]\tTime 0.030 (0.025)\tData 0.009 (0.005)\tLoss 0.0059 (0.0227)\tPrec 100.000% (99.206%)\n","Validation starts\n","Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.2414 (0.2414)\tPrec 92.969% (92.969%)\n"," * Prec 91.310% \n","best acc: 91.310000\n","Epoch: [78][0/391]\tTime 0.143 (0.143)\tData 0.115 (0.115)\tLoss 0.0144 (0.0144)\tPrec 99.219% (99.219%)\n","Epoch: [78][100/391]\tTime 0.028 (0.025)\tData 0.009 (0.006)\tLoss 0.0099 (0.0215)\tPrec 99.219% (99.211%)\n","Epoch: [78][200/391]\tTime 0.029 (0.025)\tData 0.009 (0.005)\tLoss 0.0064 (0.0204)\tPrec 100.000% (99.269%)\n","Epoch: [78][300/391]\tTime 0.028 (0.025)\tData 0.002 (0.005)\tLoss 0.0238 (0.0202)\tPrec 99.219% (99.289%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.2557 (0.2557)\tPrec 93.750% (93.750%)\n"," * Prec 91.020% \n","best acc: 91.310000\n","Epoch: [79][0/391]\tTime 0.145 (0.145)\tData 0.118 (0.118)\tLoss 0.0265 (0.0265)\tPrec 99.219% (99.219%)\n","Epoch: [79][100/391]\tTime 0.029 (0.026)\tData 0.009 (0.006)\tLoss 0.0133 (0.0178)\tPrec 100.000% (99.420%)\n","Epoch: [79][200/391]\tTime 0.029 (0.025)\tData 0.010 (0.005)\tLoss 0.0212 (0.0198)\tPrec 99.219% (99.335%)\n","Epoch: [79][300/391]\tTime 0.030 (0.025)\tData 0.010 (0.005)\tLoss 0.0186 (0.0194)\tPrec 98.438% (99.351%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.2760 (0.2760)\tPrec 92.969% (92.969%)\n"," * Prec 91.110% \n","best acc: 91.310000\n","Epoch: [80][0/391]\tTime 0.158 (0.158)\tData 0.123 (0.123)\tLoss 0.0066 (0.0066)\tPrec 100.000% (100.000%)\n","Epoch: [80][100/391]\tTime 0.031 (0.026)\tData 0.011 (0.006)\tLoss 0.0178 (0.0201)\tPrec 100.000% (99.366%)\n","Epoch: [80][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.006)\tLoss 0.0040 (0.0194)\tPrec 100.000% (99.398%)\n","Epoch: [80][300/391]\tTime 0.031 (0.025)\tData 0.011 (0.005)\tLoss 0.0463 (0.0192)\tPrec 97.656% (99.359%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2124 (0.2124)\tPrec 96.094% (96.094%)\n"," * Prec 91.230% \n","best acc: 91.310000\n","Epoch: [81][0/391]\tTime 0.142 (0.142)\tData 0.114 (0.114)\tLoss 0.0058 (0.0058)\tPrec 100.000% (100.000%)\n","Epoch: [81][100/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0782 (0.0188)\tPrec 97.656% (99.428%)\n","Epoch: [81][200/391]\tTime 0.024 (0.025)\tData 0.005 (0.005)\tLoss 0.0234 (0.0196)\tPrec 99.219% (99.370%)\n","Epoch: [81][300/391]\tTime 0.020 (0.024)\tData 0.000 (0.005)\tLoss 0.0075 (0.0187)\tPrec 100.000% (99.372%)\n","Validation starts\n","Test: [0/79]\tTime 0.104 (0.104)\tLoss 0.3025 (0.3025)\tPrec 93.750% (93.750%)\n"," * Prec 91.220% \n","best acc: 91.310000\n","Epoch: [82][0/391]\tTime 0.153 (0.153)\tData 0.125 (0.125)\tLoss 0.0119 (0.0119)\tPrec 99.219% (99.219%)\n","Epoch: [82][100/391]\tTime 0.022 (0.025)\tData 0.002 (0.005)\tLoss 0.0074 (0.0172)\tPrec 100.000% (99.435%)\n","Epoch: [82][200/391]\tTime 0.020 (0.024)\tData 0.000 (0.005)\tLoss 0.0104 (0.0186)\tPrec 99.219% (99.394%)\n","Epoch: [82][300/391]\tTime 0.022 (0.024)\tData 0.002 (0.004)\tLoss 0.0160 (0.0182)\tPrec 99.219% (99.393%)\n","Validation starts\n","Test: [0/79]\tTime 0.104 (0.104)\tLoss 0.2939 (0.2939)\tPrec 92.969% (92.969%)\n"," * Prec 91.350% \n","best acc: 91.350000\n","Epoch: [83][0/391]\tTime 0.152 (0.152)\tData 0.116 (0.116)\tLoss 0.0181 (0.0181)\tPrec 99.219% (99.219%)\n","Epoch: [83][100/391]\tTime 0.028 (0.026)\tData 0.008 (0.006)\tLoss 0.0040 (0.0205)\tPrec 100.000% (99.319%)\n","Epoch: [83][200/391]\tTime 0.029 (0.025)\tData 0.010 (0.006)\tLoss 0.0048 (0.0184)\tPrec 100.000% (99.374%)\n","Epoch: [83][300/391]\tTime 0.031 (0.025)\tData 0.012 (0.006)\tLoss 0.0055 (0.0186)\tPrec 100.000% (99.359%)\n","Validation starts\n","Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2994 (0.2994)\tPrec 92.188% (92.188%)\n"," * Prec 91.200% \n","best acc: 91.350000\n","Epoch: [84][0/391]\tTime 0.145 (0.145)\tData 0.118 (0.118)\tLoss 0.0076 (0.0076)\tPrec 100.000% (100.000%)\n","Epoch: [84][100/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.0064 (0.0136)\tPrec 100.000% (99.582%)\n","Epoch: [84][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0336 (0.0138)\tPrec 99.219% (99.572%)\n","Epoch: [84][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0015 (0.0144)\tPrec 100.000% (99.567%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2385 (0.2385)\tPrec 93.750% (93.750%)\n"," * Prec 91.180% \n","best acc: 91.350000\n","Epoch: [85][0/391]\tTime 0.146 (0.146)\tData 0.119 (0.119)\tLoss 0.0158 (0.0158)\tPrec 99.219% (99.219%)\n","Epoch: [85][100/391]\tTime 0.029 (0.026)\tData 0.010 (0.007)\tLoss 0.1031 (0.0175)\tPrec 97.656% (99.412%)\n","Epoch: [85][200/391]\tTime 0.029 (0.025)\tData 0.010 (0.006)\tLoss 0.0185 (0.0174)\tPrec 99.219% (99.386%)\n","Epoch: [85][300/391]\tTime 0.030 (0.025)\tData 0.010 (0.006)\tLoss 0.0247 (0.0168)\tPrec 99.219% (99.406%)\n","Validation starts\n","Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.2431 (0.2431)\tPrec 92.969% (92.969%)\n"," * Prec 91.220% \n","best acc: 91.350000\n","Epoch: [86][0/391]\tTime 0.144 (0.144)\tData 0.117 (0.117)\tLoss 0.0094 (0.0094)\tPrec 99.219% (99.219%)\n","Epoch: [86][100/391]\tTime 0.028 (0.025)\tData 0.008 (0.006)\tLoss 0.0042 (0.0159)\tPrec 100.000% (99.443%)\n","Epoch: [86][200/391]\tTime 0.026 (0.025)\tData 0.007 (0.005)\tLoss 0.0386 (0.0156)\tPrec 99.219% (99.483%)\n","Epoch: [86][300/391]\tTime 0.030 (0.025)\tData 0.011 (0.005)\tLoss 0.0088 (0.0155)\tPrec 100.000% (99.489%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.2191 (0.2191)\tPrec 94.531% (94.531%)\n"," * Prec 91.250% \n","best acc: 91.350000\n","Epoch: [87][0/391]\tTime 0.144 (0.144)\tData 0.117 (0.117)\tLoss 0.0275 (0.0275)\tPrec 98.438% (98.438%)\n","Epoch: [87][100/391]\tTime 0.025 (0.025)\tData 0.006 (0.005)\tLoss 0.0053 (0.0154)\tPrec 100.000% (99.489%)\n","Epoch: [87][200/391]\tTime 0.030 (0.025)\tData 0.010 (0.005)\tLoss 0.0379 (0.0154)\tPrec 99.219% (99.468%)\n","Epoch: [87][300/391]\tTime 0.030 (0.025)\tData 0.010 (0.005)\tLoss 0.0257 (0.0158)\tPrec 99.219% (99.439%)\n","Validation starts\n","Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.2392 (0.2392)\tPrec 94.531% (94.531%)\n"," * Prec 91.350% \n","best acc: 91.350000\n","Epoch: [88][0/391]\tTime 0.151 (0.151)\tData 0.116 (0.116)\tLoss 0.0074 (0.0074)\tPrec 100.000% (100.000%)\n","Epoch: [88][100/391]\tTime 0.029 (0.025)\tData 0.010 (0.005)\tLoss 0.0040 (0.0138)\tPrec 100.000% (99.520%)\n","Epoch: [88][200/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.0346 (0.0153)\tPrec 99.219% (99.491%)\n","Epoch: [88][300/391]\tTime 0.028 (0.024)\tData 0.008 (0.005)\tLoss 0.0088 (0.0148)\tPrec 100.000% (99.515%)\n","Validation starts\n","Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.2821 (0.2821)\tPrec 94.531% (94.531%)\n"," * Prec 91.220% \n","best acc: 91.350000\n","Epoch: [89][0/391]\tTime 0.150 (0.150)\tData 0.120 (0.120)\tLoss 0.0177 (0.0177)\tPrec 99.219% (99.219%)\n","Epoch: [89][100/391]\tTime 0.030 (0.027)\tData 0.010 (0.006)\tLoss 0.0081 (0.0135)\tPrec 100.000% (99.497%)\n","Epoch: [89][200/391]\tTime 0.029 (0.026)\tData 0.009 (0.006)\tLoss 0.0051 (0.0148)\tPrec 100.000% (99.452%)\n","Epoch: [89][300/391]\tTime 0.029 (0.025)\tData 0.010 (0.006)\tLoss 0.0129 (0.0150)\tPrec 99.219% (99.463%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.2607 (0.2607)\tPrec 92.969% (92.969%)\n"," * Prec 91.240% \n","best acc: 91.350000\n","Epoch: [90][0/391]\tTime 0.147 (0.147)\tData 0.119 (0.119)\tLoss 0.0209 (0.0209)\tPrec 98.438% (98.438%)\n","Epoch: [90][100/391]\tTime 0.025 (0.026)\tData 0.005 (0.005)\tLoss 0.0070 (0.0162)\tPrec 100.000% (99.451%)\n","Epoch: [90][200/391]\tTime 0.030 (0.026)\tData 0.010 (0.005)\tLoss 0.0320 (0.0161)\tPrec 98.438% (99.440%)\n","Epoch: [90][300/391]\tTime 0.030 (0.025)\tData 0.011 (0.005)\tLoss 0.0058 (0.0152)\tPrec 100.000% (99.478%)\n","Validation starts\n","Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.2710 (0.2710)\tPrec 95.312% (95.312%)\n"," * Prec 91.320% \n","best acc: 91.350000\n","Epoch: [91][0/391]\tTime 0.157 (0.157)\tData 0.128 (0.128)\tLoss 0.0192 (0.0192)\tPrec 100.000% (100.000%)\n","Epoch: [91][100/391]\tTime 0.027 (0.026)\tData 0.007 (0.006)\tLoss 0.0022 (0.0127)\tPrec 100.000% (99.644%)\n","Epoch: [91][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0094 (0.0130)\tPrec 100.000% (99.623%)\n","Epoch: [91][300/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.0023 (0.0137)\tPrec 100.000% (99.585%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.3044 (0.3044)\tPrec 93.750% (93.750%)\n"," * Prec 91.170% \n","best acc: 91.350000\n","Epoch: [92][0/391]\tTime 0.157 (0.157)\tData 0.122 (0.122)\tLoss 0.0026 (0.0026)\tPrec 100.000% (100.000%)\n","Epoch: [92][100/391]\tTime 0.021 (0.027)\tData 0.002 (0.005)\tLoss 0.0014 (0.0149)\tPrec 100.000% (99.505%)\n","Epoch: [92][200/391]\tTime 0.021 (0.026)\tData 0.002 (0.005)\tLoss 0.0339 (0.0146)\tPrec 98.438% (99.491%)\n","Epoch: [92][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0395 (0.0152)\tPrec 98.438% (99.478%)\n","Validation starts\n","Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2314 (0.2314)\tPrec 93.750% (93.750%)\n"," * Prec 91.290% \n","best acc: 91.350000\n","Epoch: [93][0/391]\tTime 0.151 (0.151)\tData 0.116 (0.116)\tLoss 0.0309 (0.0309)\tPrec 99.219% (99.219%)\n","Epoch: [93][100/391]\tTime 0.020 (0.027)\tData 0.000 (0.005)\tLoss 0.0321 (0.0127)\tPrec 98.438% (99.582%)\n","Epoch: [93][200/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0013 (0.0139)\tPrec 100.000% (99.541%)\n","Epoch: [93][300/391]\tTime 0.023 (0.026)\tData 0.000 (0.005)\tLoss 0.0038 (0.0143)\tPrec 100.000% (99.520%)\n","Validation starts\n","Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.2518 (0.2518)\tPrec 95.312% (95.312%)\n"," * Prec 91.140% \n","best acc: 91.350000\n","Epoch: [94][0/391]\tTime 0.153 (0.153)\tData 0.118 (0.118)\tLoss 0.0089 (0.0089)\tPrec 100.000% (100.000%)\n","Epoch: [94][100/391]\tTime 0.022 (0.026)\tData 0.002 (0.005)\tLoss 0.0014 (0.0158)\tPrec 100.000% (99.482%)\n","Epoch: [94][200/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.0192 (0.0139)\tPrec 99.219% (99.553%)\n","Epoch: [94][300/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.0117 (0.0143)\tPrec 99.219% (99.528%)\n","Validation starts\n","Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.1968 (0.1968)\tPrec 96.094% (96.094%)\n"," * Prec 91.260% \n","best acc: 91.350000\n","Epoch: [95][0/391]\tTime 0.145 (0.145)\tData 0.117 (0.117)\tLoss 0.0137 (0.0137)\tPrec 99.219% (99.219%)\n","Epoch: [95][100/391]\tTime 0.027 (0.027)\tData 0.008 (0.005)\tLoss 0.0072 (0.0161)\tPrec 100.000% (99.474%)\n","Epoch: [95][200/391]\tTime 0.028 (0.025)\tData 0.008 (0.005)\tLoss 0.0143 (0.0148)\tPrec 100.000% (99.495%)\n","Epoch: [95][300/391]\tTime 0.027 (0.025)\tData 0.008 (0.005)\tLoss 0.0108 (0.0146)\tPrec 99.219% (99.502%)\n","Validation starts\n","Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.2699 (0.2699)\tPrec 93.750% (93.750%)\n"," * Prec 91.230% \n","best acc: 91.350000\n","Epoch: [96][0/391]\tTime 0.146 (0.146)\tData 0.118 (0.118)\tLoss 0.0180 (0.0180)\tPrec 99.219% (99.219%)\n","Epoch: [96][100/391]\tTime 0.024 (0.026)\tData 0.003 (0.005)\tLoss 0.0032 (0.0135)\tPrec 100.000% (99.606%)\n","Epoch: [96][200/391]\tTime 0.027 (0.025)\tData 0.007 (0.005)\tLoss 0.0217 (0.0136)\tPrec 99.219% (99.588%)\n","Epoch: [96][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0070 (0.0142)\tPrec 100.000% (99.530%)\n","Validation starts\n","Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.2311 (0.2311)\tPrec 94.531% (94.531%)\n"," * Prec 91.330% \n","best acc: 91.350000\n","Epoch: [97][0/391]\tTime 0.146 (0.146)\tData 0.118 (0.118)\tLoss 0.0035 (0.0035)\tPrec 100.000% (100.000%)\n","Epoch: [97][100/391]\tTime 0.021 (0.026)\tData 0.000 (0.005)\tLoss 0.0028 (0.0121)\tPrec 100.000% (99.621%)\n","Epoch: [97][200/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0051 (0.0131)\tPrec 100.000% (99.592%)\n","Epoch: [97][300/391]\tTime 0.020 (0.025)\tData 0.000 (0.005)\tLoss 0.0081 (0.0129)\tPrec 100.000% (99.595%)\n","Validation starts\n","Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.2315 (0.2315)\tPrec 94.531% (94.531%)\n"," * Prec 91.360% \n","best acc: 91.360000\n","Epoch: [98][0/391]\tTime 0.151 (0.151)\tData 0.116 (0.116)\tLoss 0.0024 (0.0024)\tPrec 100.000% (100.000%)\n","Epoch: [98][100/391]\tTime 0.020 (0.027)\tData 0.000 (0.006)\tLoss 0.0062 (0.0145)\tPrec 100.000% (99.567%)\n","Epoch: [98][200/391]\tTime 0.021 (0.026)\tData 0.001 (0.005)\tLoss 0.0090 (0.0148)\tPrec 99.219% (99.534%)\n","Epoch: [98][300/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0102 (0.0148)\tPrec 99.219% (99.530%)\n","Validation starts\n","Test: [0/79]\tTime 0.103 (0.103)\tLoss 0.2552 (0.2552)\tPrec 94.531% (94.531%)\n"," * Prec 91.180% \n","best acc: 91.360000\n","Epoch: [99][0/391]\tTime 0.144 (0.144)\tData 0.117 (0.117)\tLoss 0.0021 (0.0021)\tPrec 100.000% (100.000%)\n","Epoch: [99][100/391]\tTime 0.020 (0.026)\tData 0.000 (0.005)\tLoss 0.0176 (0.0135)\tPrec 99.219% (99.582%)\n","Epoch: [99][200/391]\tTime 0.021 (0.025)\tData 0.002 (0.005)\tLoss 0.0141 (0.0134)\tPrec 99.219% (99.553%)\n","Epoch: [99][300/391]\tTime 0.029 (0.026)\tData 0.008 (0.005)\tLoss 0.0135 (0.0136)\tPrec 100.000% (99.533%)\n","Validation starts\n","Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2224 (0.2224)\tPrec 93.750% (93.750%)\n"," * Prec 91.200% \n","best acc: 91.360000\n"]}],"source":["# This cell won't be given, but students will complete the training\n","\n","lr = 4e-2\n","weight_decay = 1e-4\n","epochs = 100\n","best_prec = 0\n","\n","#model = nn.DataParallel(model).cuda()\n","model.cuda()\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n","#cudnn.benchmark = True\n","\n","if not os.path.exists('result'):\n","    os.makedirs('result')\n","fdir = 'result/'+str(model_name)\n","if not os.path.exists(fdir):\n","    os.makedirs(fdir)\n","\n","\n","for epoch in range(0, epochs):\n","    adjust_learning_rate(optimizer, epoch)\n","\n","    train(trainloader, model, criterion, optimizer, epoch)\n","\n","    # evaluate on test set\n","    print(\"Validation starts\")\n","    prec = validate(testloader, model, criterion)\n","\n","    # remember best precision and save checkpoint\n","    is_best = prec > best_prec\n","    best_prec = max(prec,best_prec)\n","    print('best acc: {:1f}'.format(best_prec))\n","    save_checkpoint({\n","        'epoch': epoch + 1,\n","        'state_dict': model.state_dict(),\n","        'best_prec': best_prec,\n","        'optimizer': optimizer.state_dict(),\n","    }, is_best, fdir)"]},{"cell_type":"code","execution_count":3,"id":"entertaining-queensland","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"entertaining-queensland","executionInfo":{"status":"ok","timestamp":1764040357208,"user_tz":480,"elapsed":7370,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"6fdf2180-ca74-42ee-eabe-6f6e95779b10"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Accuracy: 9140/10000 (91%)\n","\n"]}],"source":["PATH = \"/content/drive/MyDrive/ece284/result/model_best.pth.tar\"\n","model_name = \"VGG16_project\"\n","model = VGG16_project()\n","checkpoint = torch.load(PATH)\n","model.load_state_dict(checkpoint['state_dict'])\n","device = torch.device(\"cuda\")\n","\n","model.cuda()\n","model.eval()\n","\n","test_loss = 0\n","correct = 0\n","\n","with torch.no_grad():\n","    for data, target in testloader:\n","        data, target = data.to(device), target.to(device) # loading to GPU\n","        output = model(data)\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","test_loss /= len(testloader.dataset)\n","\n","print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        correct, len(testloader.dataset),\n","        100. * correct / len(testloader.dataset)))"]},{"cell_type":"code","execution_count":4,"id":"ceramic-nigeria","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ceramic-nigeria","executionInfo":{"status":"ok","timestamp":1764040369503,"user_tz":480,"elapsed":102,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"2b6800cc-f1ef-43c3-e200-299732c06aec","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["3 -th layer prehooked\n","QuantConv2d(\n","  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 1\n","7 -th layer prehooked\n","QuantConv2d(\n","  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 2\n","12 -th layer prehooked\n","QuantConv2d(\n","  64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 3\n","16 -th layer prehooked\n","QuantConv2d(\n","  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 4\n","21 -th layer prehooked\n","QuantConv2d(\n","  128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 5\n","25 -th layer prehooked\n","QuantConv2d(\n","  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 6\n","29 -th layer prehooked\n","QuantConv2d(\n","  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 7\n","34 -th layer prehooked\n","QuantConv2d(\n","  256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 8\n","38 -th layer prehooked\n","QuantConv2d(\n","  8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 9\n","41 -th layer prehooked\n","QuantConv2d(\n","  8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 10\n","46 -th layer prehooked\n","QuantConv2d(\n","  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 11\n","50 -th layer prehooked\n","QuantConv2d(\n","  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 12\n","54 -th layer prehooked\n","QuantConv2d(\n","  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","  (weight_quant): weight_quantize_fn()\n",") 13\n"]}],"source":["\n","class SaveOutput:\n","    def __init__(self):\n","        self.outputs = []\n","    def __call__(self, module, module_in):\n","        self.outputs.append(module_in)\n","    def clear(self):\n","        self.outputs = []\n","\n","######### Save inputs from selected layer ##########\n","save_output = SaveOutput()\n","i = 0\n","counter = 0\n","for layer in model.modules():\n","    i+=1\n","    if isinstance(layer, QuantConv2d):\n","        print(i,\"-th layer prehooked\")\n","        counter+=1\n","        print(layer, counter)\n","        layer.register_forward_pre_hook(save_output)\n","####################################################\n","\n","dataiter = iter(testloader)\n","images, labels = next(dataiter)\n","images = images.to(device)\n","out = model(images)\n"]},{"cell_type":"code","execution_count":5,"id":"spoken-worst","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"spoken-worst","executionInfo":{"status":"ok","timestamp":1764040373863,"user_tz":480,"elapsed":21,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"88f90002-7208-4fe0-c284-80a06a675566"},"outputs":[{"output_type":"stream","name":"stdout","text":["Weight Int Shape: torch.Size([8, 8, 3, 3])\n"]}],"source":["w_bit = 4\n","weight_q = model.features[27].weight_q # quantized value is stored during the training\n","w_alpha = model.features[27].weight_quant.wgt_alpha   # alpha is defined in your model already. bring it out here\n","w_delta = w_alpha/(2**(w_bit-1)-1)   # delta can be calculated by using alpha and w_bit\n","weight_int = weight_q/w_delta # w_int can be calculated by weight_q and w_delta\n","# print(weight_int) # you should see clean integer numbers\n","print(f\"Weight Int Shape: {weight_int.shape}\")"]},{"cell_type":"code","execution_count":10,"id":"interior-oxygen","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"interior-oxygen","executionInfo":{"status":"ok","timestamp":1764040470512,"user_tz":480,"elapsed":14,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"c0a8fd18-9b08-48ad-c452-685312b0cb89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input Shape: torch.Size([128, 8, 4, 4])\n","Input Int Sample: tensor([3.0000, 0.0000, 0.0000, 0.0000], device='cuda:0',\n","       grad_fn=<SelectBackward0>)\n"]}],"source":["x_bit = 4\n","x = save_output.outputs[8][0]  # input of the 2nd conv layer\n","print(f\"Input Shape: {x.shape}\")\n","x_alpha  = model.features[27].act_alpha\n","x_delta = x_alpha/(2**x_bit-1)\n","\n","act_quant_fn = act_quantization(x_bit) # define the quantization function\n","x_q = act_quant_fn(x, x_alpha)         # create the quantized value for x\n","\n","x_int = x_q/x_delta\n","print(f\"Input Int Sample: {x_int[0,0,0,:5]}\")"]},{"cell_type":"code","execution_count":11,"id":"designed-auction","metadata":{"id":"designed-auction","executionInfo":{"status":"ok","timestamp":1764040478224,"user_tz":480,"elapsed":41,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}}},"outputs":[],"source":["#### input floating number / weight quantized version\n","\n","conv_ref = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1, bias = False)\n","conv_ref.weight = torch.nn.parameter.Parameter(weight_int)\n","output_int = conv_ref(x_int)\n","\n","output_recovered = output_int*x_delta*w_delta\n","relu = nn.ReLU(inplace=True)\n","relu_output_recovered = relu(output_recovered)\n","\n","output_ref = save_output.outputs[9][0]"]},{"cell_type":"code","execution_count":12,"id":"157dffd8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"157dffd8","executionInfo":{"status":"ok","timestamp":1764040479789,"user_tz":480,"elapsed":15,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"2eecc1be-3f3a-40f5-ca5c-8846645ac3ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.8219e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"]}],"source":["difference = abs( output_ref - relu_output_recovered )\n","print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"]},{"cell_type":"code","execution_count":46,"id":"significant-whole","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"significant-whole","executionInfo":{"status":"ok","timestamp":1764043241170,"user_tz":480,"elapsed":21,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"66275cc5-3687-44fe-974e-f2a0585233c5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 36])"]},"metadata":{},"execution_count":46}],"source":["x_pad = torch.zeros(128, 8, 6, 6).to(x_int.device)\n","x_pad[:, :, 1:5, 1:5] = x_int\n","X = x_pad[0]\n","X = X.reshape(X.size(0), -1)\n","X.size()"]},{"cell_type":"code","execution_count":47,"id":"corresponding-significance","metadata":{"id":"corresponding-significance","executionInfo":{"status":"ok","timestamp":1764043242489,"user_tz":480,"elapsed":10,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}}},"outputs":[],"source":["tile_id = 0\n","nij = 200 # just a random number\n","#X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n","\n","bit_precision = 4\n","file = open('activation.txt', 'w') #write to file\n","file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n","file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n","file.write('#................#\\n')\n","\n","for i in range(X.size(1)):  # time step\n","    for j in range(X.size(0)): # row #\n","        X_bin = '{0:04b}'.format(int(X[7-j,i].item()+0.001))\n","        for k in range(bit_precision):\n","            file.write(X_bin[k])\n","        #file.write(' ')  # for visibility with blank between words, you can use\n","    file.write('\\n')\n","file.close() #close file"]},{"cell_type":"code","source":["print(weight_int.size())\n","W = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))\n","print(W.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-anPbG6Kl6z","executionInfo":{"status":"ok","timestamp":1764043245530,"user_tz":480,"elapsed":14,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"bb5094ac-5b0e-45be-d037-165686b5a9db"},"id":"P-anPbG6Kl6z","execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 8, 3, 3])\n","torch.Size([8, 8, 9])\n"]}]},{"cell_type":"code","source":["\n","bit_precision = 4\n","file = open('weight.txt', 'w') #write to file\n","file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n","file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n","file.write('#................#\\n')\n","for kij in range(9):\n","    for i in range(W.size(0)):\n","        for j in range(W.size(1)):\n","            if (W[i, 7-j, kij].item()<0):\n","                W_bin = '{0:04b}'.format(int(W[i,7-j,kij].item()+2**bit_precision+0.001))\n","            else:\n","                W_bin = '{0:04b}'.format(int(W[i,7-j,kij].item()+0.001))\n","            for k in range(bit_precision):\n","                file.write(W_bin[k])\n","            #file.write(' ')  # for visibility with blank between words, you can use\n","        file.write('\\n')\n","file.close() #close file"],"metadata":{"id":"W0o2upN-KvJm","executionInfo":{"status":"ok","timestamp":1764043246674,"user_tz":480,"elapsed":33,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}}},"id":"W0o2upN-KvJm","execution_count":49,"outputs":[]},{"cell_type":"code","source":["W[0,:,0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxR9Na_VLDAp","executionInfo":{"status":"ok","timestamp":1764043249145,"user_tz":480,"elapsed":14,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"960885ad-b067-4201-9136-c53803f1bb5b"},"id":"pxR9Na_VLDAp","execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-5.0000, -0.0000,  2.0000,  7.0000,  7.0000,  3.0000, -3.0000,  2.0000],\n","       device='cuda:0', grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["p_nijg = range(X.size(1)) ## psum nij group\n","psum = torch.zeros(8, len(p_nijg), 9).cuda()\n","for kij in range(9):\n","    for nij in p_nijg:       # time domain, sequentially given input\n","        m = nn.Linear(8, 8, bias=False)\n","        m.weight = torch.nn.Parameter(W[:,:,kij])\n","        psum[:, nij, kij] = m(X[:,nij]).cuda()\n","bit_precision = 16\n","file = open('psum.txt', 'w') #write to file\n","file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n","file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n","file.write('#................#\\n')\n","for kij in range(9):\n","    for i in range(psum.size(1)):\n","        for j in range(psum.size(0)):\n","            if (psum[7-j,i,kij].item()<0):\n","                P_bin = '{0:016b}'.format(int(psum[7-j,i,kij].item()+2**bit_precision+0.001))\n","            else:\n","                P_bin = '{0:016b}'.format(int(psum[7-j,i,kij].item()+0.001))\n","            for k in range(bit_precision):\n","                file.write(P_bin[k])\n","            #file.write(' ')  # for visibility with blank between words, you can use\n","        file.write('\\n')\n","file.close()"],"metadata":{"id":"4jMH_fdkLJtd","executionInfo":{"status":"ok","timestamp":1764043250921,"user_tz":480,"elapsed":188,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}}},"id":"4jMH_fdkLJtd","execution_count":51,"outputs":[]},{"cell_type":"code","source":["out = relu(output_int[0])\n","out = torch.reshape(out, (out.size(0), -1))\n","bit_precision = 16\n","file = open('output.txt', 'w') #write to file\n","file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n","file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n","file.write('#................#\\n')\n","\n","for i in range(out.size(1)):\n","    for j in range(out.size(0)):\n","        if (out[7-j,i].item()<0):\n","            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+2**bit_precision+0.001))\n","        else:\n","            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+0.001))\n","        for k in range(bit_precision):\n","            file.write(O_bin[k])\n","        #file.write(' ')  # for visibility with blank between words, you can use\n","    file.write('\\n')\n","file.close()"],"metadata":{"id":"_1SmPoKDMmpE","executionInfo":{"status":"ok","timestamp":1764044840440,"user_tz":480,"elapsed":10,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}}},"id":"_1SmPoKDMmpE","execution_count":58,"outputs":[]},{"cell_type":"code","source":["import torch\n","import math\n","\n","# ======================\n","# 1. 从 activation.txt 读回 x_pad[0]\n","# ======================\n","\n","def read_activation_txt(path, C_in=8):\n","    lines = []\n","    with open(path, 'r') as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line or line.startswith('#'):\n","                continue\n","            lines.append(line)\n","\n","    T = len(lines)                 # time steps = 展平后的空间点数\n","    X = torch.zeros(C_in, T, dtype=torch.int32)\n","\n","    for t, line in enumerate(lines):\n","        # 每行: ch7(4bit) ch6(4bit) ... ch0(4bit) → 共 8*4 = 32 bit\n","        assert len(line) >= C_in * 4, f\"activation line too short: {len(line)} bits\"\n","\n","        for c in range(C_in):\n","            group_idx = 7 - c      # 写入时用了 X[7-j,i]，所以 group=7-c\n","            start = group_idx * 4\n","            bits = line[start:start+4]\n","            val = int(bits, 2)     # 无符号 4bit（ReLU 后不会是负的）\n","            X[c, t] = val\n","\n","    # 还原空间尺寸: T = H_pad * W_pad\n","    H_pad = int(math.sqrt(T))\n","    W_pad = H_pad\n","    assert H_pad * W_pad == T, f\"activation T={T} 不能 sqrt 成方形\"\n","\n","    x_pad_0 = X.view(C_in, H_pad, W_pad)  # [C_in, H_pad, W_pad]\n","    return x_pad_0\n","\n","\n","# ======================\n","# 2. 从 weight.txt 读回 weight_int\n","# ======================\n","\n","def read_weight_txt(path, C_in=8, K=3):\n","    lines = []\n","    with open(path, 'r') as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line or line.startswith('#'):\n","                continue\n","            lines.append(line)\n","\n","    total_lines = len(lines)\n","    K2 = K * K                      # 3x3 → 9\n","    assert total_lines % K2 == 0, \"weight.txt 行数不是 9 的整数倍，检查文件格式\"\n","\n","    C_out = total_lines // K2       # 每个 kij 有 C_out 行\n","    W = torch.zeros(C_out, C_in, K2, dtype=torch.int32)  # [oc, ic, kij]\n","\n","    for kij in range(K2):\n","        for oc in range(C_out):\n","            line_idx = kij * C_out + oc\n","            line = lines[line_idx]\n","            assert len(line) >= C_in * 4, f\"weight line too short: {len(line)} bits\"\n","\n","            for ic in range(C_in):\n","                group_idx = 7 - ic       # 写入时 W[i,7-j,kij]，group = j → ic = 7-j\n","                start = group_idx * 4\n","                bits = line[start:start+4]\n","                v_u = int(bits, 2)       # 0..15\n","\n","                # 4-bit 二补码 → 有符号\n","                if v_u >= 8:\n","                    v = v_u - 16\n","                else:\n","                    v = v_u\n","\n","                W[oc, ic, kij] = v\n","\n","    # 还原到 [C_out, C_in, K, K]\n","    weight_int = W.view(C_out, C_in, K, K)\n","    return weight_int\n","\n","\n","# ======================\n","# 3. 从 output.txt 读回 output_int[0]\n","# ======================\n","\n","def read_output_txt(path, C_out=8):\n","    lines = []\n","    with open(path, 'r') as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line or line.startswith('#'):\n","                continue\n","            lines.append(line)\n","\n","    T = len(lines)                  # 输出的空间点数 (4x4=16)\n","    out_flat = torch.zeros(C_out, T, dtype=torch.int32)\n","\n","    for t, line in enumerate(lines):\n","        assert len(line) >= C_out * 16, f\"output line too short: {len(line)} bits\"\n","        for oc in range(C_out):\n","            group_idx = 7 - oc      # 写入时 out[7-j,i]，同理 group=7-oc\n","            start = group_idx * 16\n","            bits = line[start:start+16]\n","            v_u = int(bits, 2)      # 无符号 16-bit\n","\n","            # 16-bit 二补码\n","            if v_u >= 2**15:\n","                v = v_u - 2**16\n","            else:\n","                v = v_u\n","\n","            out_flat[oc, t] = v\n","\n","    # 还原空间 H_out x W_out：这里我们知道是 4x4，如果不确定可以 sqrt\n","    H_out = int(math.sqrt(T))\n","    W_out = H_out\n","    assert H_out * W_out == T, f\"output T={T} 不能 sqrt 成方形\"\n","\n","    out_0 = out_flat.view(C_out, H_out, W_out)  # [C_out, H_out, W_out]\n","    return out_0\n","\n","\n","# ======================\n","# 4. 用重建的 x_pad_0 和 weight_int 手动做 3x3 conv\n","# ======================\n","\n","def manual_conv_3x3_stride1_pad1_from_xpad(x_pad_0, weight_int):\n","    \"\"\"\n","    x_pad_0: [C_in, H_pad, W_pad] (比如 8x6x6)\n","    weight_int: [C_out, C_in, 3, 3]\n","    return: [C_out, H_out, W_out] = [C_out, H_pad-2, W_pad-2]\n","    \"\"\"\n","    C_in = x_pad_0.size(0)\n","    C_out = weight_int.size(0)\n","    Kh = Kw = 3\n","    H_pad, W_pad = x_pad_0.size(1), x_pad_0.size(2)\n","    H_out, W_out = H_pad - Kh + 1, W_pad - Kw + 1\n","\n","    out = torch.zeros(C_out, H_out, W_out, dtype=torch.int32)\n","\n","    for oc in range(C_out):\n","        for h in range(H_out):\n","            for w in range(W_out):\n","                acc = 0\n","                for ic in range(C_in):\n","                    for kh in range(Kh):\n","                        for kw in range(Kw):\n","                            acc += int(x_pad_0[ic, h+kh, w+kw].item()) * \\\n","                                   int(weight_int[oc, ic, kh, kw].item())\n","                out[oc, h, w] = acc\n","\n","    return out\n","\n","\n","# ======================\n","# 5. 整体测试：读 txt → 卷积 → 对比 output.txt\n","# ======================\n","\n","act_path = \"activation.txt\"\n","wgt_path = \"weight.txt\"\n","out_path = \"output.txt\"\n","\n","x_pad_0 = read_activation_txt(act_path, C_in=8)\n","weight_int = read_weight_txt(wgt_path, C_in=8, K=3)\n","out_from_txt = read_output_txt(out_path, C_out=8)\n","\n","print(\"x_pad_0 shape:\", x_pad_0.shape)       # 期望 [8,6,6]\n","print(\"weight_int shape:\", weight_int.shape) # 期望 [8,8,3,3]\n","print(\"out_from_txt shape:\", out_from_txt.shape)  # 期望 [8,4,4]\n","\n","out_manual = manual_conv_3x3_stride1_pad1_from_xpad(x_pad_0, weight_int)\n","\n","diff = (out_manual.to(torch.int32) - out_from_txt.to(torch.int32)).abs()\n","print(\"max abs diff:\", diff.max().item())\n","print(\"all equal?:\", bool(torch.all(diff == 0)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zl3e0iLvNkd1","executionInfo":{"status":"ok","timestamp":1764044495084,"user_tz":480,"elapsed":139,"user":{"displayName":"Wenhao Zhao","userId":"11291250091384836440"}},"outputId":"197ceafe-50c1-4448-b921-6711ac51f7d9"},"id":"zl3e0iLvNkd1","execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["x_pad_0 shape: torch.Size([8, 6, 6])\n","weight_int shape: torch.Size([8, 8, 3, 3])\n","out_from_txt shape: torch.Size([8, 4, 4])\n","max abs diff: 411\n","all equal?: False\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"vscode":{"interpreter":{"hash":"907cbb87cc825d52daa26d94a4f3471be4a7efbfbc56d778ed32b1cc3c9bdcfc"}},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}